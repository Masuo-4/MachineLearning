2023-01-19 20:41:57,033:INFO:PyCaret Supervised Module
2023-01-19 20:41:57,034:INFO:ML Usecase: classification
2023-01-19 20:41:57,034:INFO:version 2.2.2
2023-01-19 20:41:57,034:INFO:Initializing setup()
2023-01-19 20:41:57,034:INFO:setup(target=SalePrice, ml_usecase=classification, available_plots={'parameter': 'Hyperparameters', 'auc': 'AUC', 'confusion_matrix': 'Confusion Matrix', 'threshold': 'Threshold', 'pr': 'Precision Recall', 'error': 'Prediction Error', 'class_report': 'Class Report', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'calibration': 'Calibration Curve', 'vc': 'Validation Curve', 'dimension': 'Dimensions', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'boundary': 'Decision Boundary', 'lift': 'Lift Chart', 'gain': 'Gain Chart', 'tree': 'Decision Tree'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=None, normalize=False, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=stratifiedkfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=False, custom_pipeline=None, html=True, session_id=None, log_experiment=False, experiment_name=None, log_plots=False, log_profile=False, log_data=False, silent=False, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-01-19 20:41:57,034:INFO:Checking environment
2023-01-19 20:41:57,035:INFO:python_version: 3.9.12
2023-01-19 20:41:57,035:INFO:python_build: ('main', 'Apr  5 2022 01:53:17')
2023-01-19 20:41:57,035:INFO:machine: x86_64
2023-01-19 20:41:57,035:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-01-19 20:41:57,035:INFO:Memory: svmem(total=8589934592, available=2613784576, percent=69.6, used=5588123648, free=290234368, active=2328588288, inactive=2278764544, wired=3259535360)
2023-01-19 20:41:57,035:INFO:Physical Core: 4
2023-01-19 20:41:57,035:INFO:Logical Core: 8
2023-01-19 20:41:57,035:INFO:Checking libraries
2023-01-19 20:41:57,035:INFO:pd==1.4.2
2023-01-19 20:41:57,035:INFO:numpy==1.21.5
2023-01-19 20:41:57,035:INFO:sklearn==1.0.2
2023-01-19 20:41:57,104:INFO:xgboost==1.7.2
2023-01-19 20:41:57,104:INFO:lightgbm==3.3.3
2023-01-19 20:41:57,185:INFO:catboost==1.1.1
2023-01-19 20:41:58,133:INFO:mlflow==2.0.1
2023-01-19 20:41:58,133:INFO:Checking Exceptions
2023-01-19 20:41:58,136:INFO:Declaring global variables
2023-01-19 20:41:58,136:INFO:USI: c6fa
2023-01-19 20:41:58,136:INFO:pycaret_globals: {'_available_plots', 'X', 'fold_param', 'stratify_param', 'n_jobs_param', 'display_container', 'seed', 'create_model_container', '_internal_pipeline', '_ml_usecase', '_all_models_internal', 'X_test', 'gpu_param', 'exp_name_log', 'pycaret_globals', 'fold_groups_param', 'log_plots_param', 'fix_imbalance_method_param', 'imputation_regressor', 'y', 'experiment__', 'logging_param', 'master_model_container', '_all_metrics', 'transform_target_param', 'target_param', 'imputation_classifier', 'transform_target_method_param', 'fold_generator', 'X_train', 'iterative_imputation_iters_param', 'data_before_preprocess', 'y_train', '_all_models', 'fix_imbalance_param', 'fold_shuffle_param', 'USI', '_gpu_n_jobs_param', 'html_param', 'prep_pipe', 'y_test'}
2023-01-19 20:41:58,136:INFO:Preparing display monitor
2023-01-19 20:41:58,136:INFO:Preparing display monitor
2023-01-19 20:41:58,158:INFO:Importing libraries
2023-01-19 20:41:58,158:INFO:Copying data for preprocessing
2023-01-19 20:41:58,167:INFO:Declaring preprocessing parameters
2023-01-19 20:41:58,176:INFO:Creating preprocessing pipeline
2023-01-19 20:41:58,270:INFO:Preprocessing pipeline created successfully
2023-01-19 20:41:58,270:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-01-19 20:41:58,270:INFO:Creating global containers
2023-01-19 20:42:40,681:INFO:PyCaret Supervised Module
2023-01-19 20:42:40,684:INFO:ML Usecase: classification
2023-01-19 20:42:40,684:INFO:version 2.2.2
2023-01-19 20:42:40,684:INFO:Initializing setup()
2023-01-19 20:42:40,684:INFO:setup(target=SalePrice, ml_usecase=classification, available_plots={'parameter': 'Hyperparameters', 'auc': 'AUC', 'confusion_matrix': 'Confusion Matrix', 'threshold': 'Threshold', 'pr': 'Precision Recall', 'error': 'Prediction Error', 'class_report': 'Class Report', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'calibration': 'Calibration Curve', 'vc': 'Validation Curve', 'dimension': 'Dimensions', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'boundary': 'Decision Boundary', 'lift': 'Lift Chart', 'gain': 'Gain Chart', 'tree': 'Decision Tree'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=None, normalize=False, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=stratifiedkfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=False, custom_pipeline=None, html=True, session_id=None, log_experiment=False, experiment_name=None, log_plots=False, log_profile=False, log_data=False, silent=False, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-01-19 20:42:40,684:INFO:Checking environment
2023-01-19 20:42:40,684:INFO:python_version: 3.9.12
2023-01-19 20:42:40,684:INFO:python_build: ('main', 'Apr  5 2022 01:53:17')
2023-01-19 20:42:40,685:INFO:machine: x86_64
2023-01-19 20:42:40,685:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-01-19 20:42:40,687:INFO:Memory: svmem(total=8589934592, available=2093072384, percent=75.6, used=5304766464, free=98230272, active=1997463552, inactive=1992224768, wired=3307302912)
2023-01-19 20:42:40,687:INFO:Physical Core: 4
2023-01-19 20:42:40,687:INFO:Logical Core: 8
2023-01-19 20:42:40,687:INFO:Checking libraries
2023-01-19 20:42:40,687:INFO:pd==1.4.2
2023-01-19 20:42:40,687:INFO:numpy==1.21.5
2023-01-19 20:42:40,687:INFO:sklearn==1.0.2
2023-01-19 20:42:40,687:INFO:xgboost==1.7.2
2023-01-19 20:42:40,687:INFO:lightgbm==3.3.3
2023-01-19 20:42:40,687:INFO:catboost==1.1.1
2023-01-19 20:42:40,687:INFO:mlflow==2.0.1
2023-01-19 20:42:40,687:INFO:Checking Exceptions
2023-01-19 20:42:40,689:INFO:Declaring global variables
2023-01-19 20:42:40,690:INFO:USI: d5e8
2023-01-19 20:42:40,690:INFO:pycaret_globals: {'_available_plots', 'X', 'fold_param', 'stratify_param', 'n_jobs_param', 'display_container', 'seed', 'create_model_container', '_internal_pipeline', '_ml_usecase', '_all_models_internal', 'X_test', 'gpu_param', 'exp_name_log', 'pycaret_globals', 'fold_groups_param', 'log_plots_param', 'fix_imbalance_method_param', 'imputation_regressor', 'y', 'experiment__', 'logging_param', 'master_model_container', '_all_metrics', 'transform_target_param', 'target_param', 'imputation_classifier', 'transform_target_method_param', 'fold_generator', 'X_train', 'iterative_imputation_iters_param', 'data_before_preprocess', 'y_train', '_all_models', 'fix_imbalance_param', 'fold_shuffle_param', 'USI', '_gpu_n_jobs_param', 'html_param', 'prep_pipe', 'y_test'}
2023-01-19 20:42:40,690:INFO:Preparing display monitor
2023-01-19 20:42:40,690:INFO:Preparing display monitor
2023-01-19 20:42:40,723:INFO:Importing libraries
2023-01-19 20:42:40,723:INFO:Copying data for preprocessing
2023-01-19 20:42:40,734:INFO:Declaring preprocessing parameters
2023-01-19 20:42:40,739:INFO:Creating preprocessing pipeline
2023-01-19 20:42:40,898:INFO:Preprocessing pipeline created successfully
2023-01-19 20:42:40,898:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-01-19 20:42:40,898:INFO:Creating global containers
2023-01-19 20:43:30,842:INFO:PyCaret Supervised Module
2023-01-19 20:43:30,850:INFO:ML Usecase: classification
2023-01-19 20:43:30,851:INFO:version 2.2.2
2023-01-19 20:43:30,851:INFO:Initializing setup()
2023-01-19 20:43:30,851:INFO:setup(target=SalePrice, ml_usecase=classification, available_plots={'parameter': 'Hyperparameters', 'auc': 'AUC', 'confusion_matrix': 'Confusion Matrix', 'threshold': 'Threshold', 'pr': 'Precision Recall', 'error': 'Prediction Error', 'class_report': 'Class Report', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'calibration': 'Calibration Curve', 'vc': 'Validation Curve', 'dimension': 'Dimensions', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'boundary': 'Decision Boundary', 'lift': 'Lift Chart', 'gain': 'Gain Chart', 'tree': 'Decision Tree'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=None, normalize=False, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=stratifiedkfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=False, custom_pipeline=None, html=True, session_id=None, log_experiment=False, experiment_name=None, log_plots=False, log_profile=False, log_data=False, silent=False, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-01-19 20:43:30,851:INFO:Checking environment
2023-01-19 20:43:30,851:INFO:python_version: 3.9.12
2023-01-19 20:43:30,851:INFO:python_build: ('main', 'Apr  5 2022 01:53:17')
2023-01-19 20:43:30,851:INFO:machine: x86_64
2023-01-19 20:43:30,851:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-01-19 20:43:30,851:INFO:Memory: svmem(total=8589934592, available=2331185152, percent=72.9, used=5557309440, free=54358016, active=2281390080, inactive=2274086912, wired=3275919360)
2023-01-19 20:43:30,851:INFO:Physical Core: 4
2023-01-19 20:43:30,851:INFO:Logical Core: 8
2023-01-19 20:43:30,851:INFO:Checking libraries
2023-01-19 20:43:30,851:INFO:pd==1.4.2
2023-01-19 20:43:30,851:INFO:numpy==1.21.5
2023-01-19 20:43:30,851:INFO:sklearn==1.0.2
2023-01-19 20:43:30,852:INFO:xgboost==1.7.2
2023-01-19 20:43:30,852:INFO:lightgbm==3.3.3
2023-01-19 20:43:30,852:INFO:catboost==1.1.1
2023-01-19 20:43:30,852:INFO:mlflow==2.0.1
2023-01-19 20:43:30,852:INFO:Checking Exceptions
2023-01-19 20:43:30,853:INFO:Declaring global variables
2023-01-19 20:43:30,853:INFO:USI: 57c7
2023-01-19 20:43:30,853:INFO:pycaret_globals: {'_available_plots', 'X', 'fold_param', 'stratify_param', 'n_jobs_param', 'display_container', 'seed', 'create_model_container', '_internal_pipeline', '_ml_usecase', '_all_models_internal', 'X_test', 'gpu_param', 'exp_name_log', 'pycaret_globals', 'fold_groups_param', 'log_plots_param', 'fix_imbalance_method_param', 'imputation_regressor', 'y', 'experiment__', 'logging_param', 'master_model_container', '_all_metrics', 'transform_target_param', 'target_param', 'imputation_classifier', 'transform_target_method_param', 'fold_generator', 'X_train', 'iterative_imputation_iters_param', 'data_before_preprocess', 'y_train', '_all_models', 'fix_imbalance_param', 'fold_shuffle_param', 'USI', '_gpu_n_jobs_param', 'html_param', 'prep_pipe', 'y_test'}
2023-01-19 20:43:30,853:INFO:Preparing display monitor
2023-01-19 20:43:30,853:INFO:Preparing display monitor
2023-01-19 20:43:30,882:INFO:Importing libraries
2023-01-19 20:43:30,882:INFO:Copying data for preprocessing
2023-01-19 20:43:30,937:INFO:Declaring preprocessing parameters
2023-01-19 20:43:30,940:INFO:Creating preprocessing pipeline
2023-01-19 20:43:31,248:INFO:Preprocessing pipeline created successfully
2023-01-19 20:43:31,249:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-01-19 20:43:31,249:INFO:Creating global containers
2023-01-19 20:44:17,846:INFO:PyCaret Supervised Module
2023-01-19 20:44:17,847:INFO:ML Usecase: classification
2023-01-19 20:44:17,847:INFO:version 2.2.2
2023-01-19 20:44:17,848:INFO:Initializing setup()
2023-01-19 20:44:17,848:INFO:setup(target=SalePrice, ml_usecase=classification, available_plots={'parameter': 'Hyperparameters', 'auc': 'AUC', 'confusion_matrix': 'Confusion Matrix', 'threshold': 'Threshold', 'pr': 'Precision Recall', 'error': 'Prediction Error', 'class_report': 'Class Report', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'calibration': 'Calibration Curve', 'vc': 'Validation Curve', 'dimension': 'Dimensions', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'boundary': 'Decision Boundary', 'lift': 'Lift Chart', 'gain': 'Gain Chart', 'tree': 'Decision Tree'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=None, normalize=False, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=stratifiedkfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=False, custom_pipeline=None, html=True, session_id=None, log_experiment=False, experiment_name=None, log_plots=False, log_profile=False, log_data=False, silent=False, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-01-19 20:44:17,848:INFO:Checking environment
2023-01-19 20:44:17,848:INFO:python_version: 3.9.12
2023-01-19 20:44:17,848:INFO:python_build: ('main', 'Apr  5 2022 01:53:17')
2023-01-19 20:44:17,848:INFO:machine: x86_64
2023-01-19 20:44:17,848:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-01-19 20:44:17,849:INFO:Memory: svmem(total=8589934592, available=2698186752, percent=68.6, used=5669634048, free=507265024, active=2193534976, inactive=2188738560, wired=3476099072)
2023-01-19 20:44:17,849:INFO:Physical Core: 4
2023-01-19 20:44:17,849:INFO:Logical Core: 8
2023-01-19 20:44:17,849:INFO:Checking libraries
2023-01-19 20:44:17,849:INFO:pd==1.4.2
2023-01-19 20:44:17,849:INFO:numpy==1.21.5
2023-01-19 20:44:17,849:INFO:sklearn==1.0.2
2023-01-19 20:44:17,849:INFO:xgboost==1.7.2
2023-01-19 20:44:17,849:INFO:lightgbm==3.3.3
2023-01-19 20:44:17,850:INFO:catboost==1.1.1
2023-01-19 20:44:17,850:INFO:mlflow==2.0.1
2023-01-19 20:44:17,850:INFO:Checking Exceptions
2023-01-19 20:44:17,851:INFO:Declaring global variables
2023-01-19 20:44:17,858:INFO:USI: 520b
2023-01-19 20:44:17,859:INFO:pycaret_globals: {'_available_plots', 'X', 'fold_param', 'stratify_param', 'n_jobs_param', 'display_container', 'seed', 'create_model_container', '_internal_pipeline', '_ml_usecase', '_all_models_internal', 'X_test', 'gpu_param', 'exp_name_log', 'pycaret_globals', 'fold_groups_param', 'log_plots_param', 'fix_imbalance_method_param', 'imputation_regressor', 'y', 'experiment__', 'logging_param', 'master_model_container', '_all_metrics', 'transform_target_param', 'target_param', 'imputation_classifier', 'transform_target_method_param', 'fold_generator', 'X_train', 'iterative_imputation_iters_param', 'data_before_preprocess', 'y_train', '_all_models', 'fix_imbalance_param', 'fold_shuffle_param', 'USI', '_gpu_n_jobs_param', 'html_param', 'prep_pipe', 'y_test'}
2023-01-19 20:44:17,862:INFO:Preparing display monitor
2023-01-19 20:44:17,862:INFO:Preparing display monitor
2023-01-19 20:44:17,892:INFO:Importing libraries
2023-01-19 20:44:17,893:INFO:Copying data for preprocessing
2023-01-19 20:44:17,902:INFO:Declaring preprocessing parameters
2023-01-19 20:44:17,905:INFO:Creating preprocessing pipeline
2023-01-19 20:44:17,993:INFO:Preprocessing pipeline created successfully
2023-01-19 20:44:17,993:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-01-19 20:44:17,993:INFO:Creating global containers
2023-01-19 20:45:21,170:INFO:PyCaret Supervised Module
2023-01-19 20:45:21,175:INFO:ML Usecase: classification
2023-01-19 20:45:21,175:INFO:version 2.2.2
2023-01-19 20:45:21,175:INFO:Initializing setup()
2023-01-19 20:45:21,175:INFO:setup(target=SalePrice, ml_usecase=classification, available_plots={'parameter': 'Hyperparameters', 'auc': 'AUC', 'confusion_matrix': 'Confusion Matrix', 'threshold': 'Threshold', 'pr': 'Precision Recall', 'error': 'Prediction Error', 'class_report': 'Class Report', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'calibration': 'Calibration Curve', 'vc': 'Validation Curve', 'dimension': 'Dimensions', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'boundary': 'Decision Boundary', 'lift': 'Lift Chart', 'gain': 'Gain Chart', 'tree': 'Decision Tree'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=None, normalize=False, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=stratifiedkfold, fold=10, fold_shuffle=False, fold_groups=None, n_jobs=-1, use_gpu=False, custom_pipeline=None, html=True, session_id=None, log_experiment=False, experiment_name=None, log_plots=False, log_profile=False, log_data=False, silent=False, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-01-19 20:45:21,175:INFO:Checking environment
2023-01-19 20:45:21,176:INFO:python_version: 3.9.12
2023-01-19 20:45:21,176:INFO:python_build: ('main', 'Apr  5 2022 01:53:17')
2023-01-19 20:45:21,176:INFO:machine: x86_64
2023-01-19 20:45:21,176:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-01-19 20:45:21,178:INFO:Memory: svmem(total=8589934592, available=2292682752, percent=73.3, used=5513904128, free=61652992, active=2234961920, inactive=2222968832, wired=3278942208)
2023-01-19 20:45:21,178:INFO:Physical Core: 4
2023-01-19 20:45:21,179:INFO:Logical Core: 8
2023-01-19 20:45:21,179:INFO:Checking libraries
2023-01-19 20:45:21,179:INFO:pd==1.4.2
2023-01-19 20:45:21,179:INFO:numpy==1.21.5
2023-01-19 20:45:21,179:INFO:sklearn==1.0.2
2023-01-19 20:45:21,179:INFO:xgboost==1.7.2
2023-01-19 20:45:21,179:INFO:lightgbm==3.3.3
2023-01-19 20:45:21,179:INFO:catboost==1.1.1
2023-01-19 20:45:21,179:INFO:mlflow==2.0.1
2023-01-19 20:45:21,179:INFO:Checking Exceptions
2023-01-19 20:45:21,179:INFO:Declaring global variables
2023-01-19 20:45:21,180:INFO:USI: 0db4
2023-01-19 20:45:21,180:INFO:pycaret_globals: {'_available_plots', 'X', 'fold_param', 'stratify_param', 'n_jobs_param', 'display_container', 'seed', 'create_model_container', '_internal_pipeline', '_ml_usecase', '_all_models_internal', 'X_test', 'gpu_param', 'exp_name_log', 'pycaret_globals', 'fold_groups_param', 'log_plots_param', 'fix_imbalance_method_param', 'imputation_regressor', 'y', 'experiment__', 'logging_param', 'master_model_container', '_all_metrics', 'transform_target_param', 'target_param', 'imputation_classifier', 'transform_target_method_param', 'fold_generator', 'X_train', 'iterative_imputation_iters_param', 'data_before_preprocess', 'y_train', '_all_models', 'fix_imbalance_param', 'fold_shuffle_param', 'USI', '_gpu_n_jobs_param', 'html_param', 'prep_pipe', 'y_test'}
2023-01-19 20:45:21,180:INFO:Preparing display monitor
2023-01-19 20:45:21,180:INFO:Preparing display monitor
2023-01-19 20:45:21,211:INFO:Importing libraries
2023-01-19 20:45:21,212:INFO:Copying data for preprocessing
2023-01-19 20:45:21,221:INFO:Declaring preprocessing parameters
2023-01-19 20:45:21,223:INFO:Creating preprocessing pipeline
2023-01-19 20:45:21,347:INFO:Preprocessing pipeline created successfully
2023-01-19 20:45:21,348:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-01-19 20:45:21,348:INFO:Creating global containers
2023-01-19 20:45:54,020:INFO:PyCaret Supervised Module
2023-01-19 20:45:54,021:INFO:ML Usecase: classification
2023-01-19 20:45:54,021:INFO:version 2.2.2
2023-01-19 20:45:54,021:INFO:Initializing setup()
2023-01-19 20:45:54,021:INFO:setup(target=SalePrice, ml_usecase=classification, available_plots={'parameter': 'Hyperparameters', 'auc': 'AUC', 'confusion_matrix': 'Confusion Matrix', 'threshold': 'Threshold', 'pr': 'Precision Recall', 'error': 'Prediction Error', 'class_report': 'Class Report', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'calibration': 'Calibration Curve', 'vc': 'Validation Curve', 'dimension': 'Dimensions', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'boundary': 'Decision Boundary', 'lift': 'Lift Chart', 'gain': 'Gain Chart', 'tree': 'Decision Tree'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=None, normalize=False, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=stratifiedkfold, fold=10, fold_shuffle=True, fold_groups=None, n_jobs=-1, use_gpu=False, custom_pipeline=None, html=True, session_id=None, log_experiment=False, experiment_name=None, log_plots=False, log_profile=False, log_data=False, silent=False, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-01-19 20:45:54,021:INFO:Checking environment
2023-01-19 20:45:54,021:INFO:python_version: 3.9.12
2023-01-19 20:45:54,021:INFO:python_build: ('main', 'Apr  5 2022 01:53:17')
2023-01-19 20:45:54,021:INFO:machine: x86_64
2023-01-19 20:45:54,021:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-01-19 20:45:54,021:INFO:Memory: svmem(total=8589934592, available=2491105280, percent=71.0, used=5665824768, free=76288000, active=2417250304, inactive=2411511808, wired=3248574464)
2023-01-19 20:45:54,022:INFO:Physical Core: 4
2023-01-19 20:45:54,022:INFO:Logical Core: 8
2023-01-19 20:45:54,022:INFO:Checking libraries
2023-01-19 20:45:54,022:INFO:pd==1.4.2
2023-01-19 20:45:54,022:INFO:numpy==1.21.5
2023-01-19 20:45:54,022:INFO:sklearn==1.0.2
2023-01-19 20:45:54,022:INFO:xgboost==1.7.2
2023-01-19 20:45:54,022:INFO:lightgbm==3.3.3
2023-01-19 20:45:54,022:INFO:catboost==1.1.1
2023-01-19 20:45:54,022:INFO:mlflow==2.0.1
2023-01-19 20:45:54,022:INFO:Checking Exceptions
2023-01-19 20:45:54,022:INFO:Declaring global variables
2023-01-19 20:45:54,022:INFO:USI: 3be5
2023-01-19 20:45:54,023:INFO:pycaret_globals: {'_available_plots', 'X', 'fold_param', 'stratify_param', 'n_jobs_param', 'display_container', 'seed', 'create_model_container', '_internal_pipeline', '_ml_usecase', '_all_models_internal', 'X_test', 'gpu_param', 'exp_name_log', 'pycaret_globals', 'fold_groups_param', 'log_plots_param', 'fix_imbalance_method_param', 'imputation_regressor', 'y', 'experiment__', 'logging_param', 'master_model_container', '_all_metrics', 'transform_target_param', 'target_param', 'imputation_classifier', 'transform_target_method_param', 'fold_generator', 'X_train', 'iterative_imputation_iters_param', 'data_before_preprocess', 'y_train', '_all_models', 'fix_imbalance_param', 'fold_shuffle_param', 'USI', '_gpu_n_jobs_param', 'html_param', 'prep_pipe', 'y_test'}
2023-01-19 20:45:54,023:INFO:Preparing display monitor
2023-01-19 20:45:54,023:INFO:Preparing display monitor
2023-01-19 20:45:54,033:INFO:Importing libraries
2023-01-19 20:45:54,034:INFO:Copying data for preprocessing
2023-01-19 20:45:54,041:INFO:Declaring preprocessing parameters
2023-01-19 20:45:54,044:INFO:Creating preprocessing pipeline
2023-01-19 20:45:54,170:INFO:Preprocessing pipeline created successfully
2023-01-19 20:45:54,170:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-01-19 20:45:54,170:INFO:Creating global containers
2023-01-19 20:45:54,185:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-01-19 20:46:15,759:INFO:Creating grid variables
2023-01-19 20:46:15,789:INFO:create_model_container: 0
2023-01-19 20:46:15,789:INFO:master_model_container: 0
2023-01-19 20:46:15,789:INFO:display_container: 0
2023-01-19 20:48:18,412:INFO:PyCaret Supervised Module
2023-01-19 20:48:18,413:INFO:ML Usecase: classification
2023-01-19 20:48:18,413:INFO:version 2.2.2
2023-01-19 20:48:18,413:INFO:Initializing setup()
2023-01-19 20:48:18,413:INFO:setup(target=SalePrice, ml_usecase=classification, available_plots={'parameter': 'Hyperparameters', 'auc': 'AUC', 'confusion_matrix': 'Confusion Matrix', 'threshold': 'Threshold', 'pr': 'Precision Recall', 'error': 'Prediction Error', 'class_report': 'Class Report', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'calibration': 'Calibration Curve', 'vc': 'Validation Curve', 'dimension': 'Dimensions', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'boundary': 'Decision Boundary', 'lift': 'Lift Chart', 'gain': 'Gain Chart', 'tree': 'Decision Tree'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=None, normalize=False, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=stratifiedkfold, fold=10, fold_shuffle=True, fold_groups=None, n_jobs=-1, use_gpu=False, custom_pipeline=None, html=True, session_id=None, log_experiment=False, experiment_name=None, log_plots=False, log_profile=False, log_data=False, silent=False, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-01-19 20:48:18,413:INFO:Checking environment
2023-01-19 20:48:18,413:INFO:python_version: 3.9.12
2023-01-19 20:48:18,413:INFO:python_build: ('main', 'Apr  5 2022 01:53:17')
2023-01-19 20:48:18,413:INFO:machine: x86_64
2023-01-19 20:48:18,413:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-01-19 20:48:18,414:INFO:Memory: svmem(total=8589934592, available=2597392384, percent=69.8, used=5585588224, free=327901184, active=2272854016, inactive=2258083840, wired=3312734208)
2023-01-19 20:48:18,415:INFO:Physical Core: 4
2023-01-19 20:48:18,415:INFO:Logical Core: 8
2023-01-19 20:48:18,415:INFO:Checking libraries
2023-01-19 20:48:18,415:INFO:pd==1.4.2
2023-01-19 20:48:18,415:INFO:numpy==1.21.5
2023-01-19 20:48:18,415:INFO:sklearn==1.0.2
2023-01-19 20:48:18,415:INFO:xgboost==1.7.2
2023-01-19 20:48:18,415:INFO:lightgbm==3.3.3
2023-01-19 20:48:18,415:INFO:catboost==1.1.1
2023-01-19 20:48:18,415:INFO:mlflow==2.0.1
2023-01-19 20:48:18,415:INFO:Checking Exceptions
2023-01-19 20:48:18,416:INFO:Declaring global variables
2023-01-19 20:48:18,416:INFO:USI: 2136
2023-01-19 20:48:18,417:INFO:pycaret_globals: {'_available_plots', 'X', 'fold_param', 'stratify_param', 'n_jobs_param', 'display_container', 'seed', 'create_model_container', '_internal_pipeline', '_ml_usecase', '_all_models_internal', 'X_test', 'gpu_param', 'exp_name_log', 'pycaret_globals', 'fold_groups_param', 'log_plots_param', 'fix_imbalance_method_param', 'imputation_regressor', 'y', 'experiment__', 'logging_param', 'master_model_container', '_all_metrics', 'transform_target_param', 'target_param', 'imputation_classifier', 'transform_target_method_param', 'fold_generator', 'X_train', 'iterative_imputation_iters_param', 'data_before_preprocess', 'y_train', '_all_models', 'fix_imbalance_param', 'fold_shuffle_param', 'USI', '_gpu_n_jobs_param', 'html_param', 'prep_pipe', 'y_test'}
2023-01-19 20:48:18,417:INFO:Preparing display monitor
2023-01-19 20:48:18,417:INFO:Preparing display monitor
2023-01-19 20:48:18,432:INFO:Importing libraries
2023-01-19 20:48:18,432:INFO:Copying data for preprocessing
2023-01-19 20:48:18,442:INFO:Declaring preprocessing parameters
2023-01-19 20:48:18,444:INFO:Creating preprocessing pipeline
2023-01-19 20:48:18,546:INFO:Preprocessing pipeline created successfully
2023-01-19 20:48:18,546:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-01-19 20:48:18,546:INFO:Creating global containers
2023-01-19 20:48:18,547:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-01-19 20:48:23,640:INFO:Creating grid variables
2023-01-19 20:48:23,651:INFO:create_model_container: 0
2023-01-19 20:48:23,651:INFO:master_model_container: 0
2023-01-19 20:48:23,651:INFO:display_container: 0
2023-01-19 20:56:27,300:INFO:PyCaret Supervised Module
2023-01-19 20:56:27,304:INFO:ML Usecase: classification
2023-01-19 20:56:27,304:INFO:version 2.2.2
2023-01-19 20:56:27,304:INFO:Initializing setup()
2023-01-19 20:56:27,304:INFO:setup(target=SalePrice, ml_usecase=classification, available_plots={'parameter': 'Hyperparameters', 'auc': 'AUC', 'confusion_matrix': 'Confusion Matrix', 'threshold': 'Threshold', 'pr': 'Precision Recall', 'error': 'Prediction Error', 'class_report': 'Class Report', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'calibration': 'Calibration Curve', 'vc': 'Validation Curve', 'dimension': 'Dimensions', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'boundary': 'Decision Boundary', 'lift': 'Lift Chart', 'gain': 'Gain Chart', 'tree': 'Decision Tree'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=None, normalize=False, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=stratifiedkfold, fold=10, fold_shuffle=True, fold_groups=None, n_jobs=-1, use_gpu=False, custom_pipeline=None, html=True, session_id=None, log_experiment=False, experiment_name=None, log_plots=False, log_profile=False, log_data=False, silent=False, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-01-19 20:56:27,304:INFO:Checking environment
2023-01-19 20:56:27,305:INFO:python_version: 3.9.12
2023-01-19 20:56:27,305:INFO:python_build: ('main', 'Apr  5 2022 01:53:17')
2023-01-19 20:56:27,306:INFO:machine: x86_64
2023-01-19 20:56:27,306:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-01-19 20:56:27,307:INFO:Memory: svmem(total=8589934592, available=2293043200, percent=73.3, used=5507002368, free=135319552, active=2162638848, inactive=2149429248, wired=3344363520)
2023-01-19 20:56:27,307:INFO:Physical Core: 4
2023-01-19 20:56:27,307:INFO:Logical Core: 8
2023-01-19 20:56:27,307:INFO:Checking libraries
2023-01-19 20:56:27,308:INFO:pd==1.4.2
2023-01-19 20:56:27,308:INFO:numpy==1.21.5
2023-01-19 20:56:27,308:INFO:sklearn==1.0.2
2023-01-19 20:56:27,309:INFO:xgboost==1.7.2
2023-01-19 20:56:27,309:INFO:lightgbm==3.3.3
2023-01-19 20:56:27,310:INFO:catboost==1.1.1
2023-01-19 20:56:27,311:INFO:mlflow==2.0.1
2023-01-19 20:56:27,311:INFO:Checking Exceptions
2023-01-19 20:56:27,312:INFO:Declaring global variables
2023-01-19 20:56:27,313:INFO:USI: 6bb7
2023-01-19 20:56:27,313:INFO:pycaret_globals: {'_available_plots', 'X', 'fold_param', 'stratify_param', 'n_jobs_param', 'display_container', 'seed', 'create_model_container', '_internal_pipeline', '_ml_usecase', '_all_models_internal', 'X_test', 'gpu_param', 'exp_name_log', 'pycaret_globals', 'fold_groups_param', 'log_plots_param', 'fix_imbalance_method_param', 'imputation_regressor', 'y', 'experiment__', 'logging_param', 'master_model_container', '_all_metrics', 'transform_target_param', 'target_param', 'imputation_classifier', 'transform_target_method_param', 'fold_generator', 'X_train', 'iterative_imputation_iters_param', 'data_before_preprocess', 'y_train', '_all_models', 'fix_imbalance_param', 'fold_shuffle_param', 'USI', '_gpu_n_jobs_param', 'html_param', 'prep_pipe', 'y_test'}
2023-01-19 20:56:27,313:INFO:Preparing display monitor
2023-01-19 20:56:27,317:INFO:Preparing display monitor
2023-01-19 20:56:27,366:INFO:Importing libraries
2023-01-19 20:56:27,367:INFO:Copying data for preprocessing
2023-01-19 20:56:27,380:INFO:Declaring preprocessing parameters
2023-01-19 20:56:27,384:INFO:Creating preprocessing pipeline
2023-01-19 20:56:27,496:INFO:Preprocessing pipeline created successfully
2023-01-19 20:56:27,496:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-01-19 20:56:27,496:INFO:Creating global containers
2023-01-19 20:56:27,498:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-01-19 20:56:32,572:INFO:Creating grid variables
2023-01-19 20:56:32,609:INFO:create_model_container: 0
2023-01-19 20:56:32,610:INFO:master_model_container: 0
2023-01-19 20:56:32,610:INFO:display_container: 0
2023-01-19 20:58:33,852:INFO:PyCaret Supervised Module
2023-01-19 20:58:33,853:INFO:ML Usecase: classification
2023-01-19 20:58:33,854:INFO:version 2.2.2
2023-01-19 20:58:33,854:INFO:Initializing setup()
2023-01-19 20:58:33,854:INFO:setup(target=SalePrice, ml_usecase=classification, available_plots={'parameter': 'Hyperparameters', 'auc': 'AUC', 'confusion_matrix': 'Confusion Matrix', 'threshold': 'Threshold', 'pr': 'Precision Recall', 'error': 'Prediction Error', 'class_report': 'Class Report', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'calibration': 'Calibration Curve', 'vc': 'Validation Curve', 'dimension': 'Dimensions', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'boundary': 'Decision Boundary', 'lift': 'Lift Chart', 'gain': 'Gain Chart', 'tree': 'Decision Tree'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=None, normalize=False, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=stratifiedkfold, fold=10, fold_shuffle=True, fold_groups=None, n_jobs=-1, use_gpu=False, custom_pipeline=None, html=True, session_id=None, log_experiment=False, experiment_name=None, log_plots=False, log_profile=False, log_data=False, silent=False, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-01-19 20:58:33,854:INFO:Checking environment
2023-01-19 20:58:33,854:INFO:python_version: 3.9.12
2023-01-19 20:58:33,854:INFO:python_build: ('main', 'Apr  5 2022 01:53:17')
2023-01-19 20:58:33,854:INFO:machine: x86_64
2023-01-19 20:58:33,854:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-01-19 20:58:33,854:INFO:Memory: svmem(total=8589934592, available=2228379648, percent=74.1, used=5511708672, free=84365312, active=2147262464, inactive=2132746240, wired=3364446208)
2023-01-19 20:58:33,854:INFO:Physical Core: 4
2023-01-19 20:58:33,854:INFO:Logical Core: 8
2023-01-19 20:58:33,854:INFO:Checking libraries
2023-01-19 20:58:33,854:INFO:pd==1.4.2
2023-01-19 20:58:33,854:INFO:numpy==1.21.5
2023-01-19 20:58:33,855:INFO:sklearn==1.0.2
2023-01-19 20:58:33,855:INFO:xgboost==1.7.2
2023-01-19 20:58:33,855:INFO:lightgbm==3.3.3
2023-01-19 20:58:33,855:INFO:catboost==1.1.1
2023-01-19 20:58:33,855:INFO:mlflow==2.0.1
2023-01-19 20:58:33,855:INFO:Checking Exceptions
2023-01-19 20:58:33,855:INFO:Declaring global variables
2023-01-19 20:58:33,855:INFO:USI: 2aa1
2023-01-19 20:58:33,855:INFO:pycaret_globals: {'_available_plots', 'X', 'fold_param', 'stratify_param', 'n_jobs_param', 'display_container', 'seed', 'create_model_container', '_internal_pipeline', '_ml_usecase', '_all_models_internal', 'X_test', 'gpu_param', 'exp_name_log', 'pycaret_globals', 'fold_groups_param', 'log_plots_param', 'fix_imbalance_method_param', 'imputation_regressor', 'y', 'experiment__', 'logging_param', 'master_model_container', '_all_metrics', 'transform_target_param', 'target_param', 'imputation_classifier', 'transform_target_method_param', 'fold_generator', 'X_train', 'iterative_imputation_iters_param', 'data_before_preprocess', 'y_train', '_all_models', 'fix_imbalance_param', 'fold_shuffle_param', 'USI', '_gpu_n_jobs_param', 'html_param', 'prep_pipe', 'y_test'}
2023-01-19 20:58:33,855:INFO:Preparing display monitor
2023-01-19 20:58:33,856:INFO:Preparing display monitor
2023-01-19 20:58:33,891:INFO:Importing libraries
2023-01-19 20:58:33,891:INFO:Copying data for preprocessing
2023-01-19 20:58:33,903:INFO:Declaring preprocessing parameters
2023-01-19 20:58:33,908:INFO:Creating preprocessing pipeline
2023-01-19 20:58:34,021:INFO:Preprocessing pipeline created successfully
2023-01-19 20:58:34,022:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-01-19 20:58:34,022:INFO:Creating global containers
2023-01-19 20:58:34,022:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-01-19 20:58:40,354:INFO:Creating grid variables
2023-01-19 20:58:40,365:INFO:create_model_container: 0
2023-01-19 20:58:40,365:INFO:master_model_container: 0
2023-01-19 20:58:40,366:INFO:display_container: 0
2023-01-19 21:00:23,144:INFO:PyCaret Supervised Module
2023-01-19 21:00:23,145:INFO:ML Usecase: classification
2023-01-19 21:00:23,145:INFO:version 2.2.2
2023-01-19 21:00:23,145:INFO:Initializing setup()
2023-01-19 21:00:23,145:INFO:setup(target=SalePrice, ml_usecase=classification, available_plots={'parameter': 'Hyperparameters', 'auc': 'AUC', 'confusion_matrix': 'Confusion Matrix', 'threshold': 'Threshold', 'pr': 'Precision Recall', 'error': 'Prediction Error', 'class_report': 'Class Report', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'calibration': 'Calibration Curve', 'vc': 'Validation Curve', 'dimension': 'Dimensions', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'boundary': 'Decision Boundary', 'lift': 'Lift Chart', 'gain': 'Gain Chart', 'tree': 'Decision Tree'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=None, normalize=False, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=stratifiedkfold, fold=10, fold_shuffle=True, fold_groups=None, n_jobs=-1, use_gpu=False, custom_pipeline=None, html=True, session_id=None, log_experiment=False, experiment_name=None, log_plots=False, log_profile=False, log_data=False, silent=False, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-01-19 21:00:23,145:INFO:Checking environment
2023-01-19 21:00:23,145:INFO:python_version: 3.9.12
2023-01-19 21:00:23,145:INFO:python_build: ('main', 'Apr  5 2022 01:53:17')
2023-01-19 21:00:23,145:INFO:machine: x86_64
2023-01-19 21:00:23,145:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-01-19 21:00:23,145:INFO:Memory: svmem(total=8589934592, available=2986827776, percent=65.2, used=5324275712, free=862154752, active=2127691776, inactive=2047963136, wired=3196583936)
2023-01-19 21:00:23,146:INFO:Physical Core: 4
2023-01-19 21:00:23,146:INFO:Logical Core: 8
2023-01-19 21:00:23,146:INFO:Checking libraries
2023-01-19 21:00:23,146:INFO:pd==1.4.2
2023-01-19 21:00:23,146:INFO:numpy==1.21.5
2023-01-19 21:00:23,146:INFO:sklearn==1.0.2
2023-01-19 21:00:23,216:INFO:xgboost==1.7.2
2023-01-19 21:00:23,216:INFO:lightgbm==3.3.3
2023-01-19 21:00:23,358:INFO:catboost==1.1.1
2023-01-19 21:00:24,293:INFO:mlflow==2.0.1
2023-01-19 21:00:24,293:INFO:Checking Exceptions
2023-01-19 21:00:24,293:INFO:Declaring global variables
2023-01-19 21:00:24,293:INFO:USI: f5be
2023-01-19 21:00:24,293:INFO:pycaret_globals: {'_gpu_n_jobs_param', 'y_test', 'fold_shuffle_param', 'seed', 'experiment__', '_available_plots', 'log_plots_param', '_all_models', 'fix_imbalance_param', 'gpu_param', 'iterative_imputation_iters_param', 'display_container', '_all_models_internal', 'transform_target_method_param', 'data_before_preprocess', 'y_train', 'exp_name_log', 'imputation_classifier', 'USI', '_internal_pipeline', 'fix_imbalance_method_param', 'logging_param', '_ml_usecase', 'target_param', 'n_jobs_param', 'X', 'y', 'fold_generator', 'stratify_param', '_all_metrics', 'X_test', 'fold_param', 'pycaret_globals', 'X_train', 'imputation_regressor', 'transform_target_param', 'master_model_container', 'create_model_container', 'html_param', 'fold_groups_param', 'prep_pipe'}
2023-01-19 21:00:24,293:INFO:Preparing display monitor
2023-01-19 21:00:24,293:INFO:Preparing display monitor
2023-01-19 21:00:24,313:INFO:Importing libraries
2023-01-19 21:00:24,313:INFO:Copying data for preprocessing
2023-01-19 21:00:24,324:INFO:Declaring preprocessing parameters
2023-01-19 21:00:24,327:INFO:Creating preprocessing pipeline
2023-01-19 21:00:24,396:INFO:Preprocessing pipeline created successfully
2023-01-19 21:00:24,396:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-01-19 21:00:24,396:INFO:Creating global containers
2023-01-19 21:00:24,400:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-01-19 21:00:29,238:INFO:Creating grid variables
2023-01-19 21:00:29,251:INFO:create_model_container: 0
2023-01-19 21:00:29,252:INFO:master_model_container: 0
2023-01-19 21:00:29,252:INFO:display_container: 0
2023-01-19 21:06:46,481:INFO:PyCaret Supervised Module
2023-01-19 21:06:46,487:INFO:ML Usecase: classification
2023-01-19 21:06:46,487:INFO:version 2.2.2
2023-01-19 21:06:46,487:INFO:Initializing setup()
2023-01-19 21:06:46,488:INFO:setup(target=SalePrice, ml_usecase=classification, available_plots={'parameter': 'Hyperparameters', 'auc': 'AUC', 'confusion_matrix': 'Confusion Matrix', 'threshold': 'Threshold', 'pr': 'Precision Recall', 'error': 'Prediction Error', 'class_report': 'Class Report', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'calibration': 'Calibration Curve', 'vc': 'Validation Curve', 'dimension': 'Dimensions', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'boundary': 'Decision Boundary', 'lift': 'Lift Chart', 'gain': 'Gain Chart', 'tree': 'Decision Tree'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=None, normalize=False, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=stratifiedkfold, fold=10, fold_shuffle=True, fold_groups=None, n_jobs=-1, use_gpu=False, custom_pipeline=None, html=True, session_id=None, log_experiment=False, experiment_name=None, log_plots=False, log_profile=False, log_data=False, silent=False, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-01-19 21:06:46,488:INFO:Checking environment
2023-01-19 21:06:46,488:INFO:python_version: 3.9.12
2023-01-19 21:06:46,488:INFO:python_build: ('main', 'Apr  5 2022 01:53:17')
2023-01-19 21:06:46,489:INFO:machine: x86_64
2023-01-19 21:06:46,489:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-01-19 21:06:46,493:INFO:Memory: svmem(total=8589934592, available=2235736064, percent=74.0, used=5630615552, free=16252928, active=2223276032, inactive=2199789568, wired=3407339520)
2023-01-19 21:06:46,493:INFO:Physical Core: 4
2023-01-19 21:06:46,493:INFO:Logical Core: 8
2023-01-19 21:06:46,493:INFO:Checking libraries
2023-01-19 21:06:46,493:INFO:pd==1.4.2
2023-01-19 21:06:46,493:INFO:numpy==1.21.5
2023-01-19 21:06:46,494:INFO:sklearn==1.0.2
2023-01-19 21:06:46,494:INFO:xgboost==1.7.2
2023-01-19 21:06:46,496:INFO:lightgbm==3.3.3
2023-01-19 21:06:46,496:INFO:catboost==1.1.1
2023-01-19 21:06:46,496:INFO:mlflow==2.0.1
2023-01-19 21:06:46,496:INFO:Checking Exceptions
2023-01-19 21:06:46,497:INFO:Declaring global variables
2023-01-19 21:06:46,498:INFO:USI: b017
2023-01-19 21:06:46,498:INFO:pycaret_globals: {'_gpu_n_jobs_param', 'y_test', 'fold_shuffle_param', 'seed', 'experiment__', '_available_plots', 'log_plots_param', '_all_models', 'fix_imbalance_param', 'gpu_param', 'iterative_imputation_iters_param', 'display_container', '_all_models_internal', 'transform_target_method_param', 'data_before_preprocess', 'y_train', 'exp_name_log', 'imputation_classifier', 'USI', '_internal_pipeline', 'fix_imbalance_method_param', 'logging_param', '_ml_usecase', 'target_param', 'n_jobs_param', 'X', 'y', 'fold_generator', 'stratify_param', '_all_metrics', 'X_test', 'fold_param', 'pycaret_globals', 'X_train', 'imputation_regressor', 'transform_target_param', 'master_model_container', 'create_model_container', 'html_param', 'fold_groups_param', 'prep_pipe'}
2023-01-19 21:06:46,498:INFO:Preparing display monitor
2023-01-19 21:06:46,500:INFO:Preparing display monitor
2023-01-19 21:06:46,553:INFO:Importing libraries
2023-01-19 21:06:46,554:INFO:Copying data for preprocessing
2023-01-19 21:06:46,561:INFO:Declaring preprocessing parameters
2023-01-19 21:06:46,565:INFO:Creating preprocessing pipeline
2023-01-19 21:06:46,720:INFO:Preprocessing pipeline created successfully
2023-01-19 21:06:46,720:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-01-19 21:06:46,720:INFO:Creating global containers
2023-01-19 21:06:46,724:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-01-19 21:06:51,430:INFO:Creating grid variables
2023-01-19 21:06:51,444:INFO:create_model_container: 0
2023-01-19 21:06:51,444:INFO:master_model_container: 0
2023-01-19 21:06:51,445:INFO:display_container: 0
2023-01-19 21:08:40,310:INFO:PyCaret Supervised Module
2023-01-19 21:08:40,313:INFO:ML Usecase: classification
2023-01-19 21:08:40,313:INFO:version 2.2.2
2023-01-19 21:08:40,314:INFO:Initializing setup()
2023-01-19 21:08:40,314:INFO:setup(target=SalePrice, ml_usecase=classification, available_plots={'parameter': 'Hyperparameters', 'auc': 'AUC', 'confusion_matrix': 'Confusion Matrix', 'threshold': 'Threshold', 'pr': 'Precision Recall', 'error': 'Prediction Error', 'class_report': 'Class Report', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'calibration': 'Calibration Curve', 'vc': 'Validation Curve', 'dimension': 'Dimensions', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'boundary': 'Decision Boundary', 'lift': 'Lift Chart', 'gain': 'Gain Chart', 'tree': 'Decision Tree'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=None, normalize=False, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=stratifiedkfold, fold=10, fold_shuffle=True, fold_groups=None, n_jobs=-1, use_gpu=False, custom_pipeline=None, html=True, session_id=None, log_experiment=False, experiment_name=None, log_plots=False, log_profile=False, log_data=False, silent=False, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-01-19 21:08:40,314:INFO:Checking environment
2023-01-19 21:08:40,314:INFO:python_version: 3.9.12
2023-01-19 21:08:40,314:INFO:python_build: ('main', 'Apr  5 2022 01:53:17')
2023-01-19 21:08:40,314:INFO:machine: x86_64
2023-01-19 21:08:40,314:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-01-19 21:08:40,315:INFO:Memory: svmem(total=8589934592, available=2587693056, percent=69.9, used=5716480000, free=268587008, active=2323898368, inactive=2255855616, wired=3392581632)
2023-01-19 21:08:40,315:INFO:Physical Core: 4
2023-01-19 21:08:40,315:INFO:Logical Core: 8
2023-01-19 21:08:40,315:INFO:Checking libraries
2023-01-19 21:08:40,315:INFO:pd==1.4.2
2023-01-19 21:08:40,315:INFO:numpy==1.21.5
2023-01-19 21:08:40,315:INFO:sklearn==1.0.2
2023-01-19 21:08:40,315:INFO:xgboost==1.7.2
2023-01-19 21:08:40,315:INFO:lightgbm==3.3.3
2023-01-19 21:08:40,315:INFO:catboost==1.1.1
2023-01-19 21:08:40,316:INFO:mlflow==2.0.1
2023-01-19 21:08:40,316:INFO:Checking Exceptions
2023-01-19 21:08:40,316:INFO:Declaring global variables
2023-01-19 21:08:40,316:INFO:USI: 3938
2023-01-19 21:08:40,318:INFO:pycaret_globals: {'_gpu_n_jobs_param', 'y_test', 'fold_shuffle_param', 'seed', 'experiment__', '_available_plots', 'log_plots_param', '_all_models', 'fix_imbalance_param', 'gpu_param', 'iterative_imputation_iters_param', 'display_container', '_all_models_internal', 'transform_target_method_param', 'data_before_preprocess', 'y_train', 'exp_name_log', 'imputation_classifier', 'USI', '_internal_pipeline', 'fix_imbalance_method_param', 'logging_param', '_ml_usecase', 'target_param', 'n_jobs_param', 'X', 'y', 'fold_generator', 'stratify_param', '_all_metrics', 'X_test', 'fold_param', 'pycaret_globals', 'X_train', 'imputation_regressor', 'transform_target_param', 'master_model_container', 'create_model_container', 'html_param', 'fold_groups_param', 'prep_pipe'}
2023-01-19 21:08:40,318:INFO:Preparing display monitor
2023-01-19 21:08:40,318:INFO:Preparing display monitor
2023-01-19 21:08:40,342:INFO:Importing libraries
2023-01-19 21:08:40,343:INFO:Copying data for preprocessing
2023-01-19 21:08:40,353:INFO:Declaring preprocessing parameters
2023-01-19 21:08:40,357:INFO:Creating preprocessing pipeline
2023-01-19 21:08:40,508:INFO:Preprocessing pipeline created successfully
2023-01-19 21:08:40,508:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-01-19 21:08:40,509:INFO:Creating global containers
2023-01-19 21:08:40,509:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-01-19 21:08:44,406:INFO:Creating grid variables
2023-01-19 21:08:44,420:INFO:create_model_container: 0
2023-01-19 21:08:44,420:INFO:master_model_container: 0
2023-01-19 21:08:44,420:INFO:display_container: 0
2023-01-19 21:11:12,920:INFO:PyCaret Supervised Module
2023-01-19 21:11:12,921:INFO:ML Usecase: classification
2023-01-19 21:11:12,921:INFO:version 2.2.2
2023-01-19 21:11:12,922:INFO:Initializing setup()
2023-01-19 21:11:12,922:INFO:setup(target=SalePrice, ml_usecase=classification, available_plots={'parameter': 'Hyperparameters', 'auc': 'AUC', 'confusion_matrix': 'Confusion Matrix', 'threshold': 'Threshold', 'pr': 'Precision Recall', 'error': 'Prediction Error', 'class_report': 'Class Report', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'calibration': 'Calibration Curve', 'vc': 'Validation Curve', 'dimension': 'Dimensions', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'boundary': 'Decision Boundary', 'lift': 'Lift Chart', 'gain': 'Gain Chart', 'tree': 'Decision Tree'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=None, normalize=False, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=stratifiedkfold, fold=10, fold_shuffle=True, fold_groups=None, n_jobs=-1, use_gpu=False, custom_pipeline=None, html=True, session_id=None, log_experiment=False, experiment_name=None, log_plots=False, log_profile=False, log_data=False, silent=False, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-01-19 21:11:12,922:INFO:Checking environment
2023-01-19 21:11:12,922:INFO:python_version: 3.9.12
2023-01-19 21:11:12,922:INFO:python_build: ('main', 'Apr  5 2022 01:53:17')
2023-01-19 21:11:12,922:INFO:machine: x86_64
2023-01-19 21:11:12,922:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-01-19 21:11:12,922:INFO:Memory: svmem(total=8589934592, available=2550521856, percent=70.3, used=5836849152, free=71639040, active=2440421376, inactive=2411503616, wired=3396427776)
2023-01-19 21:11:12,922:INFO:Physical Core: 4
2023-01-19 21:11:12,922:INFO:Logical Core: 8
2023-01-19 21:11:12,922:INFO:Checking libraries
2023-01-19 21:11:12,922:INFO:pd==1.4.2
2023-01-19 21:11:12,922:INFO:numpy==1.21.5
2023-01-19 21:11:12,922:INFO:sklearn==1.0.2
2023-01-19 21:11:12,923:INFO:xgboost==1.7.2
2023-01-19 21:11:12,923:INFO:lightgbm==3.3.3
2023-01-19 21:11:12,923:INFO:catboost==1.1.1
2023-01-19 21:11:12,923:INFO:mlflow==2.0.1
2023-01-19 21:11:12,923:INFO:Checking Exceptions
2023-01-19 21:11:12,923:INFO:Declaring global variables
2023-01-19 21:11:12,923:INFO:USI: fe78
2023-01-19 21:11:12,923:INFO:pycaret_globals: {'_gpu_n_jobs_param', 'y_test', 'fold_shuffle_param', 'seed', 'experiment__', '_available_plots', 'log_plots_param', '_all_models', 'fix_imbalance_param', 'gpu_param', 'iterative_imputation_iters_param', 'display_container', '_all_models_internal', 'transform_target_method_param', 'data_before_preprocess', 'y_train', 'exp_name_log', 'imputation_classifier', 'USI', '_internal_pipeline', 'fix_imbalance_method_param', 'logging_param', '_ml_usecase', 'target_param', 'n_jobs_param', 'X', 'y', 'fold_generator', 'stratify_param', '_all_metrics', 'X_test', 'fold_param', 'pycaret_globals', 'X_train', 'imputation_regressor', 'transform_target_param', 'master_model_container', 'create_model_container', 'html_param', 'fold_groups_param', 'prep_pipe'}
2023-01-19 21:11:12,923:INFO:Preparing display monitor
2023-01-19 21:11:12,924:INFO:Preparing display monitor
2023-01-19 21:11:12,943:INFO:Importing libraries
2023-01-19 21:11:12,943:INFO:Copying data for preprocessing
2023-01-19 21:11:12,953:INFO:Declaring preprocessing parameters
2023-01-19 21:11:12,956:INFO:Creating preprocessing pipeline
2023-01-19 21:11:13,035:INFO:Preprocessing pipeline created successfully
2023-01-19 21:11:13,035:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-01-19 21:11:13,035:INFO:Creating global containers
2023-01-19 21:11:13,036:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-01-19 21:11:16,672:INFO:Creating grid variables
2023-01-19 21:11:16,683:INFO:create_model_container: 0
2023-01-19 21:11:16,683:INFO:master_model_container: 0
2023-01-19 21:11:16,684:INFO:display_container: 0
2023-01-19 21:42:20,634:INFO:PyCaret Supervised Module
2023-01-19 21:42:20,640:INFO:ML Usecase: classification
2023-01-19 21:42:20,640:INFO:version 2.2.2
2023-01-19 21:42:20,641:INFO:Initializing setup()
2023-01-19 21:42:20,641:INFO:setup(target=SalePrice, ml_usecase=classification, available_plots={'parameter': 'Hyperparameters', 'auc': 'AUC', 'confusion_matrix': 'Confusion Matrix', 'threshold': 'Threshold', 'pr': 'Precision Recall', 'error': 'Prediction Error', 'class_report': 'Class Report', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'calibration': 'Calibration Curve', 'vc': 'Validation Curve', 'dimension': 'Dimensions', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'boundary': 'Decision Boundary', 'lift': 'Lift Chart', 'gain': 'Gain Chart', 'tree': 'Decision Tree'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=None, normalize=False, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=stratifiedkfold, fold=10, fold_shuffle=True, fold_groups=None, n_jobs=-1, use_gpu=False, custom_pipeline=None, html=True, session_id=None, log_experiment=False, experiment_name=None, log_plots=False, log_profile=False, log_data=False, silent=False, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-01-19 21:42:20,641:INFO:Checking environment
2023-01-19 21:42:20,642:INFO:python_version: 3.9.12
2023-01-19 21:42:20,642:INFO:python_build: ('main', 'Apr  5 2022 01:53:17')
2023-01-19 21:42:20,642:INFO:machine: x86_64
2023-01-19 21:42:20,642:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-01-19 21:42:20,645:INFO:Memory: svmem(total=8589934592, available=2294661120, percent=73.3, used=5297074176, free=402411520, active=1893978112, inactive=1792479232, wired=3403096064)
2023-01-19 21:42:20,647:INFO:Physical Core: 4
2023-01-19 21:42:20,647:INFO:Logical Core: 8
2023-01-19 21:42:20,647:INFO:Checking libraries
2023-01-19 21:42:20,647:INFO:pd==1.4.2
2023-01-19 21:42:20,647:INFO:numpy==1.21.5
2023-01-19 21:42:20,648:INFO:sklearn==1.0.2
2023-01-19 21:42:20,648:INFO:xgboost==1.7.2
2023-01-19 21:42:20,649:INFO:lightgbm==3.3.3
2023-01-19 21:42:20,649:INFO:catboost==1.1.1
2023-01-19 21:42:20,650:INFO:mlflow==2.0.1
2023-01-19 21:42:20,650:INFO:Checking Exceptions
2023-01-19 21:42:20,652:INFO:Declaring global variables
2023-01-19 21:42:20,653:INFO:USI: c96a
2023-01-19 21:42:20,654:INFO:pycaret_globals: {'_gpu_n_jobs_param', 'y_test', 'fold_shuffle_param', 'seed', 'experiment__', '_available_plots', 'log_plots_param', '_all_models', 'fix_imbalance_param', 'gpu_param', 'iterative_imputation_iters_param', 'display_container', '_all_models_internal', 'transform_target_method_param', 'data_before_preprocess', 'y_train', 'exp_name_log', 'imputation_classifier', 'USI', '_internal_pipeline', 'fix_imbalance_method_param', 'logging_param', '_ml_usecase', 'target_param', 'n_jobs_param', 'X', 'y', 'fold_generator', 'stratify_param', '_all_metrics', 'X_test', 'fold_param', 'pycaret_globals', 'X_train', 'imputation_regressor', 'transform_target_param', 'master_model_container', 'create_model_container', 'html_param', 'fold_groups_param', 'prep_pipe'}
2023-01-19 21:42:20,654:INFO:Preparing display monitor
2023-01-19 21:42:20,657:INFO:Preparing display monitor
2023-01-19 21:42:20,750:INFO:Importing libraries
2023-01-19 21:42:20,751:INFO:Copying data for preprocessing
2023-01-19 21:42:20,772:INFO:Declaring preprocessing parameters
2023-01-19 21:42:20,779:INFO:Creating preprocessing pipeline
2023-01-19 21:42:20,961:INFO:Preprocessing pipeline created successfully
2023-01-19 21:42:20,961:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-01-19 21:42:20,961:INFO:Creating global containers
2023-01-19 21:42:20,969:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-01-19 21:42:32,595:INFO:Creating grid variables
2023-01-19 21:42:32,751:INFO:create_model_container: 0
2023-01-19 21:42:32,751:INFO:master_model_container: 0
2023-01-19 21:42:32,752:INFO:display_container: 0
2023-01-19 21:42:51,960:INFO:PyCaret Supervised Module
2023-01-19 21:42:51,960:INFO:ML Usecase: classification
2023-01-19 21:42:51,961:INFO:version 2.2.2
2023-01-19 21:42:51,961:INFO:Initializing setup()
2023-01-19 21:42:51,961:INFO:setup(target=SalePrice, ml_usecase=classification, available_plots={'parameter': 'Hyperparameters', 'auc': 'AUC', 'confusion_matrix': 'Confusion Matrix', 'threshold': 'Threshold', 'pr': 'Precision Recall', 'error': 'Prediction Error', 'class_report': 'Class Report', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'calibration': 'Calibration Curve', 'vc': 'Validation Curve', 'dimension': 'Dimensions', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'boundary': 'Decision Boundary', 'lift': 'Lift Chart', 'gain': 'Gain Chart', 'tree': 'Decision Tree'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=None, normalize=False, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=stratifiedkfold, fold=10, fold_shuffle=True, fold_groups=None, n_jobs=-1, use_gpu=False, custom_pipeline=None, html=True, session_id=None, log_experiment=False, experiment_name=None, log_plots=False, log_profile=False, log_data=False, silent=False, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-01-19 21:42:51,961:INFO:Checking environment
2023-01-19 21:42:51,961:INFO:python_version: 3.9.12
2023-01-19 21:42:51,961:INFO:python_build: ('main', 'Apr  5 2022 01:53:17')
2023-01-19 21:42:51,961:INFO:machine: x86_64
2023-01-19 21:42:51,961:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-01-19 21:42:51,961:INFO:Memory: svmem(total=8589934592, available=2583326720, percent=69.9, used=5603844096, free=435802112, active=2149908480, inactive=2088890368, wired=3453935616)
2023-01-19 21:42:51,962:INFO:Physical Core: 4
2023-01-19 21:42:51,962:INFO:Logical Core: 8
2023-01-19 21:42:51,962:INFO:Checking libraries
2023-01-19 21:42:51,962:INFO:pd==1.4.2
2023-01-19 21:42:51,962:INFO:numpy==1.21.5
2023-01-19 21:42:51,962:INFO:sklearn==1.0.2
2023-01-19 21:42:51,962:INFO:xgboost==1.7.2
2023-01-19 21:42:51,962:INFO:lightgbm==3.3.3
2023-01-19 21:42:51,963:INFO:catboost==1.1.1
2023-01-19 21:42:51,963:INFO:mlflow==2.0.1
2023-01-19 21:42:51,963:INFO:Checking Exceptions
2023-01-19 21:42:51,964:INFO:Declaring global variables
2023-01-19 21:42:51,964:INFO:USI: 01b2
2023-01-19 21:42:51,965:INFO:pycaret_globals: {'_gpu_n_jobs_param', 'y_test', 'fold_shuffle_param', 'seed', 'experiment__', '_available_plots', 'log_plots_param', '_all_models', 'fix_imbalance_param', 'gpu_param', 'iterative_imputation_iters_param', 'display_container', '_all_models_internal', 'transform_target_method_param', 'data_before_preprocess', 'y_train', 'exp_name_log', 'imputation_classifier', 'USI', '_internal_pipeline', 'fix_imbalance_method_param', 'logging_param', '_ml_usecase', 'target_param', 'n_jobs_param', 'X', 'y', 'fold_generator', 'stratify_param', '_all_metrics', 'X_test', 'fold_param', 'pycaret_globals', 'X_train', 'imputation_regressor', 'transform_target_param', 'master_model_container', 'create_model_container', 'html_param', 'fold_groups_param', 'prep_pipe'}
2023-01-19 21:42:51,965:INFO:Preparing display monitor
2023-01-19 21:42:51,965:INFO:Preparing display monitor
2023-01-19 21:42:51,988:INFO:Importing libraries
2023-01-19 21:42:51,988:INFO:Copying data for preprocessing
2023-01-19 21:42:52,007:INFO:Declaring preprocessing parameters
2023-01-19 21:42:52,010:INFO:Creating preprocessing pipeline
2023-01-19 21:42:52,201:INFO:Preprocessing pipeline created successfully
2023-01-19 21:42:52,201:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-01-19 21:42:52,201:INFO:Creating global containers
2023-01-19 21:42:52,202:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-01-19 21:42:57,331:INFO:Creating grid variables
2023-01-19 21:42:57,347:INFO:create_model_container: 0
2023-01-19 21:42:57,347:INFO:master_model_container: 0
2023-01-19 21:42:57,347:INFO:display_container: 0
2023-01-19 22:31:42,856:INFO:PyCaret Supervised Module
2023-01-19 22:31:42,858:INFO:ML Usecase: classification
2023-01-19 22:31:42,858:INFO:version 2.2.2
2023-01-19 22:31:42,858:INFO:Initializing setup()
2023-01-19 22:31:42,858:INFO:setup(target=SalePrice, ml_usecase=classification, available_plots={'parameter': 'Hyperparameters', 'auc': 'AUC', 'confusion_matrix': 'Confusion Matrix', 'threshold': 'Threshold', 'pr': 'Precision Recall', 'error': 'Prediction Error', 'class_report': 'Class Report', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'calibration': 'Calibration Curve', 'vc': 'Validation Curve', 'dimension': 'Dimensions', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'boundary': 'Decision Boundary', 'lift': 'Lift Chart', 'gain': 'Gain Chart', 'tree': 'Decision Tree'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=None, normalize=False, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=stratifiedkfold, fold=10, fold_shuffle=True, fold_groups=None, n_jobs=-1, use_gpu=False, custom_pipeline=None, html=True, session_id=None, log_experiment=False, experiment_name=None, log_plots=False, log_profile=False, log_data=False, silent=False, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-01-19 22:31:42,859:INFO:Checking environment
2023-01-19 22:31:42,859:INFO:python_version: 3.9.12
2023-01-19 22:31:42,859:INFO:python_build: ('main', 'Apr  5 2022 01:53:17')
2023-01-19 22:31:42,859:INFO:machine: x86_64
2023-01-19 22:31:42,859:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-01-19 22:31:42,859:INFO:Memory: svmem(total=8589934592, available=2482581504, percent=71.1, used=5524643840, free=92577792, active=2280468480, inactive=2041954304, wired=3244175360)
2023-01-19 22:31:42,859:INFO:Physical Core: 4
2023-01-19 22:31:42,859:INFO:Logical Core: 8
2023-01-19 22:31:42,859:INFO:Checking libraries
2023-01-19 22:31:42,859:INFO:pd==1.5.3
2023-01-19 22:31:42,859:INFO:numpy==1.23.5
2023-01-19 22:31:42,859:INFO:sklearn==1.2.0
2023-01-19 22:31:43,223:INFO:xgboost==1.7.3
2023-01-19 22:31:43,223:INFO:lightgbm==3.3.4
2023-01-19 22:31:43,801:INFO:catboost==1.1.1
2023-01-19 22:31:44,639:INFO:mlflow==2.1.1
2023-01-19 22:31:44,639:INFO:Checking Exceptions
2023-01-19 22:31:44,640:INFO:Declaring global variables
2023-01-19 22:31:44,641:INFO:USI: cd60
2023-01-19 22:31:44,641:INFO:pycaret_globals: {'imputation_regressor', '_available_plots', 'fold_groups_param', 'pycaret_globals', 'logging_param', '_all_metrics', '_all_models', 'y_train', 'experiment__', 'fold_param', 'seed', '_all_models_internal', 'create_model_container', 'transform_target_method_param', 'X_train', 'transform_target_param', '_ml_usecase', 'log_plots_param', 'data_before_preprocess', 'y', 'iterative_imputation_iters_param', 'X', 'X_test', 'fix_imbalance_param', 'target_param', 'fold_shuffle_param', 'n_jobs_param', 'fold_generator', '_gpu_n_jobs_param', 'fix_imbalance_method_param', '_internal_pipeline', 'html_param', 'gpu_param', 'prep_pipe', 'exp_name_log', 'imputation_classifier', 'master_model_container', 'y_test', 'display_container', 'stratify_param', 'USI'}
2023-01-19 22:31:44,641:INFO:Preparing display monitor
2023-01-19 22:31:44,641:INFO:Preparing display monitor
2023-01-19 22:31:44,659:INFO:Importing libraries
2023-01-19 22:31:44,660:INFO:Copying data for preprocessing
2023-01-19 22:31:44,673:INFO:Declaring preprocessing parameters
2023-01-19 22:31:44,677:INFO:Creating preprocessing pipeline
2023-01-19 22:31:44,780:INFO:Preprocessing pipeline created successfully
2023-01-19 22:31:44,780:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-01-19 22:31:44,781:INFO:Creating global containers
2023-01-19 22:31:44,783:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-01-19 23:03:49,629:INFO:PyCaret Supervised Module
2023-01-19 23:03:49,634:INFO:ML Usecase: classification
2023-01-19 23:03:49,635:INFO:version 2.2.2
2023-01-19 23:03:49,635:INFO:Initializing setup()
2023-01-19 23:03:49,635:INFO:setup(target=SalePrice, ml_usecase=classification, available_plots={'parameter': 'Hyperparameters', 'auc': 'AUC', 'confusion_matrix': 'Confusion Matrix', 'threshold': 'Threshold', 'pr': 'Precision Recall', 'error': 'Prediction Error', 'class_report': 'Class Report', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'calibration': 'Calibration Curve', 'vc': 'Validation Curve', 'dimension': 'Dimensions', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'boundary': 'Decision Boundary', 'lift': 'Lift Chart', 'gain': 'Gain Chart', 'tree': 'Decision Tree'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=None, normalize=False, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=stratifiedkfold, fold=10, fold_shuffle=True, fold_groups=None, n_jobs=-1, use_gpu=False, custom_pipeline=None, html=True, session_id=None, log_experiment=False, experiment_name=None, log_plots=False, log_profile=False, log_data=False, silent=False, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-01-19 23:03:49,635:INFO:Checking environment
2023-01-19 23:03:49,638:INFO:python_version: 3.9.12
2023-01-19 23:03:49,639:INFO:python_build: ('main', 'Apr  5 2022 01:53:17')
2023-01-19 23:03:49,641:INFO:machine: x86_64
2023-01-19 23:03:49,642:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-01-19 23:03:49,651:INFO:Memory: svmem(total=8589934592, available=2025013248, percent=76.4, used=5572980736, free=17604608, active=2010914816, inactive=2005626880, wired=3562065920)
2023-01-19 23:03:49,652:INFO:Physical Core: 4
2023-01-19 23:03:49,653:INFO:Logical Core: 8
2023-01-19 23:03:49,653:INFO:Checking libraries
2023-01-19 23:03:49,653:INFO:pd==1.5.3
2023-01-19 23:03:49,655:INFO:numpy==1.23.5
2023-01-19 23:03:49,658:INFO:sklearn==1.2.0
2023-01-19 23:03:49,659:INFO:xgboost==1.7.3
2023-01-19 23:03:49,660:INFO:lightgbm==3.3.4
2023-01-19 23:03:49,660:INFO:catboost==1.1.1
2023-01-19 23:03:49,660:INFO:mlflow==2.1.1
2023-01-19 23:03:49,660:INFO:Checking Exceptions
2023-01-19 23:03:49,664:INFO:Declaring global variables
2023-01-19 23:03:49,670:INFO:USI: 78ea
2023-01-19 23:03:49,671:INFO:pycaret_globals: {'imputation_regressor', '_available_plots', 'fold_groups_param', 'pycaret_globals', 'logging_param', '_all_metrics', '_all_models', 'y_train', 'experiment__', 'fold_param', 'seed', '_all_models_internal', 'create_model_container', 'transform_target_method_param', 'X_train', 'transform_target_param', '_ml_usecase', 'log_plots_param', 'data_before_preprocess', 'y', 'iterative_imputation_iters_param', 'X', 'X_test', 'fix_imbalance_param', 'target_param', 'fold_shuffle_param', 'n_jobs_param', 'fold_generator', '_gpu_n_jobs_param', 'fix_imbalance_method_param', '_internal_pipeline', 'html_param', 'gpu_param', 'prep_pipe', 'exp_name_log', 'imputation_classifier', 'master_model_container', 'y_test', 'display_container', 'stratify_param', 'USI'}
2023-01-19 23:03:49,671:INFO:Preparing display monitor
2023-01-19 23:03:49,678:INFO:Preparing display monitor
2023-01-19 23:03:49,797:INFO:Importing libraries
2023-01-19 23:03:49,798:INFO:Copying data for preprocessing
2023-01-19 23:03:49,814:INFO:Declaring preprocessing parameters
2023-01-19 23:03:49,822:INFO:Creating preprocessing pipeline
2023-01-19 23:03:49,999:INFO:Preprocessing pipeline created successfully
2023-01-19 23:03:50,005:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-01-19 23:03:50,005:INFO:Creating global containers
2023-01-19 23:03:50,015:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-01-19 23:06:32,505:INFO:PyCaret Supervised Module
2023-01-19 23:06:32,506:INFO:ML Usecase: classification
2023-01-19 23:06:32,507:INFO:version 2.2.2
2023-01-19 23:06:32,507:INFO:Initializing setup()
2023-01-19 23:06:32,507:INFO:setup(target=SalePrice, ml_usecase=classification, available_plots={'parameter': 'Hyperparameters', 'auc': 'AUC', 'confusion_matrix': 'Confusion Matrix', 'threshold': 'Threshold', 'pr': 'Precision Recall', 'error': 'Prediction Error', 'class_report': 'Class Report', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'calibration': 'Calibration Curve', 'vc': 'Validation Curve', 'dimension': 'Dimensions', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'boundary': 'Decision Boundary', 'lift': 'Lift Chart', 'gain': 'Gain Chart', 'tree': 'Decision Tree'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=None, normalize=False, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=stratifiedkfold, fold=10, fold_shuffle=True, fold_groups=None, n_jobs=-1, use_gpu=False, custom_pipeline=None, html=True, session_id=None, log_experiment=False, experiment_name=None, log_plots=False, log_profile=False, log_data=False, silent=False, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-01-19 23:06:32,507:INFO:Checking environment
2023-01-19 23:06:32,507:INFO:python_version: 3.9.12
2023-01-19 23:06:32,507:INFO:python_build: ('main', 'Apr  5 2022 01:53:17')
2023-01-19 23:06:32,507:INFO:machine: x86_64
2023-01-19 23:06:32,507:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-01-19 23:06:32,509:INFO:Memory: svmem(total=8589934592, available=737382400, percent=91.4, used=4301041664, free=14651392, active=726347776, inactive=678359040, wired=3574693888)
2023-01-19 23:06:32,510:INFO:Physical Core: 4
2023-01-19 23:06:32,510:INFO:Logical Core: 8
2023-01-19 23:06:32,510:INFO:Checking libraries
2023-01-19 23:06:32,510:INFO:pd==1.5.3
2023-01-19 23:06:32,510:INFO:numpy==1.23.5
2023-01-19 23:06:32,510:INFO:sklearn==1.2.0
2023-01-19 23:06:32,510:INFO:xgboost==1.7.3
2023-01-19 23:06:32,510:INFO:lightgbm==3.3.4
2023-01-19 23:06:32,513:INFO:catboost==1.1.1
2023-01-19 23:06:32,514:INFO:mlflow==2.1.1
2023-01-19 23:06:32,514:INFO:Checking Exceptions
2023-01-19 23:06:32,515:INFO:Declaring global variables
2023-01-19 23:06:32,517:INFO:USI: e422
2023-01-19 23:06:32,518:INFO:pycaret_globals: {'imputation_regressor', '_available_plots', 'fold_groups_param', 'pycaret_globals', 'logging_param', '_all_metrics', '_all_models', 'y_train', 'experiment__', 'fold_param', 'seed', '_all_models_internal', 'create_model_container', 'transform_target_method_param', 'X_train', 'transform_target_param', '_ml_usecase', 'log_plots_param', 'data_before_preprocess', 'y', 'iterative_imputation_iters_param', 'X', 'X_test', 'fix_imbalance_param', 'target_param', 'fold_shuffle_param', 'n_jobs_param', 'fold_generator', '_gpu_n_jobs_param', 'fix_imbalance_method_param', '_internal_pipeline', 'html_param', 'gpu_param', 'prep_pipe', 'exp_name_log', 'imputation_classifier', 'master_model_container', 'y_test', 'display_container', 'stratify_param', 'USI'}
2023-01-19 23:06:32,518:INFO:Preparing display monitor
2023-01-19 23:06:32,518:INFO:Preparing display monitor
2023-01-19 23:06:32,586:INFO:Importing libraries
2023-01-19 23:06:32,589:INFO:Copying data for preprocessing
2023-01-19 23:06:32,623:INFO:Declaring preprocessing parameters
2023-01-19 23:06:32,633:INFO:Creating preprocessing pipeline
2023-01-19 23:06:32,969:INFO:Preprocessing pipeline created successfully
2023-01-19 23:06:33,011:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-01-19 23:06:33,016:INFO:Creating global containers
2023-01-19 23:06:33,019:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-01-19 23:07:45,649:INFO:PyCaret Supervised Module
2023-01-19 23:07:45,672:INFO:ML Usecase: classification
2023-01-19 23:07:45,673:INFO:version 2.2.2
2023-01-19 23:07:45,673:INFO:Initializing setup()
2023-01-19 23:07:45,673:INFO:setup(target=SalePrice, ml_usecase=classification, available_plots={'parameter': 'Hyperparameters', 'auc': 'AUC', 'confusion_matrix': 'Confusion Matrix', 'threshold': 'Threshold', 'pr': 'Precision Recall', 'error': 'Prediction Error', 'class_report': 'Class Report', 'rfe': 'Feature Selection', 'learning': 'Learning Curve', 'manifold': 'Manifold Learning', 'calibration': 'Calibration Curve', 'vc': 'Validation Curve', 'dimension': 'Dimensions', 'feature': 'Feature Importance', 'feature_all': 'Feature Importance (All)', 'boundary': 'Decision Boundary', 'lift': 'Lift Chart', 'gain': 'Gain Chart', 'tree': 'Decision Tree'}, train_size=0.7, test_data=None, preprocess=True, imputation_type=simple, iterative_imputation_iters=5, categorical_features=None, categorical_imputation=constant, categorical_iterative_imputer=lightgbm, ordinal_features=None, high_cardinality_features=None, high_cardinality_method=frequency, numeric_features=None, numeric_imputation=mean, numeric_iterative_imputer=lightgbm, date_features=None, ignore_features=None, normalize=False, normalize_method=zscore, transformation=False, transformation_method=yeo-johnson, handle_unknown_categorical=True, unknown_categorical_method=least_frequent, pca=False, pca_method=linear, pca_components=None, ignore_low_variance=False, combine_rare_levels=False, rare_level_threshold=0.1, bin_numeric_features=None, remove_outliers=False, outliers_threshold=0.05, remove_multicollinearity=False, multicollinearity_threshold=0.9, remove_perfect_collinearity=True, create_clusters=False, cluster_iter=20, polynomial_features=False, polynomial_degree=2, trigonometry_features=False, polynomial_threshold=0.1, group_features=None, group_names=None, feature_selection=False, feature_selection_threshold=0.8, feature_selection_method=classic, feature_interaction=False, feature_ratio=False, interaction_threshold=0.01, fix_imbalance=False, fix_imbalance_method=None, transform_target=False, transform_target_method=box-cox, data_split_shuffle=True, data_split_stratify=False, fold_strategy=stratifiedkfold, fold=10, fold_shuffle=True, fold_groups=None, n_jobs=-1, use_gpu=False, custom_pipeline=None, html=True, session_id=None, log_experiment=False, experiment_name=None, log_plots=False, log_profile=False, log_data=False, silent=False, verbose=True, profile=False, profile_kwargs=None, display=None)
2023-01-19 23:07:45,673:INFO:Checking environment
2023-01-19 23:07:45,673:INFO:python_version: 3.9.12
2023-01-19 23:07:45,673:INFO:python_build: ('main', 'Apr  5 2022 01:53:17')
2023-01-19 23:07:45,673:INFO:machine: x86_64
2023-01-19 23:07:45,673:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-01-19 23:07:45,674:INFO:Memory: svmem(total=8589934592, available=2432434176, percent=71.7, used=5174005760, free=747630592, active=1688559616, inactive=1537638400, wired=3485446144)
2023-01-19 23:07:45,674:INFO:Physical Core: 4
2023-01-19 23:07:45,674:INFO:Logical Core: 8
2023-01-19 23:07:45,674:INFO:Checking libraries
2023-01-19 23:07:45,674:INFO:pd==1.5.3
2023-01-19 23:07:45,674:INFO:numpy==1.24.1
2023-01-19 23:07:45,674:INFO:sklearn==1.0.2
2023-01-19 23:07:45,723:INFO:xgboost==1.7.3
2023-01-19 23:07:45,723:INFO:lightgbm==3.3.4
2023-01-19 23:07:45,796:INFO:catboost==1.1.1
2023-01-19 23:07:46,573:INFO:mlflow==2.1.1
2023-01-19 23:07:46,573:INFO:Checking Exceptions
2023-01-19 23:07:46,574:INFO:Declaring global variables
2023-01-19 23:07:46,574:INFO:USI: 379d
2023-01-19 23:07:46,574:INFO:pycaret_globals: {'fold_param', 'stratify_param', 'transform_target_method_param', 'USI', 'fold_groups_param', 'html_param', 'fix_imbalance_param', 'exp_name_log', 'fix_imbalance_method_param', 'imputation_regressor', '_gpu_n_jobs_param', 'imputation_classifier', 'iterative_imputation_iters_param', 'fold_shuffle_param', 'target_param', 'seed', 'prep_pipe', 'y', 'data_before_preprocess', 'transform_target_param', 'fold_generator', 'X', 'X_train', 'log_plots_param', 'n_jobs_param', 'y_test', 'master_model_container', 'display_container', '_ml_usecase', 'y_train', '_available_plots', 'create_model_container', '_internal_pipeline', '_all_metrics', 'gpu_param', '_all_models_internal', 'logging_param', 'pycaret_globals', '_all_models', 'experiment__', 'X_test'}
2023-01-19 23:07:46,574:INFO:Preparing display monitor
2023-01-19 23:07:46,574:INFO:Preparing display monitor
2023-01-19 23:07:46,591:INFO:Importing libraries
2023-01-19 23:07:46,591:INFO:Copying data for preprocessing
2023-01-19 23:07:46,603:INFO:Declaring preprocessing parameters
2023-01-19 23:07:46,606:INFO:Creating preprocessing pipeline
2023-01-19 23:07:46,703:INFO:Preprocessing pipeline created successfully
2023-01-19 23:07:46,703:ERROR:(Process Exit): setup has been interupted with user command 'quit'. setup must rerun.
2023-01-19 23:07:46,703:INFO:Creating global containers
2023-01-19 23:07:46,705:INFO:Internal pipeline: Pipeline(memory=None, steps=[('empty_step', 'passthrough')], verbose=False)
2023-01-19 23:07:51,557:INFO:Creating grid variables
2023-01-19 23:07:51,570:INFO:create_model_container: 0
2023-01-19 23:07:51,570:INFO:master_model_container: 0
2023-01-19 23:07:51,570:INFO:display_container: 0
2023-01-19 23:19:59,649:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-19 23:19:59,652:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-19 23:19:59,652:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-19 23:19:59,652:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-19 23:20:07,259:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-01-19 23:20:10,912:INFO:PyCaret ClassificationExperiment
2023-01-19 23:20:10,912:INFO:Logging name: clf-default-name
2023-01-19 23:20:10,912:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-01-19 23:20:10,912:INFO:version 3.0.0.rc8
2023-01-19 23:20:10,912:INFO:Initializing setup()
2023-01-19 23:20:10,912:INFO:self.USI: 9231
2023-01-19 23:20:10,912:INFO:self._variable_keys: {'exp_id', 'logging_param', 'fold_groups_param', 'seed', 'exp_name_log', 'pipeline', 'X', 'fix_imbalance', 'gpu_n_jobs_param', 'y_test', 'fold_generator', 'log_plots_param', 'n_jobs_param', '_ml_usecase', 'y', 'fold_shuffle_param', 'y_train', '_available_plots', 'X_train', 'is_multiclass', 'X_test', 'memory', 'USI', 'html_param', 'data', 'gpu_param', 'target_param', 'idx'}
2023-01-19 23:20:10,912:INFO:Checking environment
2023-01-19 23:20:10,912:INFO:python_version: 3.9.12
2023-01-19 23:20:10,912:INFO:python_build: ('main', 'Apr  5 2022 01:53:17')
2023-01-19 23:20:10,912:INFO:machine: x86_64
2023-01-19 23:20:10,912:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-01-19 23:20:10,912:INFO:Memory: svmem(total=8589934592, available=2486472704, percent=71.1, used=5291700224, free=576331776, active=1914814464, inactive=1832931328, wired=3376885760)
2023-01-19 23:20:10,912:INFO:Physical Core: 4
2023-01-19 23:20:10,912:INFO:Logical Core: 8
2023-01-19 23:20:10,912:INFO:Checking libraries
2023-01-19 23:20:10,912:INFO:System:
2023-01-19 23:20:10,912:INFO:    python: 3.9.12 (main, Apr  5 2022, 01:53:17)  [Clang 12.0.0 ]
2023-01-19 23:20:10,912:INFO:executable: /Users/hiroto/opt/anaconda3/bin/python
2023-01-19 23:20:10,912:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-01-19 23:20:10,912:INFO:PyCaret required dependencies:
2023-01-19 23:20:10,913:INFO:                 pip: 21.2.4
2023-01-19 23:20:10,913:INFO:          setuptools: 66.0.0
2023-01-19 23:20:10,913:INFO:             pycaret: 3.0.0rc8
2023-01-19 23:20:10,913:INFO:             IPython: 8.8.0
2023-01-19 23:20:10,913:INFO:          ipywidgets: 8.0.4
2023-01-19 23:20:10,913:INFO:                tqdm: 4.64.1
2023-01-19 23:20:10,913:INFO:               numpy: 1.23.5
2023-01-19 23:20:10,913:INFO:              pandas: 1.5.3
2023-01-19 23:20:10,913:INFO:              jinja2: 3.1.2
2023-01-19 23:20:10,913:INFO:               scipy: 1.10.0
2023-01-19 23:20:10,913:INFO:              joblib: 1.2.0
2023-01-19 23:20:10,913:INFO:             sklearn: 1.1.3
2023-01-19 23:20:10,913:INFO:                pyod: 1.0.7
2023-01-19 23:20:10,913:INFO:            imblearn: 0.10.1
2023-01-19 23:20:10,913:INFO:   category_encoders: 2.6.0
2023-01-19 23:20:10,913:INFO:            lightgbm: 3.3.4
2023-01-19 23:20:10,913:INFO:               numba: 0.56.4
2023-01-19 23:20:10,913:INFO:            requests: 2.28.2
2023-01-19 23:20:10,913:INFO:          matplotlib: 3.6.3
2023-01-19 23:20:10,913:INFO:          scikitplot: 0.3.7
2023-01-19 23:20:10,913:INFO:         yellowbrick: 1.5
2023-01-19 23:20:10,913:INFO:              plotly: 5.12.0
2023-01-19 23:20:10,913:INFO:             kaleido: 0.2.1
2023-01-19 23:20:10,913:INFO:         statsmodels: 0.13.5
2023-01-19 23:20:10,913:INFO:              sktime: 0.15.1
2023-01-19 23:20:10,913:INFO:               tbats: 1.1.2
2023-01-19 23:20:10,913:INFO:            pmdarima: 2.0.2
2023-01-19 23:20:10,913:INFO:              psutil: 5.9.4
2023-01-19 23:20:10,913:INFO:PyCaret optional dependencies:
2023-01-19 23:20:10,916:INFO:                shap: 0.41.0
2023-01-19 23:20:10,916:INFO:           interpret: Not installed
2023-01-19 23:20:10,916:INFO:                umap: 0.5.3
2023-01-19 23:20:10,916:INFO:    pandas_profiling: 3.6.2
2023-01-19 23:20:10,916:INFO:  explainerdashboard: Not installed
2023-01-19 23:20:10,916:INFO:             autoviz: Not installed
2023-01-19 23:20:10,916:INFO:           fairlearn: Not installed
2023-01-19 23:20:10,916:INFO:             xgboost: 1.7.3
2023-01-19 23:20:10,916:INFO:            catboost: 1.1.1
2023-01-19 23:20:10,916:INFO:              kmodes: 0.12.2
2023-01-19 23:20:10,916:INFO:             mlxtend: 0.21.0
2023-01-19 23:20:10,916:INFO:       statsforecast: Not installed
2023-01-19 23:20:10,916:INFO:        tune_sklearn: Not installed
2023-01-19 23:20:10,917:INFO:                 ray: Not installed
2023-01-19 23:20:10,917:INFO:            hyperopt: Not installed
2023-01-19 23:20:10,917:INFO:              optuna: Not installed
2023-01-19 23:20:10,917:INFO:               skopt: Not installed
2023-01-19 23:20:10,917:INFO:              mlflow: 2.1.1
2023-01-19 23:20:10,917:INFO:              gradio: Not installed
2023-01-19 23:20:10,917:INFO:             fastapi: Not installed
2023-01-19 23:20:10,917:INFO:             uvicorn: Not installed
2023-01-19 23:20:10,917:INFO:              m2cgen: Not installed
2023-01-19 23:20:10,917:INFO:           evidently: Not installed
2023-01-19 23:20:10,917:INFO:                nltk: 3.8.1
2023-01-19 23:20:10,917:INFO:            pyLDAvis: 3.3.1
2023-01-19 23:20:10,917:INFO:              gensim: 4.3.0
2023-01-19 23:20:10,917:INFO:               spacy: 3.4.4
2023-01-19 23:20:10,917:INFO:           wordcloud: 1.8.2.2
2023-01-19 23:20:10,917:INFO:            textblob: 0.17.1
2023-01-19 23:20:10,917:INFO:               fugue: Not installed
2023-01-19 23:20:10,917:INFO:           streamlit: Not installed
2023-01-19 23:20:10,917:INFO:             prophet: Not installed
2023-01-19 23:20:10,917:INFO:None
2023-01-19 23:20:10,917:INFO:Set up data.
2023-01-19 23:20:10,963:INFO:Set up train/test split.
2023-01-19 23:20:29,154:INFO:PyCaret RegressionExperiment
2023-01-19 23:20:29,187:INFO:Logging name: reg-default-name
2023-01-19 23:20:29,187:INFO:ML Usecase: MLUsecase.REGRESSION
2023-01-19 23:20:29,187:INFO:version 3.0.0.rc8
2023-01-19 23:20:29,188:INFO:Initializing setup()
2023-01-19 23:20:29,188:INFO:self.USI: 68c9
2023-01-19 23:20:29,188:INFO:self._variable_keys: {'exp_id', 'logging_param', 'fold_groups_param', 'seed', 'exp_name_log', 'pipeline', 'X', 'gpu_n_jobs_param', 'y_test', 'transform_target_param', 'fold_generator', 'log_plots_param', 'n_jobs_param', '_ml_usecase', 'y', 'fold_shuffle_param', 'y_train', '_available_plots', 'X_train', 'X_test', 'memory', 'USI', 'html_param', 'data', 'gpu_param', 'target_param', 'idx'}
2023-01-19 23:20:29,188:INFO:Checking environment
2023-01-19 23:20:29,188:INFO:python_version: 3.9.12
2023-01-19 23:20:29,188:INFO:python_build: ('main', 'Apr  5 2022 01:53:17')
2023-01-19 23:20:29,188:INFO:machine: x86_64
2023-01-19 23:20:29,188:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-01-19 23:20:29,189:INFO:Memory: svmem(total=8589934592, available=1511366656, percent=82.4, used=4874223616, free=63455232, active=1450184704, inactive=1441497088, wired=3424038912)
2023-01-19 23:20:29,189:INFO:Physical Core: 4
2023-01-19 23:20:29,189:INFO:Logical Core: 8
2023-01-19 23:20:29,189:INFO:Checking libraries
2023-01-19 23:20:29,189:INFO:System:
2023-01-19 23:20:29,189:INFO:    python: 3.9.12 (main, Apr  5 2022, 01:53:17)  [Clang 12.0.0 ]
2023-01-19 23:20:29,189:INFO:executable: /Users/hiroto/opt/anaconda3/bin/python
2023-01-19 23:20:29,189:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-01-19 23:20:29,189:INFO:PyCaret required dependencies:
2023-01-19 23:20:29,189:INFO:                 pip: 21.2.4
2023-01-19 23:20:29,189:INFO:          setuptools: 66.0.0
2023-01-19 23:20:29,189:INFO:             pycaret: 3.0.0rc8
2023-01-19 23:20:29,190:INFO:             IPython: 8.8.0
2023-01-19 23:20:29,190:INFO:          ipywidgets: 8.0.4
2023-01-19 23:20:29,190:INFO:                tqdm: 4.64.1
2023-01-19 23:20:29,190:INFO:               numpy: 1.23.5
2023-01-19 23:20:29,190:INFO:              pandas: 1.5.3
2023-01-19 23:20:29,190:INFO:              jinja2: 3.1.2
2023-01-19 23:20:29,190:INFO:               scipy: 1.10.0
2023-01-19 23:20:29,190:INFO:              joblib: 1.2.0
2023-01-19 23:20:29,190:INFO:             sklearn: 1.1.3
2023-01-19 23:20:29,190:INFO:                pyod: 1.0.7
2023-01-19 23:20:29,190:INFO:            imblearn: 0.10.1
2023-01-19 23:20:29,190:INFO:   category_encoders: 2.6.0
2023-01-19 23:20:29,190:INFO:            lightgbm: 3.3.4
2023-01-19 23:20:29,190:INFO:               numba: 0.56.4
2023-01-19 23:20:29,190:INFO:            requests: 2.28.2
2023-01-19 23:20:29,190:INFO:          matplotlib: 3.6.3
2023-01-19 23:20:29,190:INFO:          scikitplot: 0.3.7
2023-01-19 23:20:29,190:INFO:         yellowbrick: 1.5
2023-01-19 23:20:29,190:INFO:              plotly: 5.12.0
2023-01-19 23:20:29,191:INFO:             kaleido: 0.2.1
2023-01-19 23:20:29,191:INFO:         statsmodels: 0.13.5
2023-01-19 23:20:29,191:INFO:              sktime: 0.15.1
2023-01-19 23:20:29,191:INFO:               tbats: 1.1.2
2023-01-19 23:20:29,191:INFO:            pmdarima: 2.0.2
2023-01-19 23:20:29,191:INFO:              psutil: 5.9.4
2023-01-19 23:20:29,191:INFO:PyCaret optional dependencies:
2023-01-19 23:20:29,191:INFO:                shap: 0.41.0
2023-01-19 23:20:29,191:INFO:           interpret: Not installed
2023-01-19 23:20:29,191:INFO:                umap: 0.5.3
2023-01-19 23:20:29,191:INFO:    pandas_profiling: 3.6.2
2023-01-19 23:20:29,191:INFO:  explainerdashboard: Not installed
2023-01-19 23:20:29,191:INFO:             autoviz: Not installed
2023-01-19 23:20:29,191:INFO:           fairlearn: Not installed
2023-01-19 23:20:29,191:INFO:             xgboost: 1.7.3
2023-01-19 23:20:29,192:INFO:            catboost: 1.1.1
2023-01-19 23:20:29,192:INFO:              kmodes: 0.12.2
2023-01-19 23:20:29,192:INFO:             mlxtend: 0.21.0
2023-01-19 23:20:29,192:INFO:       statsforecast: Not installed
2023-01-19 23:20:29,192:INFO:        tune_sklearn: Not installed
2023-01-19 23:20:29,192:INFO:                 ray: Not installed
2023-01-19 23:20:29,192:INFO:            hyperopt: Not installed
2023-01-19 23:20:29,192:INFO:              optuna: Not installed
2023-01-19 23:20:29,192:INFO:               skopt: Not installed
2023-01-19 23:20:29,192:INFO:              mlflow: 2.1.1
2023-01-19 23:20:29,192:INFO:              gradio: Not installed
2023-01-19 23:20:29,192:INFO:             fastapi: Not installed
2023-01-19 23:20:29,193:INFO:             uvicorn: Not installed
2023-01-19 23:20:29,193:INFO:              m2cgen: Not installed
2023-01-19 23:20:29,193:INFO:           evidently: Not installed
2023-01-19 23:20:29,193:INFO:                nltk: 3.8.1
2023-01-19 23:20:29,193:INFO:            pyLDAvis: 3.3.1
2023-01-19 23:20:29,193:INFO:              gensim: 4.3.0
2023-01-19 23:20:29,193:INFO:               spacy: 3.4.4
2023-01-19 23:20:29,193:INFO:           wordcloud: 1.8.2.2
2023-01-19 23:20:29,193:INFO:            textblob: 0.17.1
2023-01-19 23:20:29,193:INFO:               fugue: Not installed
2023-01-19 23:20:29,193:INFO:           streamlit: Not installed
2023-01-19 23:20:29,193:INFO:             prophet: Not installed
2023-01-19 23:20:29,193:INFO:None
2023-01-19 23:20:29,193:INFO:Set up data.
2023-01-19 23:20:29,268:INFO:Set up train/test split.
2023-01-19 23:20:29,317:INFO:Set up index.
2023-01-19 23:20:29,321:INFO:Set up folding strategy.
2023-01-19 23:20:29,322:INFO:Assigning column types.
2023-01-19 23:20:29,331:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-01-19 23:20:29,332:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-19 23:20:29,338:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-19 23:20:29,346:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-19 23:20:29,472:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-19 23:20:29,559:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-19 23:20:29,561:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:20:30,873:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:20:31,636:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-19 23:20:31,642:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-19 23:20:31,651:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-19 23:20:31,794:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-19 23:20:31,884:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-19 23:20:31,885:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:20:31,889:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:20:31,890:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-01-19 23:20:31,896:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-19 23:20:31,902:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-19 23:20:31,978:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-19 23:20:32,043:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-19 23:20:32,044:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:20:32,047:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:20:32,054:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-19 23:20:32,062:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-19 23:20:32,199:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-19 23:20:32,287:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-19 23:20:32,288:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:20:32,293:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:20:32,294:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-01-19 23:20:32,317:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-19 23:20:32,471:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-19 23:20:32,548:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-19 23:20:32,549:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:20:32,553:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:20:32,569:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-19 23:20:32,743:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-19 23:20:32,796:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-19 23:20:32,800:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:20:32,803:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:20:32,803:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-01-19 23:20:32,882:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-19 23:20:32,938:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-19 23:20:32,938:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:20:32,941:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:20:33,027:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-19 23:20:33,080:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-19 23:20:33,081:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:20:33,086:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:20:33,087:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-01-19 23:20:33,164:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-19 23:20:33,224:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:20:33,231:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:20:33,327:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-19 23:20:33,380:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:20:33,384:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:20:33,384:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-01-19 23:20:33,534:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:20:33,538:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:20:33,678:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:20:33,681:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:20:33,685:INFO:Preparing preprocessing pipeline...
2023-01-19 23:20:33,687:INFO:Set up column name cleaning.
2023-01-19 23:20:33,687:INFO:Set up simple imputation.
2023-01-19 23:20:33,777:INFO:Finished creating preprocessing pipeline.
2023-01-19 23:20:33,783:INFO:Pipeline: Pipeline(memory=Memory(location=/var/folders/3w/xf1fzw1s1mnb4ckhfxf67vgw0000gn/T/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['MSSubClass', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuil...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-01-19 23:20:33,783:INFO:Creating final display dataframe.
2023-01-19 23:20:34,123:INFO:Setup _display_container:                     Description             Value
0                    Session id              1145
1                        Target         SalePrice
2                   Target type        Regression
3           Original data shape       (1458, 193)
4        Transformed data shape       (1458, 193)
5   Transformed train set shape       (1020, 193)
6    Transformed test set shape        (438, 193)
7              Numeric features               192
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              68c9
2023-01-19 23:20:34,289:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:20:34,294:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:20:34,438:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:20:34,441:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:20:34,442:INFO:setup() successfully completed in 5.29s...............
2023-01-19 23:22:19,975:INFO:PyCaret RegressionExperiment
2023-01-19 23:22:19,994:INFO:Logging name: reg-default-name
2023-01-19 23:22:20,001:INFO:ML Usecase: MLUsecase.REGRESSION
2023-01-19 23:22:20,002:INFO:version 3.0.0.rc8
2023-01-19 23:22:20,002:INFO:Initializing setup()
2023-01-19 23:22:20,002:INFO:self.USI: bd4b
2023-01-19 23:22:20,004:INFO:self._variable_keys: {'exp_id', 'logging_param', 'fold_groups_param', 'seed', 'exp_name_log', 'pipeline', 'X', 'gpu_n_jobs_param', 'y_test', 'transform_target_param', 'fold_generator', 'log_plots_param', 'n_jobs_param', '_ml_usecase', 'y', 'fold_shuffle_param', 'y_train', '_available_plots', 'X_train', 'X_test', 'memory', 'USI', 'html_param', 'data', 'gpu_param', 'target_param', 'idx'}
2023-01-19 23:22:20,008:INFO:Checking environment
2023-01-19 23:22:20,017:INFO:python_version: 3.9.12
2023-01-19 23:22:20,018:INFO:python_build: ('main', 'Apr  5 2022 01:53:17')
2023-01-19 23:22:20,018:INFO:machine: x86_64
2023-01-19 23:22:20,018:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-01-19 23:22:20,054:INFO:Memory: svmem(total=8589934592, available=1691549696, percent=80.3, used=5041131520, free=76906496, active=1616322560, inactive=1557782528, wired=3424808960)
2023-01-19 23:22:20,054:INFO:Physical Core: 4
2023-01-19 23:22:20,054:INFO:Logical Core: 8
2023-01-19 23:22:20,054:INFO:Checking libraries
2023-01-19 23:22:20,061:INFO:System:
2023-01-19 23:22:20,061:INFO:    python: 3.9.12 (main, Apr  5 2022, 01:53:17)  [Clang 12.0.0 ]
2023-01-19 23:22:20,061:INFO:executable: /Users/hiroto/opt/anaconda3/bin/python
2023-01-19 23:22:20,061:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-01-19 23:22:20,061:INFO:PyCaret required dependencies:
2023-01-19 23:22:20,090:INFO:                 pip: 21.2.4
2023-01-19 23:22:20,091:INFO:          setuptools: 66.0.0
2023-01-19 23:22:20,091:INFO:             pycaret: 3.0.0rc8
2023-01-19 23:22:20,091:INFO:             IPython: 8.8.0
2023-01-19 23:22:20,091:INFO:          ipywidgets: 8.0.4
2023-01-19 23:22:20,091:INFO:                tqdm: 4.64.1
2023-01-19 23:22:20,091:INFO:               numpy: 1.23.5
2023-01-19 23:22:20,091:INFO:              pandas: 1.5.3
2023-01-19 23:22:20,091:INFO:              jinja2: 3.1.2
2023-01-19 23:22:20,091:INFO:               scipy: 1.10.0
2023-01-19 23:22:20,091:INFO:              joblib: 1.2.0
2023-01-19 23:22:20,091:INFO:             sklearn: 1.1.3
2023-01-19 23:22:20,091:INFO:                pyod: 1.0.7
2023-01-19 23:22:20,091:INFO:            imblearn: 0.10.1
2023-01-19 23:22:20,091:INFO:   category_encoders: 2.6.0
2023-01-19 23:22:20,091:INFO:            lightgbm: 3.3.4
2023-01-19 23:22:20,091:INFO:               numba: 0.56.4
2023-01-19 23:22:20,091:INFO:            requests: 2.28.2
2023-01-19 23:22:20,091:INFO:          matplotlib: 3.6.3
2023-01-19 23:22:20,091:INFO:          scikitplot: 0.3.7
2023-01-19 23:22:20,091:INFO:         yellowbrick: 1.5
2023-01-19 23:22:20,092:INFO:              plotly: 5.12.0
2023-01-19 23:22:20,092:INFO:             kaleido: 0.2.1
2023-01-19 23:22:20,092:INFO:         statsmodels: 0.13.5
2023-01-19 23:22:20,092:INFO:              sktime: 0.15.1
2023-01-19 23:22:20,092:INFO:               tbats: 1.1.2
2023-01-19 23:22:20,092:INFO:            pmdarima: 2.0.2
2023-01-19 23:22:20,092:INFO:              psutil: 5.9.4
2023-01-19 23:22:20,092:INFO:PyCaret optional dependencies:
2023-01-19 23:22:20,092:INFO:                shap: 0.41.0
2023-01-19 23:22:20,092:INFO:           interpret: Not installed
2023-01-19 23:22:20,092:INFO:                umap: 0.5.3
2023-01-19 23:22:20,092:INFO:    pandas_profiling: 3.6.2
2023-01-19 23:22:20,092:INFO:  explainerdashboard: Not installed
2023-01-19 23:22:20,092:INFO:             autoviz: Not installed
2023-01-19 23:22:20,092:INFO:           fairlearn: Not installed
2023-01-19 23:22:20,092:INFO:             xgboost: 1.7.3
2023-01-19 23:22:20,093:INFO:            catboost: 1.1.1
2023-01-19 23:22:20,093:INFO:              kmodes: 0.12.2
2023-01-19 23:22:20,093:INFO:             mlxtend: 0.21.0
2023-01-19 23:22:20,093:INFO:       statsforecast: Not installed
2023-01-19 23:22:20,093:INFO:        tune_sklearn: Not installed
2023-01-19 23:22:20,093:INFO:                 ray: Not installed
2023-01-19 23:22:20,093:INFO:            hyperopt: Not installed
2023-01-19 23:22:20,093:INFO:              optuna: Not installed
2023-01-19 23:22:20,093:INFO:               skopt: Not installed
2023-01-19 23:22:20,093:INFO:              mlflow: 2.1.1
2023-01-19 23:22:20,093:INFO:              gradio: Not installed
2023-01-19 23:22:20,093:INFO:             fastapi: Not installed
2023-01-19 23:22:20,093:INFO:             uvicorn: Not installed
2023-01-19 23:22:20,093:INFO:              m2cgen: Not installed
2023-01-19 23:22:20,093:INFO:           evidently: Not installed
2023-01-19 23:22:20,093:INFO:                nltk: 3.8.1
2023-01-19 23:22:20,093:INFO:            pyLDAvis: 3.3.1
2023-01-19 23:22:20,093:INFO:              gensim: 4.3.0
2023-01-19 23:22:20,093:INFO:               spacy: 3.4.4
2023-01-19 23:22:20,093:INFO:           wordcloud: 1.8.2.2
2023-01-19 23:22:20,093:INFO:            textblob: 0.17.1
2023-01-19 23:22:20,094:INFO:               fugue: Not installed
2023-01-19 23:22:20,094:INFO:           streamlit: Not installed
2023-01-19 23:22:20,094:INFO:             prophet: Not installed
2023-01-19 23:22:20,094:INFO:None
2023-01-19 23:22:20,094:INFO:Set up data.
2023-01-19 23:22:20,387:INFO:Set up train/test split.
2023-01-19 23:22:20,476:INFO:Set up index.
2023-01-19 23:22:20,478:INFO:Set up folding strategy.
2023-01-19 23:22:20,486:INFO:Assigning column types.
2023-01-19 23:22:20,493:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-01-19 23:22:20,494:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-19 23:22:20,504:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-19 23:22:20,510:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-19 23:22:20,576:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-19 23:22:20,625:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-19 23:22:20,626:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:22:20,629:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:22:20,630:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-19 23:22:20,635:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-19 23:22:20,640:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-19 23:22:20,702:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-19 23:22:20,751:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-19 23:22:20,752:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:22:20,755:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:22:20,755:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-01-19 23:22:20,761:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-19 23:22:20,766:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-19 23:22:20,829:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-19 23:22:20,878:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-19 23:22:20,878:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:22:20,881:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:22:20,887:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-19 23:22:20,892:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-19 23:22:20,955:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-19 23:22:21,003:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-19 23:22:21,004:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:22:21,007:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:22:21,007:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-01-19 23:22:21,018:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-19 23:22:21,083:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-19 23:22:21,132:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-19 23:22:21,133:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:22:21,135:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:22:21,146:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-19 23:22:21,210:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-19 23:22:21,260:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-19 23:22:21,260:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:22:21,263:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:22:21,263:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-01-19 23:22:21,337:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-19 23:22:21,384:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-19 23:22:21,385:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:22:21,388:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:22:21,462:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-19 23:22:21,511:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-19 23:22:21,511:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:22:21,514:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:22:21,514:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-01-19 23:22:21,588:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-19 23:22:21,639:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:22:21,642:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:22:21,717:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-19 23:22:21,768:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:22:21,771:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:22:21,772:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-01-19 23:22:21,895:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:22:21,898:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:22:22,023:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:22:22,026:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:22:22,030:INFO:Preparing preprocessing pipeline...
2023-01-19 23:22:22,031:INFO:Set up column name cleaning.
2023-01-19 23:22:22,031:INFO:Set up simple imputation.
2023-01-19 23:22:22,202:INFO:Finished creating preprocessing pipeline.
2023-01-19 23:22:22,208:INFO:Pipeline: Pipeline(memory=Memory(location=/var/folders/3w/xf1fzw1s1mnb4ckhfxf67vgw0000gn/T/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['MSSubClass', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuil...
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2023-01-19 23:22:22,208:INFO:Creating final display dataframe.
2023-01-19 23:22:22,613:INFO:Setup _display_container:                     Description             Value
0                    Session id              3987
1                        Target         SalePrice
2                   Target type        Regression
3           Original data shape       (1458, 193)
4        Transformed data shape       (1458, 193)
5   Transformed train set shape       (1020, 193)
6    Transformed test set shape        (438, 193)
7              Numeric features               192
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              bd4b
2023-01-19 23:22:22,829:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:22:22,834:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:22:23,025:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:22:23,028:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:22:23,047:INFO:setup() successfully completed in 3.2s...............
2023-01-19 23:22:23,086:INFO:Initializing compare_models()
2023-01-19 23:22:23,086:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f7f0929f0a0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7f7f0929f0a0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-01-19 23:22:23,087:INFO:Checking exceptions
2023-01-19 23:22:23,097:INFO:Preparing display monitor
2023-01-19 23:22:24,059:INFO:Initializing Linear Regression
2023-01-19 23:22:24,059:INFO:Total runtime is 6.0836474100748696e-06 minutes
2023-01-19 23:22:24,063:INFO:SubProcess create_model() called ==================================
2023-01-19 23:22:24,083:INFO:Initializing create_model()
2023-01-19 23:22:24,083:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f7f0929f0a0>, estimator=lr, fold=KFold(n_splits=10, random_state=3987, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7f0b1eaa60>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:22:24,083:INFO:Checking exceptions
2023-01-19 23:22:24,083:INFO:Importing libraries
2023-01-19 23:22:24,083:INFO:Copying training dataset
2023-01-19 23:22:24,090:INFO:Defining folds
2023-01-19 23:22:24,090:INFO:Declaring metric variables
2023-01-19 23:22:24,095:INFO:Importing untrained model
2023-01-19 23:22:24,107:INFO:Linear Regression Imported successfully
2023-01-19 23:22:24,122:INFO:Starting cross validation
2023-01-19 23:22:24,229:INFO:Cross validating with KFold(n_splits=10, random_state=3987, shuffle=True), n_jobs=-1
2023-01-19 23:22:47,572:INFO:Calculating mean and std
2023-01-19 23:22:47,586:INFO:Creating metrics dataframe
2023-01-19 23:22:47,616:INFO:Uploading results into container
2023-01-19 23:22:47,624:INFO:Uploading model into container now
2023-01-19 23:22:47,629:INFO:_master_model_container: 1
2023-01-19 23:22:47,630:INFO:_display_container: 2
2023-01-19 23:22:47,631:INFO:LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1,
                 normalize='deprecated', positive=False)
2023-01-19 23:22:47,632:INFO:create_model() successfully completed......................................
2023-01-19 23:22:48,845:INFO:SubProcess create_model() end ==================================
2023-01-19 23:22:48,846:INFO:Creating metrics dataframe
2023-01-19 23:22:48,859:INFO:Initializing Lasso Regression
2023-01-19 23:22:48,860:INFO:Total runtime is 0.41335258483886717 minutes
2023-01-19 23:22:48,864:INFO:SubProcess create_model() called ==================================
2023-01-19 23:22:48,864:INFO:Initializing create_model()
2023-01-19 23:22:48,865:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f7f0929f0a0>, estimator=lasso, fold=KFold(n_splits=10, random_state=3987, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7f0b1eaa60>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:22:48,865:INFO:Checking exceptions
2023-01-19 23:22:48,865:INFO:Importing libraries
2023-01-19 23:22:48,865:INFO:Copying training dataset
2023-01-19 23:22:48,873:INFO:Defining folds
2023-01-19 23:22:48,873:INFO:Declaring metric variables
2023-01-19 23:22:48,877:INFO:Importing untrained model
2023-01-19 23:22:48,883:INFO:Lasso Regression Imported successfully
2023-01-19 23:22:48,894:INFO:Starting cross validation
2023-01-19 23:22:48,896:INFO:Cross validating with KFold(n_splits=10, random_state=3987, shuffle=True), n_jobs=-1
2023-01-19 23:22:49,202:INFO:Calculating mean and std
2023-01-19 23:22:49,326:INFO:Creating metrics dataframe
2023-01-19 23:22:49,332:INFO:Uploading results into container
2023-01-19 23:22:49,334:INFO:Uploading model into container now
2023-01-19 23:22:49,335:INFO:_master_model_container: 2
2023-01-19 23:22:49,335:INFO:_display_container: 2
2023-01-19 23:22:49,336:INFO:Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,
      normalize='deprecated', positive=False, precompute=False,
      random_state=3987, selection='cyclic', tol=0.0001, warm_start=False)
2023-01-19 23:22:49,336:INFO:create_model() successfully completed......................................
2023-01-19 23:22:49,480:INFO:SubProcess create_model() end ==================================
2023-01-19 23:22:49,481:INFO:Creating metrics dataframe
2023-01-19 23:22:49,494:INFO:Initializing Ridge Regression
2023-01-19 23:22:49,494:INFO:Total runtime is 0.42392729918162025 minutes
2023-01-19 23:22:49,499:INFO:SubProcess create_model() called ==================================
2023-01-19 23:22:49,500:INFO:Initializing create_model()
2023-01-19 23:22:49,500:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f7f0929f0a0>, estimator=ridge, fold=KFold(n_splits=10, random_state=3987, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7f0b1eaa60>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:22:49,501:INFO:Checking exceptions
2023-01-19 23:22:49,501:INFO:Importing libraries
2023-01-19 23:22:49,502:INFO:Copying training dataset
2023-01-19 23:22:49,508:INFO:Defining folds
2023-01-19 23:22:49,508:INFO:Declaring metric variables
2023-01-19 23:22:49,513:INFO:Importing untrained model
2023-01-19 23:22:49,520:INFO:Ridge Regression Imported successfully
2023-01-19 23:22:49,553:INFO:Starting cross validation
2023-01-19 23:22:49,556:INFO:Cross validating with KFold(n_splits=10, random_state=3987, shuffle=True), n_jobs=-1
2023-01-19 23:22:49,807:INFO:Calculating mean and std
2023-01-19 23:22:49,808:INFO:Creating metrics dataframe
2023-01-19 23:22:49,812:INFO:Uploading results into container
2023-01-19 23:22:49,812:INFO:Uploading model into container now
2023-01-19 23:22:49,813:INFO:_master_model_container: 3
2023-01-19 23:22:49,813:INFO:_display_container: 2
2023-01-19 23:22:49,813:INFO:Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,
      normalize='deprecated', positive=False, random_state=3987, solver='auto',
      tol=0.001)
2023-01-19 23:22:49,813:INFO:create_model() successfully completed......................................
2023-01-19 23:22:49,947:INFO:SubProcess create_model() end ==================================
2023-01-19 23:22:49,947:INFO:Creating metrics dataframe
2023-01-19 23:22:49,962:INFO:Initializing Elastic Net
2023-01-19 23:22:49,962:INFO:Total runtime is 0.43172082106272375 minutes
2023-01-19 23:22:49,967:INFO:SubProcess create_model() called ==================================
2023-01-19 23:22:49,968:INFO:Initializing create_model()
2023-01-19 23:22:49,968:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f7f0929f0a0>, estimator=en, fold=KFold(n_splits=10, random_state=3987, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7f0b1eaa60>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:22:49,968:INFO:Checking exceptions
2023-01-19 23:22:49,968:INFO:Importing libraries
2023-01-19 23:22:49,969:INFO:Copying training dataset
2023-01-19 23:22:49,974:INFO:Defining folds
2023-01-19 23:22:49,974:INFO:Declaring metric variables
2023-01-19 23:22:49,979:INFO:Importing untrained model
2023-01-19 23:22:49,984:INFO:Elastic Net Imported successfully
2023-01-19 23:22:49,994:INFO:Starting cross validation
2023-01-19 23:22:49,996:INFO:Cross validating with KFold(n_splits=10, random_state=3987, shuffle=True), n_jobs=-1
2023-01-19 23:22:50,197:INFO:Calculating mean and std
2023-01-19 23:22:50,198:INFO:Creating metrics dataframe
2023-01-19 23:22:50,202:INFO:Uploading results into container
2023-01-19 23:22:50,203:INFO:Uploading model into container now
2023-01-19 23:22:50,204:INFO:_master_model_container: 4
2023-01-19 23:22:50,204:INFO:_display_container: 2
2023-01-19 23:22:50,204:INFO:ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
           max_iter=1000, normalize='deprecated', positive=False,
           precompute=False, random_state=3987, selection='cyclic', tol=0.0001,
           warm_start=False)
2023-01-19 23:22:50,204:INFO:create_model() successfully completed......................................
2023-01-19 23:22:50,360:INFO:SubProcess create_model() end ==================================
2023-01-19 23:22:50,360:INFO:Creating metrics dataframe
2023-01-19 23:22:50,376:INFO:Initializing Least Angle Regression
2023-01-19 23:22:50,376:INFO:Total runtime is 0.43862791856129957 minutes
2023-01-19 23:22:50,380:INFO:SubProcess create_model() called ==================================
2023-01-19 23:22:50,380:INFO:Initializing create_model()
2023-01-19 23:22:50,380:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f7f0929f0a0>, estimator=lar, fold=KFold(n_splits=10, random_state=3987, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7f0b1eaa60>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:22:50,381:INFO:Checking exceptions
2023-01-19 23:22:50,381:INFO:Importing libraries
2023-01-19 23:22:50,381:INFO:Copying training dataset
2023-01-19 23:22:50,386:INFO:Defining folds
2023-01-19 23:22:50,387:INFO:Declaring metric variables
2023-01-19 23:22:50,392:INFO:Importing untrained model
2023-01-19 23:22:50,397:INFO:Least Angle Regression Imported successfully
2023-01-19 23:22:50,405:INFO:Starting cross validation
2023-01-19 23:22:50,407:INFO:Cross validating with KFold(n_splits=10, random_state=3987, shuffle=True), n_jobs=-1
2023-01-19 23:22:50,467:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:22:50,470:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:22:50,494:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:22:50,526:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:22:50,536:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:22:50,534:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:22:50,543:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 93 iterations, i.e. alpha=1.764e-04, with an active set of 88 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,544:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:22:50,556:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 181 iterations, i.e. alpha=5.698e-05, with an active set of 162 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,564:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:22:50,564:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 154 iterations, i.e. alpha=1.079e-04, with an active set of 139 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,565:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 194 iterations, i.e. alpha=5.054e-05, with an active set of 170 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,566:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 157 iterations, i.e. alpha=1.017e-04, with an active set of 142 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,574:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=1.415e-04, with an active set of 101 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,576:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 142 iterations, i.e. alpha=8.058e-05, with an active set of 136 regressors, and the smallest cholesky pivot element being 9.657e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,581:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 145 iterations, i.e. alpha=7.173e-05, with an active set of 139 regressors, and the smallest cholesky pivot element being 9.657e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,589:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 155 iterations, i.e. alpha=5.838e-05, with an active set of 147 regressors, and the smallest cholesky pivot element being 9.657e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,590:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 221 iterations, i.e. alpha=1.090e-04, with an active set of 184 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,594:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 223 iterations, i.e. alpha=7.671e-05, with an active set of 185 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,595:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 163 iterations, i.e. alpha=5.390e-05, with an active set of 154 regressors, and the smallest cholesky pivot element being 9.657e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,596:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=4.734e-05, with an active set of 156 regressors, and the smallest cholesky pivot element being 9.657e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,598:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=3.659e-05, with an active set of 159 regressors, and the smallest cholesky pivot element being 9.657e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,600:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 209 iterations, i.e. alpha=3.802e-04, with an active set of 177 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,600:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 172 iterations, i.e. alpha=3.463e-05, with an active set of 161 regressors, and the smallest cholesky pivot element being 9.657e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,604:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 219 iterations, i.e. alpha=5.057e-04, with an active set of 180 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,619:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 178 iterations, i.e. alpha=2.536e-05, with an active set of 167 regressors, and the smallest cholesky pivot element being 9.657e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,623:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 183 iterations, i.e. alpha=2.184e-05, with an active set of 171 regressors, and the smallest cholesky pivot element being 9.657e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,629:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 186 iterations, i.e. alpha=2.222e-05, with an active set of 173 regressors, and the smallest cholesky pivot element being 9.657e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,634:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=6.378e-05, with an active set of 157 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,636:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 190 iterations, i.e. alpha=1.705e-05, with an active set of 176 regressors, and the smallest cholesky pivot element being 9.657e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,638:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 191 iterations, i.e. alpha=1.307e-05, with an active set of 177 regressors, and the smallest cholesky pivot element being 9.657e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,640:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 147 iterations, i.e. alpha=4.379e-05, with an active set of 140 regressors, and the smallest cholesky pivot element being 7.451e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,642:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 121 iterations, i.e. alpha=1.435e-04, with an active set of 117 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,644:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 153 iterations, i.e. alpha=4.505e-05, with an active set of 145 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,644:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 126 iterations, i.e. alpha=1.442e-04, with an active set of 120 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,645:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 201 iterations, i.e. alpha=3.830e-03, with an active set of 178 regressors, and the smallest cholesky pivot element being 9.657e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,646:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 203 iterations, i.e. alpha=1.679e-03, with an active set of 179 regressors, and the smallest cholesky pivot element being 9.657e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,648:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 135 iterations, i.e. alpha=1.249e-04, with an active set of 129 regressors, and the smallest cholesky pivot element being 7.955e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,648:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 205 iterations, i.e. alpha=1.303e-03, with an active set of 181 regressors, and the smallest cholesky pivot element being 9.657e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,650:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 208 iterations, i.e. alpha=9.445e-04, with an active set of 182 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,650:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 208 iterations, i.e. alpha=9.353e-04, with an active set of 182 regressors, and the smallest cholesky pivot element being 9.657e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,650:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 141 iterations, i.e. alpha=1.133e-04, with an active set of 134 regressors, and the smallest cholesky pivot element being 7.955e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,651:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 209 iterations, i.e. alpha=5.361e-04, with an active set of 183 regressors, and the smallest cholesky pivot element being 9.657e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,652:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 209 iterations, i.e. alpha=7.390e-05, with an active set of 183 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,652:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 210 iterations, i.e. alpha=2.059e-05, with an active set of 184 regressors, and the smallest cholesky pivot element being 9.657e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,653:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 210 iterations, i.e. alpha=2.635e-06, with an active set of 184 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,653:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 227 iterations, i.e. alpha=8.732e-01, with an active set of 171 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,655:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 210 iterations, i.e. alpha=2.128e-03, with an active set of 174 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,655:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 211 iterations, i.e. alpha=2.110e-03, with an active set of 175 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,656:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 184 iterations, i.e. alpha=7.954e-05, with an active set of 164 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,661:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 236 iterations, i.e. alpha=8.162e-01, with an active set of 177 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,661:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 164 iterations, i.e. alpha=9.684e-05, with an active set of 151 regressors, and the smallest cholesky pivot element being 7.955e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,663:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 225 iterations, i.e. alpha=1.145e+02, with an active set of 179 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,666:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 227 iterations, i.e. alpha=5.337e+01, with an active set of 181 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,667:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 228 iterations, i.e. alpha=1.646e+00, with an active set of 182 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,667:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=8.594e-05, with an active set of 159 regressors, and the smallest cholesky pivot element being 7.955e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,668:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 252 iterations, i.e. alpha=1.090e+05, with an active set of 181 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,668:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 207 iterations, i.e. alpha=2.194e+00, with an active set of 171 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,669:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 253 iterations, i.e. alpha=2.614e+04, with an active set of 182 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,669:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 209 iterations, i.e. alpha=1.726e+00, with an active set of 173 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,669:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 180 iterations, i.e. alpha=7.388e-05, with an active set of 164 regressors, and the smallest cholesky pivot element being 7.955e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,670:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 180 iterations, i.e. alpha=6.280e-05, with an active set of 164 regressors, and the smallest cholesky pivot element being 7.955e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,671:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 182 iterations, i.e. alpha=4.877e-05, with an active set of 166 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,673:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 185 iterations, i.e. alpha=4.059e-05, with an active set of 169 regressors, and the smallest cholesky pivot element being 7.955e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,674:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 221 iterations, i.e. alpha=1.450e+00, with an active set of 179 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,675:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 221 iterations, i.e. alpha=1.343e+00, with an active set of 179 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,675:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 221 iterations, i.e. alpha=8.698e-01, with an active set of 179 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,678:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 224 iterations, i.e. alpha=3.704e-01, with an active set of 181 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,678:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 192 iterations, i.e. alpha=4.807e-05, with an active set of 173 regressors, and the smallest cholesky pivot element being 7.955e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,678:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 224 iterations, i.e. alpha=3.315e-01, with an active set of 181 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,679:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 224 iterations, i.e. alpha=2.800e-01, with an active set of 181 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,680:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 194 iterations, i.e. alpha=3.023e-05, with an active set of 175 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,682:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 196 iterations, i.e. alpha=2.763e-05, with an active set of 177 regressors, and the smallest cholesky pivot element being 7.955e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,685:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 200 iterations, i.e. alpha=2.313e-05, with an active set of 180 regressors, and the smallest cholesky pivot element being 7.955e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,689:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 203 iterations, i.e. alpha=1.354e-05, with an active set of 183 regressors, and the smallest cholesky pivot element being 7.955e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,689:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 203 iterations, i.e. alpha=1.522e-06, with an active set of 183 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,701:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:22:50,711:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:22:50,729:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=2.267e-04, with an active set of 76 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,739:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 165 iterations, i.e. alpha=1.440e-03, with an active set of 124 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,750:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 170 iterations, i.e. alpha=1.172e-04, with an active set of 153 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,751:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 212 iterations, i.e. alpha=1.698e-03, with an active set of 160 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,756:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 229 iterations, i.e. alpha=1.391e-03, with an active set of 173 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,757:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 196 iterations, i.e. alpha=7.824e-05, with an active set of 173 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,760:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 240 iterations, i.e. alpha=7.706e-04, with an active set of 182 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,761:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 243 iterations, i.e. alpha=9.665e-04, with an active set of 183 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,761:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 244 iterations, i.e. alpha=2.217e-05, with an active set of 184 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,764:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 223 iterations, i.e. alpha=7.584e-04, with an active set of 182 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,766:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 229 iterations, i.e. alpha=7.398e-04, with an active set of 184 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:22:50,790:INFO:Calculating mean and std
2023-01-19 23:22:50,791:INFO:Creating metrics dataframe
2023-01-19 23:22:50,795:INFO:Uploading results into container
2023-01-19 23:22:50,796:INFO:Uploading model into container now
2023-01-19 23:22:50,796:INFO:_master_model_container: 5
2023-01-19 23:22:50,796:INFO:_display_container: 2
2023-01-19 23:22:50,801:INFO:Lars(copy_X=True, eps=2.220446049250313e-16, fit_intercept=True, fit_path=True,
     jitter=None, n_nonzero_coefs=500, normalize='deprecated',
     precompute='auto', random_state=3987, verbose=False)
2023-01-19 23:22:50,801:INFO:create_model() successfully completed......................................
2023-01-19 23:22:50,948:INFO:SubProcess create_model() end ==================================
2023-01-19 23:22:50,949:INFO:Creating metrics dataframe
2023-01-19 23:22:50,965:INFO:Initializing Lasso Least Angle Regression
2023-01-19 23:22:50,965:INFO:Total runtime is 0.4484507004419962 minutes
2023-01-19 23:22:50,970:INFO:SubProcess create_model() called ==================================
2023-01-19 23:22:50,970:INFO:Initializing create_model()
2023-01-19 23:22:50,970:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f7f0929f0a0>, estimator=llar, fold=KFold(n_splits=10, random_state=3987, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7f0b1eaa60>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:22:50,971:INFO:Checking exceptions
2023-01-19 23:22:50,971:INFO:Importing libraries
2023-01-19 23:22:50,971:INFO:Copying training dataset
2023-01-19 23:22:50,978:INFO:Defining folds
2023-01-19 23:22:50,978:INFO:Declaring metric variables
2023-01-19 23:22:50,983:INFO:Importing untrained model
2023-01-19 23:22:50,987:INFO:Lasso Least Angle Regression Imported successfully
2023-01-19 23:22:50,997:INFO:Starting cross validation
2023-01-19 23:22:50,998:INFO:Cross validating with KFold(n_splits=10, random_state=3987, shuffle=True), n_jobs=-1
2023-01-19 23:22:51,050:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-19 23:22:51,061:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-19 23:22:51,073:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-19 23:22:51,086:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-19 23:22:51,165:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-19 23:22:51,165:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-19 23:22:51,168:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-19 23:22:51,181:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-19 23:22:51,193:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-19 23:22:51,205:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-19 23:22:51,237:INFO:Calculating mean and std
2023-01-19 23:22:51,239:INFO:Creating metrics dataframe
2023-01-19 23:22:51,244:INFO:Uploading results into container
2023-01-19 23:22:51,244:INFO:Uploading model into container now
2023-01-19 23:22:51,245:INFO:_master_model_container: 6
2023-01-19 23:22:51,245:INFO:_display_container: 2
2023-01-19 23:22:51,245:INFO:LassoLars(alpha=1.0, copy_X=True, eps=2.220446049250313e-16, fit_intercept=True,
          fit_path=True, jitter=None, max_iter=500, normalize='deprecated',
          positive=False, precompute='auto', random_state=3987, verbose=False)
2023-01-19 23:22:51,245:INFO:create_model() successfully completed......................................
2023-01-19 23:22:51,397:INFO:SubProcess create_model() end ==================================
2023-01-19 23:22:51,398:INFO:Creating metrics dataframe
2023-01-19 23:22:51,415:INFO:Initializing Orthogonal Matching Pursuit
2023-01-19 23:22:51,415:INFO:Total runtime is 0.45594163735707594 minutes
2023-01-19 23:22:51,419:INFO:SubProcess create_model() called ==================================
2023-01-19 23:22:51,420:INFO:Initializing create_model()
2023-01-19 23:22:51,420:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f7f0929f0a0>, estimator=omp, fold=KFold(n_splits=10, random_state=3987, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7f0b1eaa60>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:22:51,420:INFO:Checking exceptions
2023-01-19 23:22:51,421:INFO:Importing libraries
2023-01-19 23:22:51,421:INFO:Copying training dataset
2023-01-19 23:22:51,427:INFO:Defining folds
2023-01-19 23:22:51,428:INFO:Declaring metric variables
2023-01-19 23:22:51,432:INFO:Importing untrained model
2023-01-19 23:22:51,437:INFO:Orthogonal Matching Pursuit Imported successfully
2023-01-19 23:22:51,446:INFO:Starting cross validation
2023-01-19 23:22:51,447:INFO:Cross validating with KFold(n_splits=10, random_state=3987, shuffle=True), n_jobs=-1
2023-01-19 23:22:51,504:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:22:51,517:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:22:51,534:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:22:51,549:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:22:51,557:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:22:51,582:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:22:51,601:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:22:51,620:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:22:51,630:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:22:51,637:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:22:51,666:INFO:Calculating mean and std
2023-01-19 23:22:51,667:INFO:Creating metrics dataframe
2023-01-19 23:22:51,671:INFO:Uploading results into container
2023-01-19 23:22:51,672:INFO:Uploading model into container now
2023-01-19 23:22:51,673:INFO:_master_model_container: 7
2023-01-19 23:22:51,673:INFO:_display_container: 2
2023-01-19 23:22:51,673:INFO:OrthogonalMatchingPursuit(fit_intercept=True, n_nonzero_coefs=None,
                          normalize='deprecated', precompute='auto', tol=None)
2023-01-19 23:22:51,673:INFO:create_model() successfully completed......................................
2023-01-19 23:22:51,824:INFO:SubProcess create_model() end ==================================
2023-01-19 23:22:51,824:INFO:Creating metrics dataframe
2023-01-19 23:22:51,843:INFO:Initializing Bayesian Ridge
2023-01-19 23:22:51,843:INFO:Total runtime is 0.46306988398234045 minutes
2023-01-19 23:22:51,847:INFO:SubProcess create_model() called ==================================
2023-01-19 23:22:51,848:INFO:Initializing create_model()
2023-01-19 23:22:51,848:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f7f0929f0a0>, estimator=br, fold=KFold(n_splits=10, random_state=3987, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7f0b1eaa60>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:22:51,848:INFO:Checking exceptions
2023-01-19 23:22:51,848:INFO:Importing libraries
2023-01-19 23:22:51,849:INFO:Copying training dataset
2023-01-19 23:22:51,854:INFO:Defining folds
2023-01-19 23:22:51,855:INFO:Declaring metric variables
2023-01-19 23:22:51,860:INFO:Importing untrained model
2023-01-19 23:22:51,864:INFO:Bayesian Ridge Imported successfully
2023-01-19 23:22:51,871:INFO:Starting cross validation
2023-01-19 23:22:51,873:INFO:Cross validating with KFold(n_splits=10, random_state=3987, shuffle=True), n_jobs=-1
2023-01-19 23:22:52,252:INFO:Calculating mean and std
2023-01-19 23:22:52,314:INFO:Creating metrics dataframe
2023-01-19 23:22:52,321:INFO:Uploading results into container
2023-01-19 23:22:52,322:INFO:Uploading model into container now
2023-01-19 23:22:52,323:INFO:_master_model_container: 8
2023-01-19 23:22:52,323:INFO:_display_container: 2
2023-01-19 23:22:52,324:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,
              normalize='deprecated', tol=0.001, verbose=False)
2023-01-19 23:22:52,324:INFO:create_model() successfully completed......................................
2023-01-19 23:22:52,471:INFO:SubProcess create_model() end ==================================
2023-01-19 23:22:52,472:INFO:Creating metrics dataframe
2023-01-19 23:22:52,490:INFO:Initializing Passive Aggressive Regressor
2023-01-19 23:22:52,490:INFO:Total runtime is 0.47385790348052975 minutes
2023-01-19 23:22:52,496:INFO:SubProcess create_model() called ==================================
2023-01-19 23:22:52,496:INFO:Initializing create_model()
2023-01-19 23:22:52,496:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f7f0929f0a0>, estimator=par, fold=KFold(n_splits=10, random_state=3987, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7f0b1eaa60>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:22:52,496:INFO:Checking exceptions
2023-01-19 23:22:52,497:INFO:Importing libraries
2023-01-19 23:22:52,497:INFO:Copying training dataset
2023-01-19 23:22:52,503:INFO:Defining folds
2023-01-19 23:22:52,503:INFO:Declaring metric variables
2023-01-19 23:22:52,509:INFO:Importing untrained model
2023-01-19 23:22:52,513:INFO:Passive Aggressive Regressor Imported successfully
2023-01-19 23:22:52,521:INFO:Starting cross validation
2023-01-19 23:22:52,523:INFO:Cross validating with KFold(n_splits=10, random_state=3987, shuffle=True), n_jobs=-1
2023-01-19 23:22:52,758:INFO:Calculating mean and std
2023-01-19 23:22:52,759:INFO:Creating metrics dataframe
2023-01-19 23:22:52,762:INFO:Uploading results into container
2023-01-19 23:22:52,763:INFO:Uploading model into container now
2023-01-19 23:22:52,764:INFO:_master_model_container: 9
2023-01-19 23:22:52,770:INFO:_display_container: 2
2023-01-19 23:22:52,771:INFO:PassiveAggressiveRegressor(C=1.0, average=False, early_stopping=False,
                           epsilon=0.1, fit_intercept=True,
                           loss='epsilon_insensitive', max_iter=1000,
                           n_iter_no_change=5, random_state=3987, shuffle=True,
                           tol=0.001, validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-01-19 23:22:52,771:INFO:create_model() successfully completed......................................
2023-01-19 23:22:52,899:INFO:SubProcess create_model() end ==================================
2023-01-19 23:22:52,902:INFO:Creating metrics dataframe
2023-01-19 23:22:52,920:INFO:Initializing Huber Regressor
2023-01-19 23:22:52,920:INFO:Total runtime is 0.4810309330622355 minutes
2023-01-19 23:22:52,924:INFO:SubProcess create_model() called ==================================
2023-01-19 23:22:52,929:INFO:Initializing create_model()
2023-01-19 23:22:52,935:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f7f0929f0a0>, estimator=huber, fold=KFold(n_splits=10, random_state=3987, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7f0b1eaa60>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:22:52,935:INFO:Checking exceptions
2023-01-19 23:22:52,935:INFO:Importing libraries
2023-01-19 23:22:52,935:INFO:Copying training dataset
2023-01-19 23:22:52,941:INFO:Defining folds
2023-01-19 23:22:52,945:INFO:Declaring metric variables
2023-01-19 23:22:52,955:INFO:Importing untrained model
2023-01-19 23:22:52,963:INFO:Huber Regressor Imported successfully
2023-01-19 23:22:52,975:INFO:Starting cross validation
2023-01-19 23:22:52,984:INFO:Cross validating with KFold(n_splits=10, random_state=3987, shuffle=True), n_jobs=-1
2023-01-19 23:22:53,361:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-19 23:22:53,361:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-19 23:22:53,361:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-19 23:22:53,361:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-19 23:22:53,364:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-19 23:22:53,361:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-19 23:22:53,363:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-19 23:22:53,361:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-19 23:22:53,511:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-19 23:22:53,512:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-19 23:22:53,531:INFO:Calculating mean and std
2023-01-19 23:22:53,533:INFO:Creating metrics dataframe
2023-01-19 23:22:53,546:INFO:Uploading results into container
2023-01-19 23:22:53,552:INFO:Uploading model into container now
2023-01-19 23:22:53,555:INFO:_master_model_container: 10
2023-01-19 23:22:53,558:INFO:_display_container: 2
2023-01-19 23:22:53,565:INFO:HuberRegressor(alpha=0.0001, epsilon=1.35, fit_intercept=True, max_iter=100,
               tol=1e-05, warm_start=False)
2023-01-19 23:22:53,568:INFO:create_model() successfully completed......................................
2023-01-19 23:22:53,760:INFO:SubProcess create_model() end ==================================
2023-01-19 23:22:53,760:INFO:Creating metrics dataframe
2023-01-19 23:22:53,780:INFO:Initializing K Neighbors Regressor
2023-01-19 23:22:53,781:INFO:Total runtime is 0.49537210067113235 minutes
2023-01-19 23:22:53,791:INFO:SubProcess create_model() called ==================================
2023-01-19 23:22:53,793:INFO:Initializing create_model()
2023-01-19 23:22:53,798:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f7f0929f0a0>, estimator=knn, fold=KFold(n_splits=10, random_state=3987, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7f0b1eaa60>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:22:53,802:INFO:Checking exceptions
2023-01-19 23:22:53,805:INFO:Importing libraries
2023-01-19 23:22:53,812:INFO:Copying training dataset
2023-01-19 23:22:53,824:INFO:Defining folds
2023-01-19 23:22:53,826:INFO:Declaring metric variables
2023-01-19 23:22:53,831:INFO:Importing untrained model
2023-01-19 23:22:53,839:INFO:K Neighbors Regressor Imported successfully
2023-01-19 23:22:53,850:INFO:Starting cross validation
2023-01-19 23:22:53,854:INFO:Cross validating with KFold(n_splits=10, random_state=3987, shuffle=True), n_jobs=-1
2023-01-19 23:22:54,154:INFO:Calculating mean and std
2023-01-19 23:22:54,159:INFO:Creating metrics dataframe
2023-01-19 23:22:54,165:INFO:Uploading results into container
2023-01-19 23:22:54,168:INFO:Uploading model into container now
2023-01-19 23:22:54,171:INFO:_master_model_container: 11
2023-01-19 23:22:54,174:INFO:_display_container: 2
2023-01-19 23:22:54,183:INFO:KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
                    metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                    weights='uniform')
2023-01-19 23:22:54,186:INFO:create_model() successfully completed......................................
2023-01-19 23:22:54,343:INFO:SubProcess create_model() end ==================================
2023-01-19 23:22:54,346:INFO:Creating metrics dataframe
2023-01-19 23:22:54,368:INFO:Initializing Decision Tree Regressor
2023-01-19 23:22:54,370:INFO:Total runtime is 0.5051985184351603 minutes
2023-01-19 23:22:54,376:INFO:SubProcess create_model() called ==================================
2023-01-19 23:22:54,377:INFO:Initializing create_model()
2023-01-19 23:22:54,380:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f7f0929f0a0>, estimator=dt, fold=KFold(n_splits=10, random_state=3987, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7f0b1eaa60>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:22:54,383:INFO:Checking exceptions
2023-01-19 23:22:54,386:INFO:Importing libraries
2023-01-19 23:22:54,395:INFO:Copying training dataset
2023-01-19 23:22:54,402:INFO:Defining folds
2023-01-19 23:22:54,405:INFO:Declaring metric variables
2023-01-19 23:22:54,412:INFO:Importing untrained model
2023-01-19 23:22:54,419:INFO:Decision Tree Regressor Imported successfully
2023-01-19 23:22:54,432:INFO:Starting cross validation
2023-01-19 23:22:54,435:INFO:Cross validating with KFold(n_splits=10, random_state=3987, shuffle=True), n_jobs=-1
2023-01-19 23:22:54,683:INFO:Calculating mean and std
2023-01-19 23:22:54,693:INFO:Creating metrics dataframe
2023-01-19 23:22:54,699:INFO:Uploading results into container
2023-01-19 23:22:54,701:INFO:Uploading model into container now
2023-01-19 23:22:54,704:INFO:_master_model_container: 12
2023-01-19 23:22:54,714:INFO:_display_container: 2
2023-01-19 23:22:54,718:INFO:DecisionTreeRegressor(ccp_alpha=0.0, criterion='squared_error', max_depth=None,
                      max_features=None, max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      random_state=3987, splitter='best')
2023-01-19 23:22:54,722:INFO:create_model() successfully completed......................................
2023-01-19 23:22:54,870:INFO:SubProcess create_model() end ==================================
2023-01-19 23:22:54,888:INFO:Creating metrics dataframe
2023-01-19 23:22:54,906:INFO:Initializing Random Forest Regressor
2023-01-19 23:22:54,906:INFO:Total runtime is 0.5141245007514953 minutes
2023-01-19 23:22:54,910:INFO:SubProcess create_model() called ==================================
2023-01-19 23:22:54,910:INFO:Initializing create_model()
2023-01-19 23:22:54,910:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f7f0929f0a0>, estimator=rf, fold=KFold(n_splits=10, random_state=3987, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7f0b1eaa60>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:22:54,910:INFO:Checking exceptions
2023-01-19 23:22:54,910:INFO:Importing libraries
2023-01-19 23:22:54,911:INFO:Copying training dataset
2023-01-19 23:22:54,916:INFO:Defining folds
2023-01-19 23:22:54,917:INFO:Declaring metric variables
2023-01-19 23:22:54,920:INFO:Importing untrained model
2023-01-19 23:22:54,925:INFO:Random Forest Regressor Imported successfully
2023-01-19 23:22:54,934:INFO:Starting cross validation
2023-01-19 23:22:54,936:INFO:Cross validating with KFold(n_splits=10, random_state=3987, shuffle=True), n_jobs=-1
2023-01-19 23:22:58,319:INFO:Calculating mean and std
2023-01-19 23:22:58,320:INFO:Creating metrics dataframe
2023-01-19 23:22:58,325:INFO:Uploading results into container
2023-01-19 23:22:58,326:INFO:Uploading model into container now
2023-01-19 23:22:58,326:INFO:_master_model_container: 13
2023-01-19 23:22:58,327:INFO:_display_container: 2
2023-01-19 23:22:58,327:INFO:RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='squared_error',
                      max_depth=None, max_features=1.0, max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,
                      oob_score=False, random_state=3987, verbose=0,
                      warm_start=False)
2023-01-19 23:22:58,327:INFO:create_model() successfully completed......................................
2023-01-19 23:22:58,522:INFO:SubProcess create_model() end ==================================
2023-01-19 23:22:58,522:INFO:Creating metrics dataframe
2023-01-19 23:22:58,541:INFO:Initializing Extra Trees Regressor
2023-01-19 23:22:58,541:INFO:Total runtime is 0.5747135678927103 minutes
2023-01-19 23:22:58,546:INFO:SubProcess create_model() called ==================================
2023-01-19 23:22:58,546:INFO:Initializing create_model()
2023-01-19 23:22:58,547:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f7f0929f0a0>, estimator=et, fold=KFold(n_splits=10, random_state=3987, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7f0b1eaa60>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:22:58,547:INFO:Checking exceptions
2023-01-19 23:22:58,547:INFO:Importing libraries
2023-01-19 23:22:58,547:INFO:Copying training dataset
2023-01-19 23:22:58,555:INFO:Defining folds
2023-01-19 23:22:58,555:INFO:Declaring metric variables
2023-01-19 23:22:58,559:INFO:Importing untrained model
2023-01-19 23:22:58,565:INFO:Extra Trees Regressor Imported successfully
2023-01-19 23:22:58,579:INFO:Starting cross validation
2023-01-19 23:22:58,581:INFO:Cross validating with KFold(n_splits=10, random_state=3987, shuffle=True), n_jobs=-1
2023-01-19 23:23:02,159:INFO:Calculating mean and std
2023-01-19 23:23:02,161:INFO:Creating metrics dataframe
2023-01-19 23:23:02,195:INFO:Uploading results into container
2023-01-19 23:23:02,196:INFO:Uploading model into container now
2023-01-19 23:23:02,197:INFO:_master_model_container: 14
2023-01-19 23:23:02,197:INFO:_display_container: 2
2023-01-19 23:23:02,197:INFO:ExtraTreesRegressor(bootstrap=False, ccp_alpha=0.0, criterion='squared_error',
                    max_depth=None, max_features=1.0, max_leaf_nodes=None,
                    max_samples=None, min_impurity_decrease=0.0,
                    min_samples_leaf=1, min_samples_split=2,
                    min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,
                    oob_score=False, random_state=3987, verbose=0,
                    warm_start=False)
2023-01-19 23:23:02,197:INFO:create_model() successfully completed......................................
2023-01-19 23:23:02,345:INFO:SubProcess create_model() end ==================================
2023-01-19 23:23:02,345:INFO:Creating metrics dataframe
2023-01-19 23:23:02,362:INFO:Initializing AdaBoost Regressor
2023-01-19 23:23:02,362:INFO:Total runtime is 0.638393751780192 minutes
2023-01-19 23:23:02,367:INFO:SubProcess create_model() called ==================================
2023-01-19 23:23:02,367:INFO:Initializing create_model()
2023-01-19 23:23:02,367:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f7f0929f0a0>, estimator=ada, fold=KFold(n_splits=10, random_state=3987, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7f0b1eaa60>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:23:02,367:INFO:Checking exceptions
2023-01-19 23:23:02,368:INFO:Importing libraries
2023-01-19 23:23:02,368:INFO:Copying training dataset
2023-01-19 23:23:02,373:INFO:Defining folds
2023-01-19 23:23:02,373:INFO:Declaring metric variables
2023-01-19 23:23:02,377:INFO:Importing untrained model
2023-01-19 23:23:02,382:INFO:AdaBoost Regressor Imported successfully
2023-01-19 23:23:02,391:INFO:Starting cross validation
2023-01-19 23:23:02,393:INFO:Cross validating with KFold(n_splits=10, random_state=3987, shuffle=True), n_jobs=-1
2023-01-19 23:23:03,588:INFO:Calculating mean and std
2023-01-19 23:23:03,590:INFO:Creating metrics dataframe
2023-01-19 23:23:03,593:INFO:Uploading results into container
2023-01-19 23:23:03,594:INFO:Uploading model into container now
2023-01-19 23:23:03,594:INFO:_master_model_container: 15
2023-01-19 23:23:03,595:INFO:_display_container: 2
2023-01-19 23:23:03,595:INFO:AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',
                  n_estimators=50, random_state=3987)
2023-01-19 23:23:03,595:INFO:create_model() successfully completed......................................
2023-01-19 23:23:03,727:INFO:SubProcess create_model() end ==================================
2023-01-19 23:23:03,727:INFO:Creating metrics dataframe
2023-01-19 23:23:03,746:INFO:Initializing Gradient Boosting Regressor
2023-01-19 23:23:03,746:INFO:Total runtime is 0.6614557345708211 minutes
2023-01-19 23:23:03,751:INFO:SubProcess create_model() called ==================================
2023-01-19 23:23:03,751:INFO:Initializing create_model()
2023-01-19 23:23:03,751:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f7f0929f0a0>, estimator=gbr, fold=KFold(n_splits=10, random_state=3987, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7f0b1eaa60>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:23:03,751:INFO:Checking exceptions
2023-01-19 23:23:03,752:INFO:Importing libraries
2023-01-19 23:23:03,752:INFO:Copying training dataset
2023-01-19 23:23:03,758:INFO:Defining folds
2023-01-19 23:23:03,758:INFO:Declaring metric variables
2023-01-19 23:23:03,762:INFO:Importing untrained model
2023-01-19 23:23:03,767:INFO:Gradient Boosting Regressor Imported successfully
2023-01-19 23:23:03,774:INFO:Starting cross validation
2023-01-19 23:23:03,776:INFO:Cross validating with KFold(n_splits=10, random_state=3987, shuffle=True), n_jobs=-1
2023-01-19 23:23:05,252:INFO:Calculating mean and std
2023-01-19 23:23:05,254:INFO:Creating metrics dataframe
2023-01-19 23:23:05,257:INFO:Uploading results into container
2023-01-19 23:23:05,258:INFO:Uploading model into container now
2023-01-19 23:23:05,259:INFO:_master_model_container: 16
2023-01-19 23:23:05,259:INFO:_display_container: 2
2023-01-19 23:23:05,259:INFO:GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',
                          init=None, learning_rate=0.1, loss='squared_error',
                          max_depth=3, max_features=None, max_leaf_nodes=None,
                          min_impurity_decrease=0.0, min_samples_leaf=1,
                          min_samples_split=2, min_weight_fraction_leaf=0.0,
                          n_estimators=100, n_iter_no_change=None,
                          random_state=3987, subsample=1.0, tol=0.0001,
                          validation_fraction=0.1, verbose=0, warm_start=False)
2023-01-19 23:23:05,259:INFO:create_model() successfully completed......................................
2023-01-19 23:23:05,390:INFO:SubProcess create_model() end ==================================
2023-01-19 23:23:05,390:INFO:Creating metrics dataframe
2023-01-19 23:23:05,408:INFO:Initializing Extreme Gradient Boosting
2023-01-19 23:23:05,409:INFO:Total runtime is 0.6891704360644022 minutes
2023-01-19 23:23:05,413:INFO:SubProcess create_model() called ==================================
2023-01-19 23:23:05,413:INFO:Initializing create_model()
2023-01-19 23:23:05,414:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f7f0929f0a0>, estimator=xgboost, fold=KFold(n_splits=10, random_state=3987, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7f0b1eaa60>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:23:05,414:INFO:Checking exceptions
2023-01-19 23:23:05,414:INFO:Importing libraries
2023-01-19 23:23:05,414:INFO:Copying training dataset
2023-01-19 23:23:05,421:INFO:Defining folds
2023-01-19 23:23:05,421:INFO:Declaring metric variables
2023-01-19 23:23:05,426:INFO:Importing untrained model
2023-01-19 23:23:05,430:INFO:Extreme Gradient Boosting Imported successfully
2023-01-19 23:23:05,438:INFO:Starting cross validation
2023-01-19 23:23:05,440:INFO:Cross validating with KFold(n_splits=10, random_state=3987, shuffle=True), n_jobs=-1
2023-01-19 23:23:09,848:INFO:Calculating mean and std
2023-01-19 23:23:09,849:INFO:Creating metrics dataframe
2023-01-19 23:23:09,853:INFO:Uploading results into container
2023-01-19 23:23:09,854:INFO:Uploading model into container now
2023-01-19 23:23:09,854:INFO:_master_model_container: 17
2023-01-19 23:23:09,854:INFO:_display_container: 2
2023-01-19 23:23:09,855:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             objective='reg:squarederror', predictor=None, ...)
2023-01-19 23:23:09,855:INFO:create_model() successfully completed......................................
2023-01-19 23:23:09,996:INFO:SubProcess create_model() end ==================================
2023-01-19 23:23:09,997:INFO:Creating metrics dataframe
2023-01-19 23:23:10,024:INFO:Initializing Light Gradient Boosting Machine
2023-01-19 23:23:10,024:INFO:Total runtime is 0.7660884698232014 minutes
2023-01-19 23:23:10,028:INFO:SubProcess create_model() called ==================================
2023-01-19 23:23:10,028:INFO:Initializing create_model()
2023-01-19 23:23:10,028:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f7f0929f0a0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=3987, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7f0b1eaa60>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:23:10,028:INFO:Checking exceptions
2023-01-19 23:23:10,028:INFO:Importing libraries
2023-01-19 23:23:10,029:INFO:Copying training dataset
2023-01-19 23:23:10,048:INFO:Defining folds
2023-01-19 23:23:10,048:INFO:Declaring metric variables
2023-01-19 23:23:10,077:INFO:Importing untrained model
2023-01-19 23:23:10,152:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-19 23:23:10,161:INFO:Starting cross validation
2023-01-19 23:23:10,162:INFO:Cross validating with KFold(n_splits=10, random_state=3987, shuffle=True), n_jobs=-1
2023-01-19 23:23:15,558:INFO:Calculating mean and std
2023-01-19 23:23:15,559:INFO:Creating metrics dataframe
2023-01-19 23:23:15,563:INFO:Uploading results into container
2023-01-19 23:23:15,563:INFO:Uploading model into container now
2023-01-19 23:23:15,563:INFO:_master_model_container: 18
2023-01-19 23:23:15,564:INFO:_display_container: 2
2023-01-19 23:23:15,564:INFO:LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
              importance_type='split', learning_rate=0.1, max_depth=-1,
              min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
              n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
              random_state=3987, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
              subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-01-19 23:23:15,564:INFO:create_model() successfully completed......................................
2023-01-19 23:23:15,692:INFO:SubProcess create_model() end ==================================
2023-01-19 23:23:15,693:INFO:Creating metrics dataframe
2023-01-19 23:23:15,711:INFO:Initializing CatBoost Regressor
2023-01-19 23:23:15,712:INFO:Total runtime is 0.8608855843544005 minutes
2023-01-19 23:23:15,716:INFO:SubProcess create_model() called ==================================
2023-01-19 23:23:15,717:INFO:Initializing create_model()
2023-01-19 23:23:15,717:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f7f0929f0a0>, estimator=catboost, fold=KFold(n_splits=10, random_state=3987, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7f0b1eaa60>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:23:15,717:INFO:Checking exceptions
2023-01-19 23:23:15,717:INFO:Importing libraries
2023-01-19 23:23:15,717:INFO:Copying training dataset
2023-01-19 23:23:15,723:INFO:Defining folds
2023-01-19 23:23:15,724:INFO:Declaring metric variables
2023-01-19 23:23:15,727:INFO:Importing untrained model
2023-01-19 23:23:15,809:INFO:CatBoost Regressor Imported successfully
2023-01-19 23:23:15,820:INFO:Starting cross validation
2023-01-19 23:23:15,822:INFO:Cross validating with KFold(n_splits=10, random_state=3987, shuffle=True), n_jobs=-1
2023-01-19 23:23:36,412:INFO:Calculating mean and std
2023-01-19 23:23:36,423:INFO:Creating metrics dataframe
2023-01-19 23:23:36,437:INFO:Uploading results into container
2023-01-19 23:23:36,438:INFO:Uploading model into container now
2023-01-19 23:23:36,440:INFO:_master_model_container: 19
2023-01-19 23:23:36,440:INFO:_display_container: 2
2023-01-19 23:23:36,440:INFO:<catboost.core.CatBoostRegressor object at 0x7f7f09571be0>
2023-01-19 23:23:36,440:INFO:create_model() successfully completed......................................
2023-01-19 23:23:36,895:INFO:SubProcess create_model() end ==================================
2023-01-19 23:23:36,895:INFO:Creating metrics dataframe
2023-01-19 23:23:36,921:INFO:Initializing Dummy Regressor
2023-01-19 23:23:36,922:INFO:Total runtime is 1.2143845677375793 minutes
2023-01-19 23:23:36,926:INFO:SubProcess create_model() called ==================================
2023-01-19 23:23:36,927:INFO:Initializing create_model()
2023-01-19 23:23:36,927:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f7f0929f0a0>, estimator=dummy, fold=KFold(n_splits=10, random_state=3987, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7f0b1eaa60>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:23:36,927:INFO:Checking exceptions
2023-01-19 23:23:36,927:INFO:Importing libraries
2023-01-19 23:23:36,928:INFO:Copying training dataset
2023-01-19 23:23:36,938:INFO:Defining folds
2023-01-19 23:23:36,938:INFO:Declaring metric variables
2023-01-19 23:23:36,944:INFO:Importing untrained model
2023-01-19 23:23:36,952:INFO:Dummy Regressor Imported successfully
2023-01-19 23:23:36,961:INFO:Starting cross validation
2023-01-19 23:23:36,963:INFO:Cross validating with KFold(n_splits=10, random_state=3987, shuffle=True), n_jobs=-1
2023-01-19 23:23:37,540:INFO:Calculating mean and std
2023-01-19 23:23:37,542:INFO:Creating metrics dataframe
2023-01-19 23:23:37,546:INFO:Uploading results into container
2023-01-19 23:23:37,548:INFO:Uploading model into container now
2023-01-19 23:23:37,549:INFO:_master_model_container: 20
2023-01-19 23:23:37,549:INFO:_display_container: 2
2023-01-19 23:23:37,552:INFO:DummyRegressor(constant=None, quantile=None, strategy='mean')
2023-01-19 23:23:37,553:INFO:create_model() successfully completed......................................
2023-01-19 23:23:37,792:INFO:SubProcess create_model() end ==================================
2023-01-19 23:23:37,792:INFO:Creating metrics dataframe
2023-01-19 23:23:37,833:INFO:Initializing create_model()
2023-01-19 23:23:37,833:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f7f0929f0a0>, estimator=<catboost.core.CatBoostRegressor object at 0x7f7f09571be0>, fold=KFold(n_splits=10, random_state=3987, shuffle=True), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:23:37,833:INFO:Checking exceptions
2023-01-19 23:23:37,849:INFO:Importing libraries
2023-01-19 23:23:37,849:INFO:Copying training dataset
2023-01-19 23:23:37,854:INFO:Defining folds
2023-01-19 23:23:37,854:INFO:Declaring metric variables
2023-01-19 23:23:37,854:INFO:Importing untrained model
2023-01-19 23:23:37,854:INFO:Declaring custom model
2023-01-19 23:23:37,856:INFO:CatBoost Regressor Imported successfully
2023-01-19 23:23:37,857:INFO:Cross validation set to False
2023-01-19 23:23:37,857:INFO:Fitting Model
2023-01-19 23:23:40,905:INFO:<catboost.core.CatBoostRegressor object at 0x7f7f0b02d640>
2023-01-19 23:23:40,905:INFO:create_model() successfully completed......................................
2023-01-19 23:23:41,113:INFO:_master_model_container: 20
2023-01-19 23:23:41,113:INFO:_display_container: 2
2023-01-19 23:23:41,113:INFO:<catboost.core.CatBoostRegressor object at 0x7f7f0b02d640>
2023-01-19 23:23:41,113:INFO:compare_models() successfully completed......................................
2023-01-19 23:27:53,990:INFO:Initializing create_model()
2023-01-19 23:27:53,993:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f7f0929f0a0>, estimator=catboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:27:53,993:INFO:Checking exceptions
2023-01-19 23:27:54,229:INFO:Importing libraries
2023-01-19 23:27:54,230:INFO:Copying training dataset
2023-01-19 23:27:54,249:INFO:Defining folds
2023-01-19 23:27:54,249:INFO:Declaring metric variables
2023-01-19 23:27:54,254:INFO:Importing untrained model
2023-01-19 23:27:54,270:INFO:CatBoost Regressor Imported successfully
2023-01-19 23:27:54,281:INFO:Starting cross validation
2023-01-19 23:27:54,290:INFO:Cross validating with KFold(n_splits=10, random_state=3987, shuffle=True), n_jobs=-1
2023-01-19 23:28:10,732:INFO:Calculating mean and std
2023-01-19 23:28:10,737:INFO:Creating metrics dataframe
2023-01-19 23:28:10,786:INFO:Finalizing model
2023-01-19 23:28:13,879:INFO:Uploading results into container
2023-01-19 23:28:13,881:INFO:Uploading model into container now
2023-01-19 23:28:14,004:INFO:_master_model_container: 21
2023-01-19 23:28:14,004:INFO:_display_container: 3
2023-01-19 23:28:14,005:INFO:<catboost.core.CatBoostRegressor object at 0x7f7f093f0e80>
2023-01-19 23:28:14,005:INFO:create_model() successfully completed......................................
2023-01-19 23:28:15,502:INFO:Initializing create_model()
2023-01-19 23:28:15,503:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f7f0929f0a0>, estimator=br, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:28:15,503:INFO:Checking exceptions
2023-01-19 23:28:15,530:INFO:Importing libraries
2023-01-19 23:28:15,530:INFO:Copying training dataset
2023-01-19 23:28:15,537:INFO:Defining folds
2023-01-19 23:28:15,537:INFO:Declaring metric variables
2023-01-19 23:28:15,543:INFO:Importing untrained model
2023-01-19 23:28:15,551:INFO:Bayesian Ridge Imported successfully
2023-01-19 23:28:15,566:INFO:Starting cross validation
2023-01-19 23:28:15,568:INFO:Cross validating with KFold(n_splits=10, random_state=3987, shuffle=True), n_jobs=-1
2023-01-19 23:28:17,447:INFO:Calculating mean and std
2023-01-19 23:28:17,448:INFO:Creating metrics dataframe
2023-01-19 23:28:17,454:INFO:Finalizing model
2023-01-19 23:28:17,628:INFO:Uploading results into container
2023-01-19 23:28:17,629:INFO:Uploading model into container now
2023-01-19 23:28:17,644:INFO:_master_model_container: 22
2023-01-19 23:28:17,644:INFO:_display_container: 4
2023-01-19 23:28:17,645:INFO:BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, alpha_init=None,
              compute_score=False, copy_X=True, fit_intercept=True,
              lambda_1=1e-06, lambda_2=1e-06, lambda_init=None, n_iter=300,
              normalize='deprecated', tol=0.001, verbose=False)
2023-01-19 23:28:17,645:INFO:create_model() successfully completed......................................
2023-01-19 23:28:38,880:INFO:Initializing create_model()
2023-01-19 23:28:38,881:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f7f0929f0a0>, estimator=catboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:28:38,881:INFO:Checking exceptions
2023-01-19 23:28:38,926:INFO:Importing libraries
2023-01-19 23:28:38,926:INFO:Copying training dataset
2023-01-19 23:28:38,939:INFO:Defining folds
2023-01-19 23:28:38,940:INFO:Declaring metric variables
2023-01-19 23:28:38,944:INFO:Importing untrained model
2023-01-19 23:28:38,954:INFO:CatBoost Regressor Imported successfully
2023-01-19 23:28:38,997:INFO:Starting cross validation
2023-01-19 23:28:39,001:INFO:Cross validating with KFold(n_splits=10, random_state=3987, shuffle=True), n_jobs=-1
2023-01-19 23:28:56,236:INFO:Calculating mean and std
2023-01-19 23:28:56,243:INFO:Creating metrics dataframe
2023-01-19 23:28:56,256:INFO:Finalizing model
2023-01-19 23:28:59,614:INFO:Uploading results into container
2023-01-19 23:28:59,615:INFO:Uploading model into container now
2023-01-19 23:28:59,631:INFO:_master_model_container: 23
2023-01-19 23:28:59,640:INFO:_display_container: 5
2023-01-19 23:28:59,641:INFO:<catboost.core.CatBoostRegressor object at 0x7f7f0910a220>
2023-01-19 23:28:59,641:INFO:create_model() successfully completed......................................
2023-01-19 23:29:00,105:INFO:Initializing tune_model()
2023-01-19 23:29:00,105:INFO:tune_model(estimator=<catboost.core.CatBoostRegressor object at 0x7f7f0910a220>, fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f7f0929f0a0>)
2023-01-19 23:29:00,105:INFO:Checking exceptions
2023-01-19 23:29:00,128:INFO:Copying training dataset
2023-01-19 23:29:00,135:INFO:Checking base model
2023-01-19 23:29:00,136:INFO:Base model : CatBoost Regressor
2023-01-19 23:29:00,142:INFO:Declaring metric variables
2023-01-19 23:29:00,148:INFO:Defining Hyperparameters
2023-01-19 23:29:00,315:INFO:Tuning with n_jobs=-1
2023-01-19 23:29:00,352:INFO:Initializing RandomizedSearchCV
2023-01-19 23:31:14,489:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: 
20 fits failed out of a total of 100.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
20 fits failed with the following error:
Traceback (most recent call last):
  File "/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 216, in fit
    _fit_one(self._final_estimator, X, y, **fit_params_last_step)
  File "/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 54, in _fit_one
    transformer.fit(*args, **fit_params)
  File "/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py", line 5730, in fit
    return self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline,
  File "/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py", line 2339, in _fit
    train_params = self._prepare_train_params(
  File "/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/catboost/core.py", line 2266, in _prepare_train_params
    _check_train_params(params)
  File "_catboost.pyx", line 6080, in _catboost._check_train_params
  File "_catboost.pyx", line 6099, in _catboost._check_train_params
_catboost.CatBoostError: catboost/private/libs/options/boosting_options.cpp:79: Learning rate should be non-zero

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-01-19 23:31:14,942:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [        nan         nan  0.87861794 -0.0072288   0.87767116  0.03968559
  0.83306655  0.83679183 -0.01525739  0.87771443]
  warnings.warn(

2023-01-19 23:31:15,158:INFO:best_params: {'actual_estimator__random_strength': 0.3, 'actual_estimator__n_estimators': 300, 'actual_estimator__l2_leaf_reg': 8, 'actual_estimator__eta': 1e-07, 'actual_estimator__depth': 11}
2023-01-19 23:31:15,414:INFO:Hyperparameter search completed
2023-01-19 23:31:15,450:INFO:SubProcess create_model() called ==================================
2023-01-19 23:31:15,501:INFO:Initializing create_model()
2023-01-19 23:31:15,501:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f7f0929f0a0>, estimator=<catboost.core.CatBoostRegressor object at 0x7f7f09cd5550>, fold=KFold(n_splits=10, random_state=3987, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7f2599ad00>, model_only=True, return_train_score=False, kwargs={'random_strength': 0.3, 'n_estimators': 300, 'l2_leaf_reg': 8, 'eta': 1e-07, 'depth': 11})
2023-01-19 23:31:15,501:INFO:Checking exceptions
2023-01-19 23:31:15,515:INFO:Importing libraries
2023-01-19 23:31:15,624:INFO:Copying training dataset
2023-01-19 23:31:16,142:INFO:Defining folds
2023-01-19 23:31:16,142:INFO:Declaring metric variables
2023-01-19 23:31:16,259:INFO:Importing untrained model
2023-01-19 23:31:16,259:INFO:Declaring custom model
2023-01-19 23:31:16,465:INFO:CatBoost Regressor Imported successfully
2023-01-19 23:31:16,482:INFO:Starting cross validation
2023-01-19 23:31:16,493:INFO:Cross validating with KFold(n_splits=10, random_state=3987, shuffle=True), n_jobs=-1
2023-01-19 23:34:47,876:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-19 23:34:47,877:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-19 23:34:47,877:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-19 23:34:47,877:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-19 23:34:48,851:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-01-19 23:34:49,171:INFO:PyCaret RegressionExperiment
2023-01-19 23:34:49,172:INFO:Logging name: reg-default-name
2023-01-19 23:34:49,172:INFO:ML Usecase: MLUsecase.REGRESSION
2023-01-19 23:34:49,172:INFO:version 3.0.0.rc8
2023-01-19 23:34:49,172:INFO:Initializing setup()
2023-01-19 23:34:49,172:INFO:self.USI: 1f77
2023-01-19 23:34:49,172:INFO:self._variable_keys: {'gpu_n_jobs_param', 'logging_param', 'target_param', 'y_train', 'transform_target_param', 'data', 'gpu_param', 'exp_id', 'pipeline', 'log_plots_param', 'y', 'fold_groups_param', 'fold_generator', 'X_train', 'html_param', '_available_plots', 'fold_shuffle_param', 'X', 'USI', 'n_jobs_param', 'memory', 'y_test', 'X_test', 'exp_name_log', 'idx', 'seed', '_ml_usecase'}
2023-01-19 23:34:49,172:INFO:Checking environment
2023-01-19 23:34:49,172:INFO:python_version: 3.9.12
2023-01-19 23:34:49,172:INFO:python_build: ('main', 'Apr  5 2022 01:53:17')
2023-01-19 23:34:49,172:INFO:machine: x86_64
2023-01-19 23:34:49,172:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-01-19 23:34:49,172:INFO:Memory: svmem(total=8589934592, available=2325028864, percent=72.9, used=5615030272, free=18599936, active=2313080832, inactive=2214965248, wired=3301949440)
2023-01-19 23:34:49,172:INFO:Physical Core: 4
2023-01-19 23:34:49,172:INFO:Logical Core: 8
2023-01-19 23:34:49,172:INFO:Checking libraries
2023-01-19 23:34:49,172:INFO:System:
2023-01-19 23:34:49,172:INFO:    python: 3.9.12 (main, Apr  5 2022, 01:53:17)  [Clang 12.0.0 ]
2023-01-19 23:34:49,172:INFO:executable: /Users/hiroto/opt/anaconda3/bin/python
2023-01-19 23:34:49,172:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-01-19 23:34:49,172:INFO:PyCaret required dependencies:
2023-01-19 23:34:49,173:INFO:                 pip: 21.2.4
2023-01-19 23:34:49,173:INFO:          setuptools: 66.0.0
2023-01-19 23:34:49,173:INFO:             pycaret: 3.0.0rc8
2023-01-19 23:34:49,173:INFO:             IPython: 8.8.0
2023-01-19 23:34:49,173:INFO:          ipywidgets: 8.0.4
2023-01-19 23:34:49,173:INFO:                tqdm: 4.64.1
2023-01-19 23:34:49,173:INFO:               numpy: 1.23.5
2023-01-19 23:34:49,173:INFO:              pandas: 1.5.3
2023-01-19 23:34:49,173:INFO:              jinja2: 3.1.2
2023-01-19 23:34:49,173:INFO:               scipy: 1.10.0
2023-01-19 23:34:49,173:INFO:              joblib: 1.2.0
2023-01-19 23:34:49,173:INFO:             sklearn: 1.1.3
2023-01-19 23:34:49,173:INFO:                pyod: 1.0.7
2023-01-19 23:34:49,173:INFO:            imblearn: 0.10.1
2023-01-19 23:34:49,173:INFO:   category_encoders: 2.6.0
2023-01-19 23:34:49,173:INFO:            lightgbm: 3.3.4
2023-01-19 23:34:49,173:INFO:               numba: 0.56.4
2023-01-19 23:34:49,173:INFO:            requests: 2.28.2
2023-01-19 23:34:49,173:INFO:          matplotlib: 3.6.3
2023-01-19 23:34:49,173:INFO:          scikitplot: 0.3.7
2023-01-19 23:34:49,173:INFO:         yellowbrick: 1.5
2023-01-19 23:34:49,173:INFO:              plotly: 5.12.0
2023-01-19 23:34:49,173:INFO:             kaleido: 0.2.1
2023-01-19 23:34:49,174:INFO:         statsmodels: 0.13.5
2023-01-19 23:34:49,174:INFO:              sktime: 0.15.1
2023-01-19 23:34:49,174:INFO:               tbats: 1.1.2
2023-01-19 23:34:49,174:INFO:            pmdarima: 2.0.2
2023-01-19 23:34:49,174:INFO:              psutil: 5.9.4
2023-01-19 23:34:49,174:INFO:PyCaret optional dependencies:
2023-01-19 23:34:49,177:INFO:                shap: 0.41.0
2023-01-19 23:34:49,177:INFO:           interpret: Not installed
2023-01-19 23:34:49,177:INFO:                umap: 0.5.3
2023-01-19 23:34:49,177:INFO:    pandas_profiling: 3.6.2
2023-01-19 23:34:49,177:INFO:  explainerdashboard: Not installed
2023-01-19 23:34:49,177:INFO:             autoviz: Not installed
2023-01-19 23:34:49,177:INFO:           fairlearn: Not installed
2023-01-19 23:34:49,177:INFO:             xgboost: 1.7.3
2023-01-19 23:34:49,177:INFO:            catboost: 1.1.1
2023-01-19 23:34:49,177:INFO:              kmodes: 0.12.2
2023-01-19 23:34:49,177:INFO:             mlxtend: 0.21.0
2023-01-19 23:34:49,177:INFO:       statsforecast: Not installed
2023-01-19 23:34:49,178:INFO:        tune_sklearn: Not installed
2023-01-19 23:34:49,178:INFO:                 ray: Not installed
2023-01-19 23:34:49,178:INFO:            hyperopt: Not installed
2023-01-19 23:34:49,178:INFO:              optuna: Not installed
2023-01-19 23:34:49,178:INFO:               skopt: Not installed
2023-01-19 23:34:49,178:INFO:              mlflow: 2.1.1
2023-01-19 23:34:49,178:INFO:              gradio: Not installed
2023-01-19 23:34:49,178:INFO:             fastapi: Not installed
2023-01-19 23:34:49,178:INFO:             uvicorn: Not installed
2023-01-19 23:34:49,178:INFO:              m2cgen: Not installed
2023-01-19 23:34:49,178:INFO:           evidently: Not installed
2023-01-19 23:34:49,178:INFO:                nltk: 3.8.1
2023-01-19 23:34:49,178:INFO:            pyLDAvis: 3.3.1
2023-01-19 23:34:49,178:INFO:              gensim: 4.3.0
2023-01-19 23:34:49,178:INFO:               spacy: 3.4.4
2023-01-19 23:34:49,178:INFO:           wordcloud: 1.8.2.2
2023-01-19 23:34:49,178:INFO:            textblob: 0.17.1
2023-01-19 23:34:49,178:INFO:               fugue: Not installed
2023-01-19 23:34:49,178:INFO:           streamlit: Not installed
2023-01-19 23:34:49,178:INFO:             prophet: Not installed
2023-01-19 23:34:49,178:INFO:None
2023-01-19 23:34:49,178:INFO:Set up data.
2023-01-19 23:34:49,224:INFO:Set up train/test split.
2023-01-19 23:34:49,236:INFO:Set up index.
2023-01-19 23:34:49,238:INFO:Set up folding strategy.
2023-01-19 23:34:49,238:INFO:Assigning column types.
2023-01-19 23:34:49,243:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-01-19 23:34:49,244:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-19 23:34:49,249:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-19 23:34:49,255:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-19 23:34:49,322:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-19 23:34:49,391:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-19 23:34:49,392:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:34:49,548:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:34:49,625:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-19 23:34:49,631:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-19 23:34:49,637:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-19 23:34:49,703:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-19 23:34:49,754:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-19 23:34:49,754:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:34:49,757:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:34:49,757:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-01-19 23:34:49,762:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-19 23:34:49,767:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-19 23:34:49,838:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-19 23:34:49,893:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-19 23:34:49,894:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:34:49,896:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:34:49,901:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-19 23:34:49,906:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-19 23:34:49,969:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-19 23:34:50,017:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-19 23:34:50,017:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:34:50,020:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:34:50,021:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-01-19 23:34:50,031:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-19 23:34:50,094:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-19 23:34:50,142:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-19 23:34:50,142:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:34:50,145:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:34:50,155:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-19 23:34:50,219:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-19 23:34:50,267:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-19 23:34:50,268:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:34:50,271:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:34:50,271:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-01-19 23:34:50,347:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-19 23:34:50,403:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-19 23:34:50,403:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:34:50,406:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:34:50,488:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-19 23:34:50,538:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-19 23:34:50,539:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:34:50,542:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:34:50,542:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-01-19 23:34:50,613:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-19 23:34:50,668:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:34:50,671:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:34:50,758:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-19 23:34:50,815:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:34:50,818:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:34:50,819:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-01-19 23:34:50,961:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:34:50,964:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:34:51,110:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:34:51,113:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:34:51,114:INFO:Preparing preprocessing pipeline...
2023-01-19 23:34:51,115:INFO:Set up column name cleaning.
2023-01-19 23:34:51,115:INFO:Set up simple imputation.
2023-01-19 23:34:51,205:INFO:Finished creating preprocessing pipeline.
2023-01-19 23:34:51,212:INFO:Pipeline: Pipeline(memory=Memory(location=/var/folders/3w/xf1fzw1s1mnb4ckhfxf67vgw0000gn/T/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['MSSubClass', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '...
                                             'BsmtFullBath', 'BsmtHalfBath',
                                             'FullBath', 'HalfBath',
                                             'BedroomAbvGr', 'KitchenAbvGr',
                                             'TotRmsAbvGrd', 'Fireplaces',
                                             'GarageCars', 'GarageArea',
                                             'WoodDeckSF', 'OpenPorchSF',
                                             'EnclosedPorch', '3SsnPorch',
                                             'ScreenPorch', 'PoolArea', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-01-19 23:34:51,212:INFO:Creating final display dataframe.
2023-01-19 23:34:51,599:INFO:Setup _display_container:                     Description             Value
0                    Session id              3983
1                        Target         SalePrice
2                   Target type        Regression
3           Original data shape       (1458, 193)
4        Transformed data shape       (1458, 193)
5   Transformed train set shape       (1020, 193)
6    Transformed test set shape        (438, 193)
7              Numeric features               192
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              1f77
2023-01-19 23:34:51,778:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:34:51,782:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:34:51,923:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:34:51,926:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:34:51,927:INFO:setup() successfully completed in 2.76s...............
2023-01-19 23:34:51,927:INFO:Initializing compare_models()
2023-01-19 23:34:51,927:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc65940dbe0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fc65940dbe0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-01-19 23:34:51,927:INFO:Checking exceptions
2023-01-19 23:34:51,929:INFO:Preparing display monitor
2023-01-19 23:34:52,012:INFO:Initializing Linear Regression
2023-01-19 23:34:52,012:INFO:Total runtime is 8.33272933959961e-06 minutes
2023-01-19 23:34:52,023:INFO:SubProcess create_model() called ==================================
2023-01-19 23:34:52,024:INFO:Initializing create_model()
2023-01-19 23:34:52,025:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc65940dbe0>, estimator=lr, fold=KFold(n_splits=10, random_state=3983, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc6451565e0>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:34:52,025:INFO:Checking exceptions
2023-01-19 23:34:52,025:INFO:Importing libraries
2023-01-19 23:34:52,025:INFO:Copying training dataset
2023-01-19 23:34:52,035:INFO:Defining folds
2023-01-19 23:34:52,036:INFO:Declaring metric variables
2023-01-19 23:34:52,049:INFO:Importing untrained model
2023-01-19 23:34:52,057:INFO:Linear Regression Imported successfully
2023-01-19 23:34:52,071:INFO:Starting cross validation
2023-01-19 23:34:52,084:INFO:Cross validating with KFold(n_splits=10, random_state=3983, shuffle=True), n_jobs=-1
2023-01-19 23:35:03,711:INFO:Calculating mean and std
2023-01-19 23:35:03,724:INFO:Creating metrics dataframe
2023-01-19 23:35:03,751:INFO:Uploading results into container
2023-01-19 23:35:03,755:INFO:Uploading model into container now
2023-01-19 23:35:03,756:INFO:_master_model_container: 1
2023-01-19 23:35:03,756:INFO:_display_container: 2
2023-01-19 23:35:03,757:INFO:LinearRegression(n_jobs=-1)
2023-01-19 23:35:03,757:INFO:create_model() successfully completed......................................
2023-01-19 23:35:04,464:INFO:SubProcess create_model() end ==================================
2023-01-19 23:35:04,464:INFO:Creating metrics dataframe
2023-01-19 23:35:04,483:INFO:Initializing Lasso Regression
2023-01-19 23:35:04,483:INFO:Total runtime is 0.20785788297653196 minutes
2023-01-19 23:35:04,487:INFO:SubProcess create_model() called ==================================
2023-01-19 23:35:04,488:INFO:Initializing create_model()
2023-01-19 23:35:04,488:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc65940dbe0>, estimator=lasso, fold=KFold(n_splits=10, random_state=3983, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc6451565e0>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:35:04,488:INFO:Checking exceptions
2023-01-19 23:35:04,488:INFO:Importing libraries
2023-01-19 23:35:04,488:INFO:Copying training dataset
2023-01-19 23:35:04,496:INFO:Defining folds
2023-01-19 23:35:04,496:INFO:Declaring metric variables
2023-01-19 23:35:04,500:INFO:Importing untrained model
2023-01-19 23:35:04,505:INFO:Lasso Regression Imported successfully
2023-01-19 23:35:04,513:INFO:Starting cross validation
2023-01-19 23:35:04,515:INFO:Cross validating with KFold(n_splits=10, random_state=3983, shuffle=True), n_jobs=-1
2023-01-19 23:35:04,713:INFO:Calculating mean and std
2023-01-19 23:35:04,714:INFO:Creating metrics dataframe
2023-01-19 23:35:04,717:INFO:Uploading results into container
2023-01-19 23:35:04,717:INFO:Uploading model into container now
2023-01-19 23:35:04,717:INFO:_master_model_container: 2
2023-01-19 23:35:04,717:INFO:_display_container: 2
2023-01-19 23:35:04,718:INFO:Lasso(random_state=3983)
2023-01-19 23:35:04,718:INFO:create_model() successfully completed......................................
2023-01-19 23:35:04,825:INFO:SubProcess create_model() end ==================================
2023-01-19 23:35:04,825:INFO:Creating metrics dataframe
2023-01-19 23:35:04,840:INFO:Initializing Ridge Regression
2023-01-19 23:35:04,840:INFO:Total runtime is 0.21380779743194578 minutes
2023-01-19 23:35:04,845:INFO:SubProcess create_model() called ==================================
2023-01-19 23:35:04,845:INFO:Initializing create_model()
2023-01-19 23:35:04,845:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc65940dbe0>, estimator=ridge, fold=KFold(n_splits=10, random_state=3983, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc6451565e0>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:35:04,845:INFO:Checking exceptions
2023-01-19 23:35:04,845:INFO:Importing libraries
2023-01-19 23:35:04,846:INFO:Copying training dataset
2023-01-19 23:35:04,851:INFO:Defining folds
2023-01-19 23:35:04,852:INFO:Declaring metric variables
2023-01-19 23:35:04,856:INFO:Importing untrained model
2023-01-19 23:35:04,860:INFO:Ridge Regression Imported successfully
2023-01-19 23:35:04,868:INFO:Starting cross validation
2023-01-19 23:35:04,870:INFO:Cross validating with KFold(n_splits=10, random_state=3983, shuffle=True), n_jobs=-1
2023-01-19 23:35:05,040:INFO:Calculating mean and std
2023-01-19 23:35:05,042:INFO:Creating metrics dataframe
2023-01-19 23:35:05,045:INFO:Uploading results into container
2023-01-19 23:35:05,046:INFO:Uploading model into container now
2023-01-19 23:35:05,046:INFO:_master_model_container: 3
2023-01-19 23:35:05,046:INFO:_display_container: 2
2023-01-19 23:35:05,047:INFO:Ridge(random_state=3983)
2023-01-19 23:35:05,047:INFO:create_model() successfully completed......................................
2023-01-19 23:35:05,149:INFO:SubProcess create_model() end ==================================
2023-01-19 23:35:05,149:INFO:Creating metrics dataframe
2023-01-19 23:35:05,162:INFO:Initializing Elastic Net
2023-01-19 23:35:05,163:INFO:Total runtime is 0.21918454964955644 minutes
2023-01-19 23:35:05,167:INFO:SubProcess create_model() called ==================================
2023-01-19 23:35:05,167:INFO:Initializing create_model()
2023-01-19 23:35:05,167:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc65940dbe0>, estimator=en, fold=KFold(n_splits=10, random_state=3983, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc6451565e0>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:35:05,167:INFO:Checking exceptions
2023-01-19 23:35:05,167:INFO:Importing libraries
2023-01-19 23:35:05,167:INFO:Copying training dataset
2023-01-19 23:35:05,174:INFO:Defining folds
2023-01-19 23:35:05,174:INFO:Declaring metric variables
2023-01-19 23:35:05,178:INFO:Importing untrained model
2023-01-19 23:35:05,182:INFO:Elastic Net Imported successfully
2023-01-19 23:35:05,190:INFO:Starting cross validation
2023-01-19 23:35:05,192:INFO:Cross validating with KFold(n_splits=10, random_state=3983, shuffle=True), n_jobs=-1
2023-01-19 23:35:05,351:INFO:Calculating mean and std
2023-01-19 23:35:05,352:INFO:Creating metrics dataframe
2023-01-19 23:35:05,355:INFO:Uploading results into container
2023-01-19 23:35:05,356:INFO:Uploading model into container now
2023-01-19 23:35:05,356:INFO:_master_model_container: 4
2023-01-19 23:35:05,356:INFO:_display_container: 2
2023-01-19 23:35:05,357:INFO:ElasticNet(random_state=3983)
2023-01-19 23:35:05,357:INFO:create_model() successfully completed......................................
2023-01-19 23:35:05,458:INFO:SubProcess create_model() end ==================================
2023-01-19 23:35:05,458:INFO:Creating metrics dataframe
2023-01-19 23:35:05,472:INFO:Initializing Least Angle Regression
2023-01-19 23:35:05,472:INFO:Total runtime is 0.2243489305178324 minutes
2023-01-19 23:35:05,477:INFO:SubProcess create_model() called ==================================
2023-01-19 23:35:05,478:INFO:Initializing create_model()
2023-01-19 23:35:05,478:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc65940dbe0>, estimator=lar, fold=KFold(n_splits=10, random_state=3983, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc6451565e0>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:35:05,478:INFO:Checking exceptions
2023-01-19 23:35:05,478:INFO:Importing libraries
2023-01-19 23:35:05,478:INFO:Copying training dataset
2023-01-19 23:35:05,484:INFO:Defining folds
2023-01-19 23:35:05,485:INFO:Declaring metric variables
2023-01-19 23:35:05,489:INFO:Importing untrained model
2023-01-19 23:35:05,494:INFO:Least Angle Regression Imported successfully
2023-01-19 23:35:05,501:INFO:Starting cross validation
2023-01-19 23:35:05,503:INFO:Cross validating with KFold(n_splits=10, random_state=3983, shuffle=True), n_jobs=-1
2023-01-19 23:35:05,560:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:35:05,562:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:35:05,576:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:35:05,584:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:35:05,601:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:35:05,606:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:35:05,610:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=1.046e-04, with an active set of 106 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,621:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 140 iterations, i.e. alpha=5.780e-05, with an active set of 133 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,624:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:35:05,630:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 150 iterations, i.e. alpha=4.575e-05, with an active set of 141 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,642:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 174 iterations, i.e. alpha=3.313e-05, with an active set of 158 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,648:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:35:05,648:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 186 iterations, i.e. alpha=2.173e-05, with an active set of 168 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,648:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 186 iterations, i.e. alpha=2.003e-05, with an active set of 168 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,649:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 187 iterations, i.e. alpha=1.693e-05, with an active set of 169 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,654:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 193 iterations, i.e. alpha=1.278e-05, with an active set of 174 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,656:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 199 iterations, i.e. alpha=8.475e-06, with an active set of 178 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,657:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 199 iterations, i.e. alpha=6.988e-06, with an active set of 178 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,659:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 203 iterations, i.e. alpha=6.562e-06, with an active set of 179 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,659:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 204 iterations, i.e. alpha=5.181e-06, with an active set of 180 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,660:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 204 iterations, i.e. alpha=5.181e-06, with an active set of 180 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,660:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 204 iterations, i.e. alpha=4.913e-07, with an active set of 180 regressors, and the smallest cholesky pivot element being 4.344e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,666:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 203 iterations, i.e. alpha=2.753e-05, with an active set of 178 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,668:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 207 iterations, i.e. alpha=1.724e-05, with an active set of 180 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,672:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 216 iterations, i.e. alpha=9.126e-03, with an active set of 181 regressors, and the smallest cholesky pivot element being 7.598e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,676:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 220 iterations, i.e. alpha=1.072e-03, with an active set of 175 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,679:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 248 iterations, i.e. alpha=2.189e+02, with an active set of 181 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,683:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 232 iterations, i.e. alpha=6.262e-03, with an active set of 177 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,683:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 232 iterations, i.e. alpha=2.414e-03, with an active set of 177 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,684:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 234 iterations, i.e. alpha=9.187e-04, with an active set of 179 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,685:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 235 iterations, i.e. alpha=1.423e-04, with an active set of 180 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,686:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 191 iterations, i.e. alpha=5.911e-05, with an active set of 169 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,686:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 236 iterations, i.e. alpha=4.160e-05, with an active set of 181 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,693:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 203 iterations, i.e. alpha=4.731e-05, with an active set of 177 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,694:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 192 iterations, i.e. alpha=7.580e-05, with an active set of 169 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,696:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 209 iterations, i.e. alpha=2.522e-05, with an active set of 181 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,697:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 211 iterations, i.e. alpha=3.298e-05, with an active set of 182 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,708:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 220 iterations, i.e. alpha=1.041e+01, with an active set of 176 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,710:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 222 iterations, i.e. alpha=6.383e+00, with an active set of 178 regressors, and the smallest cholesky pivot element being 9.306e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,712:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 227 iterations, i.e. alpha=1.936e+01, with an active set of 179 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,712:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 227 iterations, i.e. alpha=8.283e+00, with an active set of 179 regressors, and the smallest cholesky pivot element being 9.306e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,713:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 229 iterations, i.e. alpha=3.843e+00, with an active set of 180 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,714:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 229 iterations, i.e. alpha=1.893e+00, with an active set of 180 regressors, and the smallest cholesky pivot element being 6.234e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,715:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 208 iterations, i.e. alpha=1.130e-03, with an active set of 177 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,716:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 210 iterations, i.e. alpha=4.461e-04, with an active set of 179 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,719:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 218 iterations, i.e. alpha=2.641e-03, with an active set of 180 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,736:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 239 iterations, i.e. alpha=5.076e+04, with an active set of 182 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,737:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 240 iterations, i.e. alpha=6.706e+03, with an active set of 183 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,737:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:35:05,742:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:35:05,767:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 140 iterations, i.e. alpha=3.017e-04, with an active set of 132 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,771:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 161 iterations, i.e. alpha=2.239e-04, with an active set of 151 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,778:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 193 iterations, i.e. alpha=1.929e-02, with an active set of 171 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,779:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 198 iterations, i.e. alpha=1.250e-02, with an active set of 173 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,781:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 202 iterations, i.e. alpha=7.933e-03, with an active set of 176 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,781:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 213 iterations, i.e. alpha=5.322e-02, with an active set of 179 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,781:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 216 iterations, i.e. alpha=2.823e-02, with an active set of 181 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,782:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 206 iterations, i.e. alpha=5.022e-03, with an active set of 180 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,782:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 217 iterations, i.e. alpha=1.516e-02, with an active set of 182 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,784:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 218 iterations, i.e. alpha=1.139e+00, with an active set of 182 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,785:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 219 iterations, i.e. alpha=8.964e-02, with an active set of 183 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:35:05,801:INFO:Calculating mean and std
2023-01-19 23:35:05,802:INFO:Creating metrics dataframe
2023-01-19 23:35:05,805:INFO:Uploading results into container
2023-01-19 23:35:05,806:INFO:Uploading model into container now
2023-01-19 23:35:05,807:INFO:_master_model_container: 5
2023-01-19 23:35:05,807:INFO:_display_container: 2
2023-01-19 23:35:05,810:INFO:Lars(random_state=3983)
2023-01-19 23:35:05,811:INFO:create_model() successfully completed......................................
2023-01-19 23:35:05,914:INFO:SubProcess create_model() end ==================================
2023-01-19 23:35:05,914:INFO:Creating metrics dataframe
2023-01-19 23:35:05,929:INFO:Initializing Lasso Least Angle Regression
2023-01-19 23:35:05,929:INFO:Total runtime is 0.2319553653399149 minutes
2023-01-19 23:35:05,933:INFO:SubProcess create_model() called ==================================
2023-01-19 23:35:05,934:INFO:Initializing create_model()
2023-01-19 23:35:05,934:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc65940dbe0>, estimator=llar, fold=KFold(n_splits=10, random_state=3983, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc6451565e0>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:35:05,934:INFO:Checking exceptions
2023-01-19 23:35:05,934:INFO:Importing libraries
2023-01-19 23:35:05,935:INFO:Copying training dataset
2023-01-19 23:35:05,940:INFO:Defining folds
2023-01-19 23:35:05,940:INFO:Declaring metric variables
2023-01-19 23:35:05,944:INFO:Importing untrained model
2023-01-19 23:35:05,951:INFO:Lasso Least Angle Regression Imported successfully
2023-01-19 23:35:05,960:INFO:Starting cross validation
2023-01-19 23:35:05,961:INFO:Cross validating with KFold(n_splits=10, random_state=3983, shuffle=True), n_jobs=-1
2023-01-19 23:35:06,020:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-19 23:35:06,035:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-19 23:35:06,049:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-19 23:35:06,069:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-19 23:35:06,086:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-19 23:35:06,101:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-19 23:35:06,115:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-19 23:35:06,136:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-19 23:35:06,152:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-19 23:35:06,160:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-19 23:35:06,182:INFO:Calculating mean and std
2023-01-19 23:35:06,183:INFO:Creating metrics dataframe
2023-01-19 23:35:06,187:INFO:Uploading results into container
2023-01-19 23:35:06,187:INFO:Uploading model into container now
2023-01-19 23:35:06,188:INFO:_master_model_container: 6
2023-01-19 23:35:06,188:INFO:_display_container: 2
2023-01-19 23:35:06,188:INFO:LassoLars(random_state=3983)
2023-01-19 23:35:06,188:INFO:create_model() successfully completed......................................
2023-01-19 23:35:06,321:INFO:SubProcess create_model() end ==================================
2023-01-19 23:35:06,322:INFO:Creating metrics dataframe
2023-01-19 23:35:06,346:INFO:Initializing Orthogonal Matching Pursuit
2023-01-19 23:35:06,347:INFO:Total runtime is 0.23892443180084222 minutes
2023-01-19 23:35:06,352:INFO:SubProcess create_model() called ==================================
2023-01-19 23:35:06,352:INFO:Initializing create_model()
2023-01-19 23:35:06,352:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc65940dbe0>, estimator=omp, fold=KFold(n_splits=10, random_state=3983, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc6451565e0>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:35:06,352:INFO:Checking exceptions
2023-01-19 23:35:06,352:INFO:Importing libraries
2023-01-19 23:35:06,353:INFO:Copying training dataset
2023-01-19 23:35:06,360:INFO:Defining folds
2023-01-19 23:35:06,360:INFO:Declaring metric variables
2023-01-19 23:35:06,365:INFO:Importing untrained model
2023-01-19 23:35:06,370:INFO:Orthogonal Matching Pursuit Imported successfully
2023-01-19 23:35:06,390:INFO:Starting cross validation
2023-01-19 23:35:06,398:INFO:Cross validating with KFold(n_splits=10, random_state=3983, shuffle=True), n_jobs=-1
2023-01-19 23:35:06,466:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:35:06,481:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:35:06,489:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:35:06,501:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:35:06,523:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:35:06,537:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:35:06,553:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:35:06,584:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:35:06,598:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:35:06,607:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:35:06,645:INFO:Calculating mean and std
2023-01-19 23:35:06,646:INFO:Creating metrics dataframe
2023-01-19 23:35:06,649:INFO:Uploading results into container
2023-01-19 23:35:06,650:INFO:Uploading model into container now
2023-01-19 23:35:06,651:INFO:_master_model_container: 7
2023-01-19 23:35:06,651:INFO:_display_container: 2
2023-01-19 23:35:06,651:INFO:OrthogonalMatchingPursuit()
2023-01-19 23:35:06,651:INFO:create_model() successfully completed......................................
2023-01-19 23:35:06,778:INFO:SubProcess create_model() end ==================================
2023-01-19 23:35:06,778:INFO:Creating metrics dataframe
2023-01-19 23:35:06,793:INFO:Initializing Bayesian Ridge
2023-01-19 23:35:06,793:INFO:Total runtime is 0.2463659524917602 minutes
2023-01-19 23:35:06,798:INFO:SubProcess create_model() called ==================================
2023-01-19 23:35:06,798:INFO:Initializing create_model()
2023-01-19 23:35:06,798:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc65940dbe0>, estimator=br, fold=KFold(n_splits=10, random_state=3983, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc6451565e0>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:35:06,799:INFO:Checking exceptions
2023-01-19 23:35:06,799:INFO:Importing libraries
2023-01-19 23:35:06,799:INFO:Copying training dataset
2023-01-19 23:35:06,804:INFO:Defining folds
2023-01-19 23:35:06,805:INFO:Declaring metric variables
2023-01-19 23:35:06,809:INFO:Importing untrained model
2023-01-19 23:35:06,813:INFO:Bayesian Ridge Imported successfully
2023-01-19 23:35:06,823:INFO:Starting cross validation
2023-01-19 23:35:06,826:INFO:Cross validating with KFold(n_splits=10, random_state=3983, shuffle=True), n_jobs=-1
2023-01-19 23:35:07,116:INFO:Calculating mean and std
2023-01-19 23:35:07,117:INFO:Creating metrics dataframe
2023-01-19 23:35:07,121:INFO:Uploading results into container
2023-01-19 23:35:07,121:INFO:Uploading model into container now
2023-01-19 23:35:07,122:INFO:_master_model_container: 8
2023-01-19 23:35:07,123:INFO:_display_container: 2
2023-01-19 23:35:07,123:INFO:BayesianRidge()
2023-01-19 23:35:07,123:INFO:create_model() successfully completed......................................
2023-01-19 23:35:07,238:INFO:SubProcess create_model() end ==================================
2023-01-19 23:35:07,238:INFO:Creating metrics dataframe
2023-01-19 23:35:07,253:INFO:Initializing Passive Aggressive Regressor
2023-01-19 23:35:07,253:INFO:Total runtime is 0.2540262659390767 minutes
2023-01-19 23:35:07,258:INFO:SubProcess create_model() called ==================================
2023-01-19 23:35:07,258:INFO:Initializing create_model()
2023-01-19 23:35:07,259:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc65940dbe0>, estimator=par, fold=KFold(n_splits=10, random_state=3983, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc6451565e0>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:35:07,259:INFO:Checking exceptions
2023-01-19 23:35:07,259:INFO:Importing libraries
2023-01-19 23:35:07,259:INFO:Copying training dataset
2023-01-19 23:35:07,266:INFO:Defining folds
2023-01-19 23:35:07,266:INFO:Declaring metric variables
2023-01-19 23:35:07,272:INFO:Importing untrained model
2023-01-19 23:35:07,276:INFO:Passive Aggressive Regressor Imported successfully
2023-01-19 23:35:07,283:INFO:Starting cross validation
2023-01-19 23:35:07,285:INFO:Cross validating with KFold(n_splits=10, random_state=3983, shuffle=True), n_jobs=-1
2023-01-19 23:35:07,521:INFO:Calculating mean and std
2023-01-19 23:35:07,522:INFO:Creating metrics dataframe
2023-01-19 23:35:07,526:INFO:Uploading results into container
2023-01-19 23:35:07,527:INFO:Uploading model into container now
2023-01-19 23:35:07,528:INFO:_master_model_container: 9
2023-01-19 23:35:07,528:INFO:_display_container: 2
2023-01-19 23:35:07,529:INFO:PassiveAggressiveRegressor(random_state=3983)
2023-01-19 23:35:07,529:INFO:create_model() successfully completed......................................
2023-01-19 23:35:07,636:INFO:SubProcess create_model() end ==================================
2023-01-19 23:35:07,636:INFO:Creating metrics dataframe
2023-01-19 23:35:07,652:INFO:Initializing Huber Regressor
2023-01-19 23:35:07,652:INFO:Total runtime is 0.26067539850870763 minutes
2023-01-19 23:35:07,656:INFO:SubProcess create_model() called ==================================
2023-01-19 23:35:07,656:INFO:Initializing create_model()
2023-01-19 23:35:07,657:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc65940dbe0>, estimator=huber, fold=KFold(n_splits=10, random_state=3983, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc6451565e0>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:35:07,657:INFO:Checking exceptions
2023-01-19 23:35:07,657:INFO:Importing libraries
2023-01-19 23:35:07,657:INFO:Copying training dataset
2023-01-19 23:35:07,663:INFO:Defining folds
2023-01-19 23:35:07,663:INFO:Declaring metric variables
2023-01-19 23:35:07,667:INFO:Importing untrained model
2023-01-19 23:35:07,671:INFO:Huber Regressor Imported successfully
2023-01-19 23:35:07,681:INFO:Starting cross validation
2023-01-19 23:35:07,682:INFO:Cross validating with KFold(n_splits=10, random_state=3983, shuffle=True), n_jobs=-1
2023-01-19 23:35:08,070:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-19 23:35:08,070:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-19 23:35:08,079:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-19 23:35:08,082:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-19 23:35:08,082:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-19 23:35:08,086:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-19 23:35:08,094:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-19 23:35:08,100:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-19 23:35:08,239:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-19 23:35:08,244:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-19 23:35:08,262:INFO:Calculating mean and std
2023-01-19 23:35:08,263:INFO:Creating metrics dataframe
2023-01-19 23:35:08,266:INFO:Uploading results into container
2023-01-19 23:35:08,267:INFO:Uploading model into container now
2023-01-19 23:35:08,267:INFO:_master_model_container: 10
2023-01-19 23:35:08,268:INFO:_display_container: 2
2023-01-19 23:35:08,268:INFO:HuberRegressor()
2023-01-19 23:35:08,268:INFO:create_model() successfully completed......................................
2023-01-19 23:35:08,380:INFO:SubProcess create_model() end ==================================
2023-01-19 23:35:08,380:INFO:Creating metrics dataframe
2023-01-19 23:35:08,396:INFO:Initializing K Neighbors Regressor
2023-01-19 23:35:08,396:INFO:Total runtime is 0.27307131687800085 minutes
2023-01-19 23:35:08,399:INFO:SubProcess create_model() called ==================================
2023-01-19 23:35:08,400:INFO:Initializing create_model()
2023-01-19 23:35:08,400:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc65940dbe0>, estimator=knn, fold=KFold(n_splits=10, random_state=3983, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc6451565e0>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:35:08,400:INFO:Checking exceptions
2023-01-19 23:35:08,401:INFO:Importing libraries
2023-01-19 23:35:08,401:INFO:Copying training dataset
2023-01-19 23:35:08,407:INFO:Defining folds
2023-01-19 23:35:08,407:INFO:Declaring metric variables
2023-01-19 23:35:08,411:INFO:Importing untrained model
2023-01-19 23:35:08,415:INFO:K Neighbors Regressor Imported successfully
2023-01-19 23:35:08,423:INFO:Starting cross validation
2023-01-19 23:35:08,424:INFO:Cross validating with KFold(n_splits=10, random_state=3983, shuffle=True), n_jobs=-1
2023-01-19 23:35:08,685:INFO:Calculating mean and std
2023-01-19 23:35:08,687:INFO:Creating metrics dataframe
2023-01-19 23:35:08,690:INFO:Uploading results into container
2023-01-19 23:35:08,690:INFO:Uploading model into container now
2023-01-19 23:35:08,691:INFO:_master_model_container: 11
2023-01-19 23:35:08,691:INFO:_display_container: 2
2023-01-19 23:35:08,692:INFO:KNeighborsRegressor(n_jobs=-1)
2023-01-19 23:35:08,693:INFO:create_model() successfully completed......................................
2023-01-19 23:35:08,794:INFO:SubProcess create_model() end ==================================
2023-01-19 23:35:08,794:INFO:Creating metrics dataframe
2023-01-19 23:35:08,810:INFO:Initializing Decision Tree Regressor
2023-01-19 23:35:08,810:INFO:Total runtime is 0.27997561693191525 minutes
2023-01-19 23:35:08,814:INFO:SubProcess create_model() called ==================================
2023-01-19 23:35:08,814:INFO:Initializing create_model()
2023-01-19 23:35:08,814:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc65940dbe0>, estimator=dt, fold=KFold(n_splits=10, random_state=3983, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc6451565e0>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:35:08,814:INFO:Checking exceptions
2023-01-19 23:35:08,815:INFO:Importing libraries
2023-01-19 23:35:08,815:INFO:Copying training dataset
2023-01-19 23:35:08,820:INFO:Defining folds
2023-01-19 23:35:08,821:INFO:Declaring metric variables
2023-01-19 23:35:08,825:INFO:Importing untrained model
2023-01-19 23:35:08,830:INFO:Decision Tree Regressor Imported successfully
2023-01-19 23:35:08,838:INFO:Starting cross validation
2023-01-19 23:35:08,839:INFO:Cross validating with KFold(n_splits=10, random_state=3983, shuffle=True), n_jobs=-1
2023-01-19 23:35:09,066:INFO:Calculating mean and std
2023-01-19 23:35:09,067:INFO:Creating metrics dataframe
2023-01-19 23:35:09,070:INFO:Uploading results into container
2023-01-19 23:35:09,071:INFO:Uploading model into container now
2023-01-19 23:35:09,072:INFO:_master_model_container: 12
2023-01-19 23:35:09,072:INFO:_display_container: 2
2023-01-19 23:35:09,072:INFO:DecisionTreeRegressor(random_state=3983)
2023-01-19 23:35:09,072:INFO:create_model() successfully completed......................................
2023-01-19 23:35:09,176:INFO:SubProcess create_model() end ==================================
2023-01-19 23:35:09,177:INFO:Creating metrics dataframe
2023-01-19 23:35:09,192:INFO:Initializing Random Forest Regressor
2023-01-19 23:35:09,192:INFO:Total runtime is 0.2863383650779724 minutes
2023-01-19 23:35:09,196:INFO:SubProcess create_model() called ==================================
2023-01-19 23:35:09,196:INFO:Initializing create_model()
2023-01-19 23:35:09,196:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc65940dbe0>, estimator=rf, fold=KFold(n_splits=10, random_state=3983, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc6451565e0>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:35:09,196:INFO:Checking exceptions
2023-01-19 23:35:09,196:INFO:Importing libraries
2023-01-19 23:35:09,196:INFO:Copying training dataset
2023-01-19 23:35:09,203:INFO:Defining folds
2023-01-19 23:35:09,203:INFO:Declaring metric variables
2023-01-19 23:35:09,207:INFO:Importing untrained model
2023-01-19 23:35:09,212:INFO:Random Forest Regressor Imported successfully
2023-01-19 23:35:09,220:INFO:Starting cross validation
2023-01-19 23:35:09,221:INFO:Cross validating with KFold(n_splits=10, random_state=3983, shuffle=True), n_jobs=-1
2023-01-19 23:35:12,564:INFO:Calculating mean and std
2023-01-19 23:35:12,568:INFO:Creating metrics dataframe
2023-01-19 23:35:12,572:INFO:Uploading results into container
2023-01-19 23:35:12,573:INFO:Uploading model into container now
2023-01-19 23:35:12,574:INFO:_master_model_container: 13
2023-01-19 23:35:12,574:INFO:_display_container: 2
2023-01-19 23:35:12,574:INFO:RandomForestRegressor(n_jobs=-1, random_state=3983)
2023-01-19 23:35:12,575:INFO:create_model() successfully completed......................................
2023-01-19 23:35:12,683:INFO:SubProcess create_model() end ==================================
2023-01-19 23:35:12,684:INFO:Creating metrics dataframe
2023-01-19 23:35:12,700:INFO:Initializing Extra Trees Regressor
2023-01-19 23:35:12,701:INFO:Total runtime is 0.34482021331787105 minutes
2023-01-19 23:35:12,705:INFO:SubProcess create_model() called ==================================
2023-01-19 23:35:12,705:INFO:Initializing create_model()
2023-01-19 23:35:12,705:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc65940dbe0>, estimator=et, fold=KFold(n_splits=10, random_state=3983, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc6451565e0>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:35:12,706:INFO:Checking exceptions
2023-01-19 23:35:12,706:INFO:Importing libraries
2023-01-19 23:35:12,706:INFO:Copying training dataset
2023-01-19 23:35:12,712:INFO:Defining folds
2023-01-19 23:35:12,713:INFO:Declaring metric variables
2023-01-19 23:35:12,717:INFO:Importing untrained model
2023-01-19 23:35:12,722:INFO:Extra Trees Regressor Imported successfully
2023-01-19 23:35:12,733:INFO:Starting cross validation
2023-01-19 23:35:12,735:INFO:Cross validating with KFold(n_splits=10, random_state=3983, shuffle=True), n_jobs=-1
2023-01-19 23:35:25,046:INFO:Initializing create_model()
2023-01-19 23:35:25,047:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc65940dbe0>, estimator=catboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:35:25,047:INFO:Checking exceptions
2023-01-19 23:35:25,067:INFO:Importing libraries
2023-01-19 23:35:25,067:INFO:Copying training dataset
2023-01-19 23:35:25,074:INFO:Defining folds
2023-01-19 23:35:25,074:INFO:Declaring metric variables
2023-01-19 23:35:25,079:INFO:Importing untrained model
2023-01-19 23:35:25,087:INFO:CatBoost Regressor Imported successfully
2023-01-19 23:35:25,096:INFO:Starting cross validation
2023-01-19 23:35:25,098:INFO:Cross validating with KFold(n_splits=10, random_state=3983, shuffle=True), n_jobs=-1
2023-01-19 23:35:47,954:INFO:Calculating mean and std
2023-01-19 23:35:47,995:INFO:Creating metrics dataframe
2023-01-19 23:35:48,035:INFO:Finalizing model
2023-01-19 23:35:50,481:INFO:Uploading results into container
2023-01-19 23:35:50,483:INFO:Uploading model into container now
2023-01-19 23:35:50,526:INFO:_master_model_container: 14
2023-01-19 23:35:50,526:INFO:_display_container: 2
2023-01-19 23:35:50,527:INFO:<catboost.core.CatBoostRegressor object at 0x7fc6469a1880>
2023-01-19 23:35:50,527:INFO:create_model() successfully completed......................................
2023-01-19 23:35:51,006:INFO:Initializing tune_model()
2023-01-19 23:35:51,006:INFO:tune_model(estimator=<catboost.core.CatBoostRegressor object at 0x7fc6469a1880>, fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc65940dbe0>)
2023-01-19 23:35:51,007:INFO:Checking exceptions
2023-01-19 23:35:51,035:INFO:Copying training dataset
2023-01-19 23:35:51,042:INFO:Checking base model
2023-01-19 23:35:51,042:INFO:Base model : CatBoost Regressor
2023-01-19 23:35:51,047:INFO:Declaring metric variables
2023-01-19 23:35:51,055:INFO:Defining Hyperparameters
2023-01-19 23:35:51,212:INFO:Tuning with n_jobs=-1
2023-01-19 23:35:51,213:INFO:Initializing RandomizedSearchCV
2023-01-19 23:39:17,705:INFO:best_params: {'actual_estimator__random_strength': 0.8, 'actual_estimator__n_estimators': 190, 'actual_estimator__l2_leaf_reg': 7, 'actual_estimator__eta': 0.1, 'actual_estimator__depth': 3}
2023-01-19 23:39:17,783:INFO:Hyperparameter search completed
2023-01-19 23:39:17,785:INFO:SubProcess create_model() called ==================================
2023-01-19 23:39:17,794:INFO:Initializing create_model()
2023-01-19 23:39:17,794:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc65940dbe0>, estimator=<catboost.core.CatBoostRegressor object at 0x7fc645b88310>, fold=KFold(n_splits=10, random_state=3983, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc645393eb0>, model_only=True, return_train_score=False, kwargs={'random_strength': 0.8, 'n_estimators': 190, 'l2_leaf_reg': 7, 'eta': 0.1, 'depth': 3})
2023-01-19 23:39:17,796:INFO:Checking exceptions
2023-01-19 23:39:17,800:INFO:Importing libraries
2023-01-19 23:39:17,802:INFO:Copying training dataset
2023-01-19 23:39:17,855:INFO:Defining folds
2023-01-19 23:39:17,857:INFO:Declaring metric variables
2023-01-19 23:39:17,890:INFO:Importing untrained model
2023-01-19 23:39:17,890:INFO:Declaring custom model
2023-01-19 23:39:17,906:INFO:CatBoost Regressor Imported successfully
2023-01-19 23:39:17,917:INFO:Starting cross validation
2023-01-19 23:39:17,920:INFO:Cross validating with KFold(n_splits=10, random_state=3983, shuffle=True), n_jobs=-1
2023-01-19 23:39:19,113:INFO:Calculating mean and std
2023-01-19 23:39:19,116:INFO:Creating metrics dataframe
2023-01-19 23:39:19,137:INFO:Finalizing model
2023-01-19 23:39:19,493:INFO:Uploading results into container
2023-01-19 23:39:19,494:INFO:Uploading model into container now
2023-01-19 23:39:19,497:INFO:_master_model_container: 15
2023-01-19 23:39:19,497:INFO:_display_container: 3
2023-01-19 23:39:19,497:INFO:<catboost.core.CatBoostRegressor object at 0x7fc645b7a1c0>
2023-01-19 23:39:19,498:INFO:create_model() successfully completed......................................
2023-01-19 23:39:20,340:INFO:SubProcess create_model() end ==================================
2023-01-19 23:39:20,340:INFO:choose_better activated
2023-01-19 23:39:20,346:INFO:SubProcess create_model() called ==================================
2023-01-19 23:39:20,347:INFO:Initializing create_model()
2023-01-19 23:39:20,347:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc65940dbe0>, estimator=<catboost.core.CatBoostRegressor object at 0x7fc6469a1880>, fold=KFold(n_splits=10, random_state=3983, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:39:20,347:INFO:Checking exceptions
2023-01-19 23:39:20,349:INFO:Importing libraries
2023-01-19 23:39:20,349:INFO:Copying training dataset
2023-01-19 23:39:20,355:INFO:Defining folds
2023-01-19 23:39:20,355:INFO:Declaring metric variables
2023-01-19 23:39:20,356:INFO:Importing untrained model
2023-01-19 23:39:20,356:INFO:Declaring custom model
2023-01-19 23:39:20,357:INFO:CatBoost Regressor Imported successfully
2023-01-19 23:39:20,358:INFO:Starting cross validation
2023-01-19 23:39:20,360:INFO:Cross validating with KFold(n_splits=10, random_state=3983, shuffle=True), n_jobs=-1
2023-01-19 23:39:33,658:INFO:Calculating mean and std
2023-01-19 23:39:33,659:INFO:Creating metrics dataframe
2023-01-19 23:39:33,661:INFO:Finalizing model
2023-01-19 23:39:35,986:INFO:Uploading results into container
2023-01-19 23:39:35,987:INFO:Uploading model into container now
2023-01-19 23:39:35,987:INFO:_master_model_container: 16
2023-01-19 23:39:35,987:INFO:_display_container: 4
2023-01-19 23:39:35,987:INFO:<catboost.core.CatBoostRegressor object at 0x7fc645477580>
2023-01-19 23:39:35,987:INFO:create_model() successfully completed......................................
2023-01-19 23:39:36,114:INFO:SubProcess create_model() end ==================================
2023-01-19 23:39:36,115:INFO:<catboost.core.CatBoostRegressor object at 0x7fc645477580> result for R2 is 0.8966
2023-01-19 23:39:36,116:INFO:<catboost.core.CatBoostRegressor object at 0x7fc645b7a1c0> result for R2 is 0.8875
2023-01-19 23:39:36,116:INFO:<catboost.core.CatBoostRegressor object at 0x7fc645477580> is best model
2023-01-19 23:39:36,117:INFO:choose_better completed
2023-01-19 23:39:36,117:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-01-19 23:39:36,141:INFO:_master_model_container: 16
2023-01-19 23:39:36,142:INFO:_display_container: 3
2023-01-19 23:39:36,142:INFO:<catboost.core.CatBoostRegressor object at 0x7fc645477580>
2023-01-19 23:39:36,142:INFO:tune_model() successfully completed......................................
2023-01-19 23:40:14,706:INFO:Initializing create_model()
2023-01-19 23:40:14,709:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc65940dbe0>, estimator=br, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:40:14,709:INFO:Checking exceptions
2023-01-19 23:40:14,734:INFO:Importing libraries
2023-01-19 23:40:14,735:INFO:Copying training dataset
2023-01-19 23:40:14,747:INFO:Defining folds
2023-01-19 23:40:14,747:INFO:Declaring metric variables
2023-01-19 23:40:14,754:INFO:Importing untrained model
2023-01-19 23:40:14,760:INFO:Bayesian Ridge Imported successfully
2023-01-19 23:40:14,776:INFO:Starting cross validation
2023-01-19 23:40:14,779:INFO:Cross validating with KFold(n_splits=10, random_state=3983, shuffle=True), n_jobs=-1
2023-01-19 23:40:15,406:INFO:Calculating mean and std
2023-01-19 23:40:15,407:INFO:Creating metrics dataframe
2023-01-19 23:40:15,415:INFO:Finalizing model
2023-01-19 23:40:15,506:INFO:Uploading results into container
2023-01-19 23:40:15,507:INFO:Uploading model into container now
2023-01-19 23:40:15,527:INFO:_master_model_container: 17
2023-01-19 23:40:15,528:INFO:_display_container: 4
2023-01-19 23:40:15,529:INFO:BayesianRidge()
2023-01-19 23:40:15,529:INFO:create_model() successfully completed......................................
2023-01-19 23:40:15,829:INFO:Initializing tune_model()
2023-01-19 23:40:15,830:INFO:tune_model(estimator=BayesianRidge(), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc65940dbe0>)
2023-01-19 23:40:15,830:INFO:Checking exceptions
2023-01-19 23:40:15,854:INFO:Copying training dataset
2023-01-19 23:40:15,861:INFO:Checking base model
2023-01-19 23:40:15,862:INFO:Base model : Bayesian Ridge
2023-01-19 23:40:15,866:INFO:Declaring metric variables
2023-01-19 23:40:15,871:INFO:Defining Hyperparameters
2023-01-19 23:40:16,022:INFO:Tuning with n_jobs=-1
2023-01-19 23:40:16,023:INFO:Initializing RandomizedSearchCV
2023-01-19 23:40:16,141:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:16,156:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:16,139:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:16,160:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:16,175:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:16,169:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:16,204:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:16,230:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:16,341:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:16,348:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:16,369:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:16,376:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:16,393:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:16,409:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:16,425:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:16,447:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:16,489:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:16,500:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:16,508:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:16,515:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:16,535:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:16,537:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:16,557:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:16,568:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:16,615:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:16,640:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:16,646:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:16,650:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:16,665:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:16,680:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:16,683:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:16,697:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:16,750:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:16,764:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:16,775:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:16,778:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:16,792:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:16,803:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:16,813:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:16,824:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:16,869:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:16,887:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:16,900:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:16,907:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:16,920:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:16,924:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:16,934:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:16,950:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:17,003:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:17,014:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:17,024:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:17,035:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:17,054:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:17,057:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:17,067:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:17,083:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:17,130:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:17,144:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:17,163:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:17,173:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:17,177:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:17,181:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:17,201:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:17,219:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:17,274:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:17,288:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:17,298:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:17,325:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:17,336:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:17,396:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:17,413:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:17,439:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:17,484:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:17,496:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:17,510:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:17,516:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:17,539:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:17,541:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:17,555:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:17,589:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:17,621:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:17,642:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:17,655:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:17,656:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:17,679:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:17,679:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:17,685:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:17,713:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:17,746:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:17,767:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:17,774:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:17,775:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:17,800:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:17,813:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:17,818:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:17,867:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:17,904:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:17,915:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:17,925:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:17,926:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:40:17,985:INFO:best_params: {'actual_estimator__normalize': False, 'actual_estimator__lambda_2': 0.0001, 'actual_estimator__lambda_1': 0.3, 'actual_estimator__fit_intercept': True, 'actual_estimator__compute_score': False, 'actual_estimator__alpha_2': 1e-06, 'actual_estimator__alpha_1': 0.0005}
2023-01-19 23:40:17,986:INFO:Hyperparameter search completed
2023-01-19 23:40:17,987:INFO:SubProcess create_model() called ==================================
2023-01-19 23:40:17,987:INFO:Initializing create_model()
2023-01-19 23:40:17,987:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc65940dbe0>, estimator=BayesianRidge(), fold=KFold(n_splits=10, random_state=3983, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc6456e40a0>, model_only=True, return_train_score=False, kwargs={'normalize': False, 'lambda_2': 0.0001, 'lambda_1': 0.3, 'fit_intercept': True, 'compute_score': False, 'alpha_2': 1e-06, 'alpha_1': 0.0005})
2023-01-19 23:40:17,987:INFO:Checking exceptions
2023-01-19 23:40:17,988:INFO:Importing libraries
2023-01-19 23:40:17,988:INFO:Copying training dataset
2023-01-19 23:40:17,992:INFO:Defining folds
2023-01-19 23:40:17,992:INFO:Declaring metric variables
2023-01-19 23:40:17,996:INFO:Importing untrained model
2023-01-19 23:40:17,997:INFO:Declaring custom model
2023-01-19 23:40:18,003:INFO:Bayesian Ridge Imported successfully
2023-01-19 23:40:18,021:INFO:Starting cross validation
2023-01-19 23:40:18,023:INFO:Cross validating with KFold(n_splits=10, random_state=3983, shuffle=True), n_jobs=-1
2023-01-19 23:40:18,196:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:18,226:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:18,234:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:18,236:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:18,257:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:18,264:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:18,269:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:18,274:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:18,372:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:18,381:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:18,425:INFO:Calculating mean and std
2023-01-19 23:40:18,426:INFO:Creating metrics dataframe
2023-01-19 23:40:18,433:INFO:Finalizing model
2023-01-19 23:40:18,485:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:40:18,532:INFO:Uploading results into container
2023-01-19 23:40:18,533:INFO:Uploading model into container now
2023-01-19 23:40:18,535:INFO:_master_model_container: 18
2023-01-19 23:40:18,535:INFO:_display_container: 5
2023-01-19 23:40:18,544:INFO:BayesianRidge(alpha_1=0.0005, lambda_1=0.3, lambda_2=0.0001, normalize=False)
2023-01-19 23:40:18,544:INFO:create_model() successfully completed......................................
2023-01-19 23:40:18,714:INFO:SubProcess create_model() end ==================================
2023-01-19 23:40:18,715:INFO:choose_better activated
2023-01-19 23:40:18,719:INFO:SubProcess create_model() called ==================================
2023-01-19 23:40:18,720:INFO:Initializing create_model()
2023-01-19 23:40:18,720:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc65940dbe0>, estimator=BayesianRidge(), fold=KFold(n_splits=10, random_state=3983, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:40:18,720:INFO:Checking exceptions
2023-01-19 23:40:18,722:INFO:Importing libraries
2023-01-19 23:40:18,722:INFO:Copying training dataset
2023-01-19 23:40:18,727:INFO:Defining folds
2023-01-19 23:40:18,727:INFO:Declaring metric variables
2023-01-19 23:40:18,727:INFO:Importing untrained model
2023-01-19 23:40:18,728:INFO:Declaring custom model
2023-01-19 23:40:18,728:INFO:Bayesian Ridge Imported successfully
2023-01-19 23:40:18,728:INFO:Starting cross validation
2023-01-19 23:40:18,730:INFO:Cross validating with KFold(n_splits=10, random_state=3983, shuffle=True), n_jobs=-1
2023-01-19 23:40:18,969:INFO:Calculating mean and std
2023-01-19 23:40:18,970:INFO:Creating metrics dataframe
2023-01-19 23:40:18,972:INFO:Finalizing model
2023-01-19 23:40:19,015:INFO:Uploading results into container
2023-01-19 23:40:19,016:INFO:Uploading model into container now
2023-01-19 23:40:19,016:INFO:_master_model_container: 19
2023-01-19 23:40:19,016:INFO:_display_container: 6
2023-01-19 23:40:19,016:INFO:BayesianRidge()
2023-01-19 23:40:19,016:INFO:create_model() successfully completed......................................
2023-01-19 23:40:19,151:INFO:SubProcess create_model() end ==================================
2023-01-19 23:40:19,152:INFO:BayesianRidge() result for R2 is 0.8684
2023-01-19 23:40:19,152:INFO:BayesianRidge(alpha_1=0.0005, lambda_1=0.3, lambda_2=0.0001, normalize=False) result for R2 is 0.8685
2023-01-19 23:40:19,153:INFO:BayesianRidge(alpha_1=0.0005, lambda_1=0.3, lambda_2=0.0001, normalize=False) is best model
2023-01-19 23:40:19,153:INFO:choose_better completed
2023-01-19 23:40:19,166:INFO:_master_model_container: 19
2023-01-19 23:40:19,166:INFO:_display_container: 5
2023-01-19 23:40:19,167:INFO:BayesianRidge(alpha_1=0.0005, lambda_1=0.3, lambda_2=0.0001, normalize=False)
2023-01-19 23:40:19,167:INFO:tune_model() successfully completed......................................
2023-01-19 23:40:56,664:INFO:Initializing plot_model()
2023-01-19 23:40:56,665:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=<catboost.core.CatBoostRegressor object at 0x7fc6469a1880>, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc65940dbe0>, system=True)
2023-01-19 23:40:56,666:INFO:Checking exceptions
2023-01-19 23:40:56,737:INFO:Preloading libraries
2023-01-19 23:40:56,776:INFO:Copying training dataset
2023-01-19 23:40:56,776:INFO:Plot type: residuals
2023-01-19 23:40:57,153:INFO:Fitting Model
2023-01-19 23:40:57,304:INFO:Scoring test/hold-out set
2023-01-19 23:40:57,960:INFO:Visual Rendered Successfully
2023-01-19 23:40:58,456:INFO:plot_model() successfully completed......................................
2023-01-19 23:41:14,591:INFO:Initializing plot_model()
2023-01-19 23:41:14,592:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=BayesianRidge(alpha_1=0.0005, lambda_1=0.3, lambda_2=0.0001, normalize=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc65940dbe0>, system=True)
2023-01-19 23:41:14,592:INFO:Checking exceptions
2023-01-19 23:41:14,601:INFO:Preloading libraries
2023-01-19 23:41:14,606:INFO:Copying training dataset
2023-01-19 23:41:14,606:INFO:Plot type: residuals
2023-01-19 23:41:14,719:INFO:Fitting Model
2023-01-19 23:41:14,722:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but BayesianRidge was fitted with feature names
  warnings.warn(

2023-01-19 23:41:14,782:INFO:Scoring test/hold-out set
2023-01-19 23:41:15,204:INFO:Visual Rendered Successfully
2023-01-19 23:41:15,348:INFO:plot_model() successfully completed......................................
2023-01-19 23:41:23,122:INFO:Initializing plot_model()
2023-01-19 23:41:23,123:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=BayesianRidge(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc65940dbe0>, system=True)
2023-01-19 23:41:23,123:INFO:Checking exceptions
2023-01-19 23:41:23,141:INFO:Preloading libraries
2023-01-19 23:41:23,174:INFO:Copying training dataset
2023-01-19 23:41:23,174:INFO:Plot type: residuals
2023-01-19 23:41:23,340:INFO:Fitting Model
2023-01-19 23:41:23,341:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but BayesianRidge was fitted with feature names
  warnings.warn(

2023-01-19 23:41:23,404:INFO:Scoring test/hold-out set
2023-01-19 23:41:23,869:INFO:Visual Rendered Successfully
2023-01-19 23:41:24,021:INFO:plot_model() successfully completed......................................
2023-01-19 23:41:41,245:INFO:Initializing create_model()
2023-01-19 23:41:41,246:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc65940dbe0>, estimator=br, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:41:41,246:INFO:Checking exceptions
2023-01-19 23:41:41,276:INFO:Importing libraries
2023-01-19 23:41:41,276:INFO:Copying training dataset
2023-01-19 23:41:41,282:INFO:Defining folds
2023-01-19 23:41:41,282:INFO:Declaring metric variables
2023-01-19 23:41:41,289:INFO:Importing untrained model
2023-01-19 23:41:41,296:INFO:Bayesian Ridge Imported successfully
2023-01-19 23:41:41,306:INFO:Starting cross validation
2023-01-19 23:41:41,309:INFO:Cross validating with KFold(n_splits=10, random_state=3983, shuffle=True), n_jobs=-1
2023-01-19 23:41:41,735:INFO:Calculating mean and std
2023-01-19 23:41:41,735:INFO:Creating metrics dataframe
2023-01-19 23:41:41,743:INFO:Finalizing model
2023-01-19 23:41:41,805:INFO:Uploading results into container
2023-01-19 23:41:41,806:INFO:Uploading model into container now
2023-01-19 23:41:41,820:INFO:_master_model_container: 20
2023-01-19 23:41:41,820:INFO:_display_container: 6
2023-01-19 23:41:41,820:INFO:BayesianRidge()
2023-01-19 23:41:41,820:INFO:create_model() successfully completed......................................
2023-01-19 23:41:41,984:INFO:Initializing tune_model()
2023-01-19 23:41:41,984:INFO:tune_model(estimator=BayesianRidge(), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc65940dbe0>)
2023-01-19 23:41:41,984:INFO:Checking exceptions
2023-01-19 23:41:42,007:INFO:Copying training dataset
2023-01-19 23:41:42,015:INFO:Checking base model
2023-01-19 23:41:42,015:INFO:Base model : Bayesian Ridge
2023-01-19 23:41:42,019:INFO:Declaring metric variables
2023-01-19 23:41:42,022:INFO:Defining Hyperparameters
2023-01-19 23:41:42,172:INFO:Tuning with n_jobs=-1
2023-01-19 23:41:42,172:INFO:Initializing RandomizedSearchCV
2023-01-19 23:41:42,235:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:42,238:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:42,249:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:42,253:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:42,254:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:42,270:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:42,281:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:42,285:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:42,353:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:42,360:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:42,383:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:42,386:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:42,404:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:42,410:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:42,414:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:42,442:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:42,489:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:42,511:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:42,515:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:42,539:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:42,545:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:42,545:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:42,550:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:42,564:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:42,607:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:42,627:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:42,633:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:42,656:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:42,660:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:42,661:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:42,667:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:42,670:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:42,733:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:42,757:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:42,775:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:42,775:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:42,790:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:42,801:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:42,810:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:42,826:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:42,830:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:42,865:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:42,889:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:42,895:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:42,920:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:42,957:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:42,981:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:43,003:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:43,004:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:43,040:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:43,071:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:43,087:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:43,122:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:43,134:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:43,152:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:43,165:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:43,173:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:43,225:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:43,258:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:43,265:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:43,298:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:43,306:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:43,360:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:43,381:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:43,387:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:43,420:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:43,461:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:43,468:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:43,504:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:43,519:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:43,555:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:43,562:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:43,590:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:43,616:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:43,674:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:43,693:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:43,736:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:43,745:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:43,775:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:43,797:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:43,800:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:43,819:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:43,868:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:43,892:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:43,926:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:43,937:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:43,957:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:43,964:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:43,970:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:43,991:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:44,026:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:44,047:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:44,084:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:44,122:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:44,145:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:44,149:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:44,163:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:44,190:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:44,207:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:44,226:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), BayesianRidge())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:41:44,287:INFO:best_params: {'actual_estimator__normalize': False, 'actual_estimator__lambda_2': 0.0001, 'actual_estimator__lambda_1': 0.3, 'actual_estimator__fit_intercept': True, 'actual_estimator__compute_score': False, 'actual_estimator__alpha_2': 1e-06, 'actual_estimator__alpha_1': 0.0005}
2023-01-19 23:41:44,288:INFO:Hyperparameter search completed
2023-01-19 23:41:44,288:INFO:SubProcess create_model() called ==================================
2023-01-19 23:41:44,288:INFO:Initializing create_model()
2023-01-19 23:41:44,288:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc65940dbe0>, estimator=BayesianRidge(), fold=KFold(n_splits=10, random_state=3983, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc6444a1610>, model_only=True, return_train_score=False, kwargs={'normalize': False, 'lambda_2': 0.0001, 'lambda_1': 0.3, 'fit_intercept': True, 'compute_score': False, 'alpha_2': 1e-06, 'alpha_1': 0.0005})
2023-01-19 23:41:44,288:INFO:Checking exceptions
2023-01-19 23:41:44,289:INFO:Importing libraries
2023-01-19 23:41:44,289:INFO:Copying training dataset
2023-01-19 23:41:44,294:INFO:Defining folds
2023-01-19 23:41:44,294:INFO:Declaring metric variables
2023-01-19 23:41:44,298:INFO:Importing untrained model
2023-01-19 23:41:44,299:INFO:Declaring custom model
2023-01-19 23:41:44,303:INFO:Bayesian Ridge Imported successfully
2023-01-19 23:41:44,311:INFO:Starting cross validation
2023-01-19 23:41:44,313:INFO:Cross validating with KFold(n_splits=10, random_state=3983, shuffle=True), n_jobs=-1
2023-01-19 23:41:44,371:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:44,385:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:44,399:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:44,435:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:44,444:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:44,447:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:44,451:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:44,451:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:44,511:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:44,533:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:44,572:INFO:Calculating mean and std
2023-01-19 23:41:44,573:INFO:Creating metrics dataframe
2023-01-19 23:41:44,578:INFO:Finalizing model
2023-01-19 23:41:44,598:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:41:44,629:INFO:Uploading results into container
2023-01-19 23:41:44,630:INFO:Uploading model into container now
2023-01-19 23:41:44,630:INFO:_master_model_container: 21
2023-01-19 23:41:44,631:INFO:_display_container: 7
2023-01-19 23:41:44,631:INFO:BayesianRidge(alpha_1=0.0005, lambda_1=0.3, lambda_2=0.0001, normalize=False)
2023-01-19 23:41:44,632:INFO:create_model() successfully completed......................................
2023-01-19 23:41:44,776:INFO:SubProcess create_model() end ==================================
2023-01-19 23:41:44,777:INFO:choose_better activated
2023-01-19 23:41:44,781:INFO:SubProcess create_model() called ==================================
2023-01-19 23:41:44,782:INFO:Initializing create_model()
2023-01-19 23:41:44,782:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc65940dbe0>, estimator=BayesianRidge(), fold=KFold(n_splits=10, random_state=3983, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:41:44,782:INFO:Checking exceptions
2023-01-19 23:41:44,785:INFO:Importing libraries
2023-01-19 23:41:44,785:INFO:Copying training dataset
2023-01-19 23:41:44,789:INFO:Defining folds
2023-01-19 23:41:44,789:INFO:Declaring metric variables
2023-01-19 23:41:44,789:INFO:Importing untrained model
2023-01-19 23:41:44,789:INFO:Declaring custom model
2023-01-19 23:41:44,790:INFO:Bayesian Ridge Imported successfully
2023-01-19 23:41:44,790:INFO:Starting cross validation
2023-01-19 23:41:44,792:INFO:Cross validating with KFold(n_splits=10, random_state=3983, shuffle=True), n_jobs=-1
2023-01-19 23:41:45,059:INFO:Calculating mean and std
2023-01-19 23:41:45,060:INFO:Creating metrics dataframe
2023-01-19 23:41:45,062:INFO:Finalizing model
2023-01-19 23:41:45,112:INFO:Uploading results into container
2023-01-19 23:41:45,113:INFO:Uploading model into container now
2023-01-19 23:41:45,114:INFO:_master_model_container: 22
2023-01-19 23:41:45,114:INFO:_display_container: 8
2023-01-19 23:41:45,115:INFO:BayesianRidge()
2023-01-19 23:41:45,115:INFO:create_model() successfully completed......................................
2023-01-19 23:41:45,283:INFO:SubProcess create_model() end ==================================
2023-01-19 23:41:45,283:INFO:BayesianRidge() result for R2 is 0.8684
2023-01-19 23:41:45,284:INFO:BayesianRidge(alpha_1=0.0005, lambda_1=0.3, lambda_2=0.0001, normalize=False) result for R2 is 0.8685
2023-01-19 23:41:45,284:INFO:BayesianRidge(alpha_1=0.0005, lambda_1=0.3, lambda_2=0.0001, normalize=False) is best model
2023-01-19 23:41:45,284:INFO:choose_better completed
2023-01-19 23:41:45,298:INFO:_master_model_container: 22
2023-01-19 23:41:45,298:INFO:_display_container: 7
2023-01-19 23:41:45,298:INFO:BayesianRidge(alpha_1=0.0005, lambda_1=0.3, lambda_2=0.0001, normalize=False)
2023-01-19 23:41:45,298:INFO:tune_model() successfully completed......................................
2023-01-19 23:41:48,647:INFO:Initializing plot_model()
2023-01-19 23:41:48,647:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=BayesianRidge(alpha_1=0.0005, lambda_1=0.3, lambda_2=0.0001, normalize=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc65940dbe0>, system=True)
2023-01-19 23:41:48,648:INFO:Checking exceptions
2023-01-19 23:41:48,655:INFO:Preloading libraries
2023-01-19 23:41:48,655:INFO:Copying training dataset
2023-01-19 23:41:48,655:INFO:Plot type: residuals
2023-01-19 23:41:48,766:INFO:Fitting Model
2023-01-19 23:41:48,767:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but BayesianRidge was fitted with feature names
  warnings.warn(

2023-01-19 23:41:48,846:INFO:Scoring test/hold-out set
2023-01-19 23:41:49,269:INFO:Visual Rendered Successfully
2023-01-19 23:41:49,421:INFO:plot_model() successfully completed......................................
2023-01-19 23:42:39,552:INFO:Initializing plot_model()
2023-01-19 23:42:39,553:INFO:plot_model(plot=residuals, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=BayesianRidge(), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc65940dbe0>, system=True)
2023-01-19 23:42:39,553:INFO:Checking exceptions
2023-01-19 23:42:39,560:INFO:Preloading libraries
2023-01-19 23:42:39,561:INFO:Copying training dataset
2023-01-19 23:42:39,561:INFO:Plot type: residuals
2023-01-19 23:42:39,691:INFO:Fitting Model
2023-01-19 23:42:39,691:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but BayesianRidge was fitted with feature names
  warnings.warn(

2023-01-19 23:42:39,778:INFO:Scoring test/hold-out set
2023-01-19 23:42:40,165:INFO:Visual Rendered Successfully
2023-01-19 23:42:40,310:INFO:plot_model() successfully completed......................................
2023-01-19 23:42:45,235:INFO:Initializing predict_model()
2023-01-19 23:42:45,235:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc65940dbe0>, estimator=BayesianRidge(), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fc6464e2280>)
2023-01-19 23:42:45,235:INFO:Checking exceptions
2023-01-19 23:42:45,235:INFO:Preloading libraries
2023-01-19 23:43:58,615:INFO:Initializing finalize_model()
2023-01-19 23:43:58,616:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc65940dbe0>, estimator=BayesianRidge(alpha_1=0.0005, lambda_1=0.3, lambda_2=0.0001, normalize=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-01-19 23:43:58,617:INFO:Finalizing BayesianRidge(alpha_1=0.0005, lambda_1=0.3, lambda_2=0.0001, normalize=False)
2023-01-19 23:43:58,623:INFO:Initializing create_model()
2023-01-19 23:43:58,623:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc65940dbe0>, estimator=BayesianRidge(alpha_1=0.0005, lambda_1=0.3, lambda_2=0.0001, normalize=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-01-19 23:43:58,624:INFO:Checking exceptions
2023-01-19 23:43:58,626:INFO:Importing libraries
2023-01-19 23:43:58,626:INFO:Copying training dataset
2023-01-19 23:43:58,627:INFO:Defining folds
2023-01-19 23:43:58,627:INFO:Declaring metric variables
2023-01-19 23:43:58,628:INFO:Importing untrained model
2023-01-19 23:43:58,628:INFO:Declaring custom model
2023-01-19 23:43:58,629:INFO:Bayesian Ridge Imported successfully
2023-01-19 23:43:58,631:INFO:Cross validation set to False
2023-01-19 23:43:58,631:INFO:Fitting Model
2023-01-19 23:43:58,941:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:43:58,981:INFO:Pipeline(memory=Memory(location=/var/folders/3w/xf1fzw1s1mnb4ckhfxf67vgw0000gn/T/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['MSSubClass', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '...
                                             'TotRmsAbvGrd', 'Fireplaces',
                                             'GarageCars', 'GarageArea',
                                             'WoodDeckSF', 'OpenPorchSF',
                                             'EnclosedPorch', '3SsnPorch',
                                             'ScreenPorch', 'PoolArea', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 BayesianRidge(alpha_1=0.0005, lambda_1=0.3, lambda_2=0.0001,
                               normalize=False))])
2023-01-19 23:43:58,982:INFO:create_model() successfully completed......................................
2023-01-19 23:43:59,124:INFO:_master_model_container: 22
2023-01-19 23:43:59,124:INFO:_display_container: 8
2023-01-19 23:43:59,134:INFO:Pipeline(memory=Memory(location=/var/folders/3w/xf1fzw1s1mnb4ckhfxf67vgw0000gn/T/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['MSSubClass', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '...
                                             'TotRmsAbvGrd', 'Fireplaces',
                                             'GarageCars', 'GarageArea',
                                             'WoodDeckSF', 'OpenPorchSF',
                                             'EnclosedPorch', '3SsnPorch',
                                             'ScreenPorch', 'PoolArea', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 BayesianRidge(alpha_1=0.0005, lambda_1=0.3, lambda_2=0.0001,
                               normalize=False))])
2023-01-19 23:43:59,134:INFO:finalize_model() successfully completed......................................
2023-01-19 23:44:07,728:INFO:Initializing finalize_model()
2023-01-19 23:44:07,728:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc65940dbe0>, estimator=BayesianRidge(alpha_1=0.0005, lambda_1=0.3, lambda_2=0.0001, normalize=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-01-19 23:44:07,729:INFO:Finalizing BayesianRidge(alpha_1=0.0005, lambda_1=0.3, lambda_2=0.0001, normalize=False)
2023-01-19 23:44:07,733:INFO:Initializing create_model()
2023-01-19 23:44:07,733:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc65940dbe0>, estimator=BayesianRidge(alpha_1=0.0005, lambda_1=0.3, lambda_2=0.0001, normalize=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-01-19 23:44:07,733:INFO:Checking exceptions
2023-01-19 23:44:07,735:INFO:Importing libraries
2023-01-19 23:44:07,735:INFO:Copying training dataset
2023-01-19 23:44:07,736:INFO:Defining folds
2023-01-19 23:44:07,736:INFO:Declaring metric variables
2023-01-19 23:44:07,737:INFO:Importing untrained model
2023-01-19 23:44:07,737:INFO:Declaring custom model
2023-01-19 23:44:07,738:INFO:Bayesian Ridge Imported successfully
2023-01-19 23:44:07,739:INFO:Cross validation set to False
2023-01-19 23:44:07,740:INFO:Fitting Model
2023-01-19 23:44:07,770:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.
  warnings.warn(

2023-01-19 23:44:07,831:INFO:Pipeline(memory=Memory(location=/var/folders/3w/xf1fzw1s1mnb4ckhfxf67vgw0000gn/T/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['MSSubClass', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '...
                                             'TotRmsAbvGrd', 'Fireplaces',
                                             'GarageCars', 'GarageArea',
                                             'WoodDeckSF', 'OpenPorchSF',
                                             'EnclosedPorch', '3SsnPorch',
                                             'ScreenPorch', 'PoolArea', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 BayesianRidge(alpha_1=0.0005, lambda_1=0.3, lambda_2=0.0001,
                               normalize=False))])
2023-01-19 23:44:07,831:INFO:create_model() successfully completed......................................
2023-01-19 23:44:08,034:INFO:_master_model_container: 22
2023-01-19 23:44:08,034:INFO:_display_container: 8
2023-01-19 23:44:08,044:INFO:Pipeline(memory=Memory(location=/var/folders/3w/xf1fzw1s1mnb4ckhfxf67vgw0000gn/T/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['MSSubClass', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '...
                                             'TotRmsAbvGrd', 'Fireplaces',
                                             'GarageCars', 'GarageArea',
                                             'WoodDeckSF', 'OpenPorchSF',
                                             'EnclosedPorch', '3SsnPorch',
                                             'ScreenPorch', 'PoolArea', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 BayesianRidge(alpha_1=0.0005, lambda_1=0.3, lambda_2=0.0001,
                               normalize=False))])
2023-01-19 23:44:08,044:INFO:finalize_model() successfully completed......................................
2023-01-19 23:44:08,178:INFO:Initializing finalize_model()
2023-01-19 23:44:08,178:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc65940dbe0>, estimator=BayesianRidge(), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-01-19 23:44:08,179:INFO:Finalizing BayesianRidge()
2023-01-19 23:44:08,223:INFO:Initializing create_model()
2023-01-19 23:44:08,223:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc65940dbe0>, estimator=BayesianRidge(), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-01-19 23:44:08,223:INFO:Checking exceptions
2023-01-19 23:44:08,225:INFO:Importing libraries
2023-01-19 23:44:08,225:INFO:Copying training dataset
2023-01-19 23:44:08,226:INFO:Defining folds
2023-01-19 23:44:08,226:INFO:Declaring metric variables
2023-01-19 23:44:08,226:INFO:Importing untrained model
2023-01-19 23:44:08,226:INFO:Declaring custom model
2023-01-19 23:44:08,226:INFO:Bayesian Ridge Imported successfully
2023-01-19 23:44:08,228:INFO:Cross validation set to False
2023-01-19 23:44:08,228:INFO:Fitting Model
2023-01-19 23:44:08,296:INFO:Pipeline(memory=Memory(location=/var/folders/3w/xf1fzw1s1mnb4ckhfxf67vgw0000gn/T/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['MSSubClass', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '...
                                             'FullBath', 'HalfBath',
                                             'BedroomAbvGr', 'KitchenAbvGr',
                                             'TotRmsAbvGrd', 'Fireplaces',
                                             'GarageCars', 'GarageArea',
                                             'WoodDeckSF', 'OpenPorchSF',
                                             'EnclosedPorch', '3SsnPorch',
                                             'ScreenPorch', 'PoolArea', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator', BayesianRidge())])
2023-01-19 23:44:08,296:INFO:create_model() successfully completed......................................
2023-01-19 23:44:08,443:INFO:_master_model_container: 22
2023-01-19 23:44:08,443:INFO:_display_container: 8
2023-01-19 23:44:08,453:INFO:Pipeline(memory=Memory(location=/var/folders/3w/xf1fzw1s1mnb4ckhfxf67vgw0000gn/T/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['MSSubClass', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '...
                                             'FullBath', 'HalfBath',
                                             'BedroomAbvGr', 'KitchenAbvGr',
                                             'TotRmsAbvGrd', 'Fireplaces',
                                             'GarageCars', 'GarageArea',
                                             'WoodDeckSF', 'OpenPorchSF',
                                             'EnclosedPorch', '3SsnPorch',
                                             'ScreenPorch', 'PoolArea', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator', BayesianRidge())])
2023-01-19 23:44:08,453:INFO:finalize_model() successfully completed......................................
2023-01-19 23:45:11,837:INFO:PyCaret RegressionExperiment
2023-01-19 23:45:11,838:INFO:Logging name: reg-default-name
2023-01-19 23:45:11,838:INFO:ML Usecase: MLUsecase.REGRESSION
2023-01-19 23:45:11,838:INFO:version 3.0.0.rc8
2023-01-19 23:45:11,838:INFO:Initializing setup()
2023-01-19 23:45:11,838:INFO:self.USI: 0add
2023-01-19 23:45:11,838:INFO:self._variable_keys: {'gpu_n_jobs_param', 'logging_param', 'target_param', 'y_train', 'transform_target_param', 'data', 'gpu_param', 'exp_id', 'pipeline', 'log_plots_param', 'y', 'fold_groups_param', 'fold_generator', 'X_train', 'html_param', '_available_plots', 'fold_shuffle_param', 'X', 'USI', 'n_jobs_param', 'memory', 'y_test', 'X_test', 'exp_name_log', 'idx', 'seed', '_ml_usecase'}
2023-01-19 23:45:11,839:INFO:Checking environment
2023-01-19 23:45:11,840:INFO:python_version: 3.9.12
2023-01-19 23:45:11,840:INFO:python_build: ('main', 'Apr  5 2022 01:53:17')
2023-01-19 23:45:11,840:INFO:machine: x86_64
2023-01-19 23:45:11,840:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-01-19 23:45:11,844:INFO:Memory: svmem(total=8589934592, available=2629279744, percent=69.4, used=5438324736, free=656941056, active=1974992896, inactive=1941372928, wired=3463331840)
2023-01-19 23:45:11,844:INFO:Physical Core: 4
2023-01-19 23:45:11,845:INFO:Logical Core: 8
2023-01-19 23:45:11,845:INFO:Checking libraries
2023-01-19 23:45:11,846:INFO:System:
2023-01-19 23:45:11,847:INFO:    python: 3.9.12 (main, Apr  5 2022, 01:53:17)  [Clang 12.0.0 ]
2023-01-19 23:45:11,847:INFO:executable: /Users/hiroto/opt/anaconda3/bin/python
2023-01-19 23:45:11,847:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-01-19 23:45:11,847:INFO:PyCaret required dependencies:
2023-01-19 23:45:11,850:INFO:                 pip: 21.2.4
2023-01-19 23:45:11,850:INFO:          setuptools: 66.0.0
2023-01-19 23:45:11,850:INFO:             pycaret: 3.0.0rc8
2023-01-19 23:45:11,850:INFO:             IPython: 8.8.0
2023-01-19 23:45:11,850:INFO:          ipywidgets: 8.0.4
2023-01-19 23:45:11,850:INFO:                tqdm: 4.64.1
2023-01-19 23:45:11,850:INFO:               numpy: 1.23.5
2023-01-19 23:45:11,850:INFO:              pandas: 1.5.3
2023-01-19 23:45:11,850:INFO:              jinja2: 3.1.2
2023-01-19 23:45:11,850:INFO:               scipy: 1.10.0
2023-01-19 23:45:11,850:INFO:              joblib: 1.2.0
2023-01-19 23:45:11,850:INFO:             sklearn: 1.1.3
2023-01-19 23:45:11,850:INFO:                pyod: 1.0.7
2023-01-19 23:45:11,850:INFO:            imblearn: 0.10.1
2023-01-19 23:45:11,850:INFO:   category_encoders: 2.6.0
2023-01-19 23:45:11,851:INFO:            lightgbm: 3.3.4
2023-01-19 23:45:11,851:INFO:               numba: 0.56.4
2023-01-19 23:45:11,851:INFO:            requests: 2.28.2
2023-01-19 23:45:11,851:INFO:          matplotlib: 3.6.3
2023-01-19 23:45:11,851:INFO:          scikitplot: 0.3.7
2023-01-19 23:45:11,851:INFO:         yellowbrick: 1.5
2023-01-19 23:45:11,851:INFO:              plotly: 5.12.0
2023-01-19 23:45:11,851:INFO:             kaleido: 0.2.1
2023-01-19 23:45:11,851:INFO:         statsmodels: 0.13.5
2023-01-19 23:45:11,851:INFO:              sktime: 0.15.1
2023-01-19 23:45:11,851:INFO:               tbats: 1.1.2
2023-01-19 23:45:11,851:INFO:            pmdarima: 2.0.2
2023-01-19 23:45:11,851:INFO:              psutil: 5.9.4
2023-01-19 23:45:11,851:INFO:PyCaret optional dependencies:
2023-01-19 23:45:11,851:INFO:                shap: 0.41.0
2023-01-19 23:45:11,851:INFO:           interpret: Not installed
2023-01-19 23:45:11,851:INFO:                umap: 0.5.3
2023-01-19 23:45:11,851:INFO:    pandas_profiling: 3.6.2
2023-01-19 23:45:11,851:INFO:  explainerdashboard: Not installed
2023-01-19 23:45:11,851:INFO:             autoviz: Not installed
2023-01-19 23:45:11,851:INFO:           fairlearn: Not installed
2023-01-19 23:45:11,851:INFO:             xgboost: 1.7.3
2023-01-19 23:45:11,851:INFO:            catboost: 1.1.1
2023-01-19 23:45:11,851:INFO:              kmodes: 0.12.2
2023-01-19 23:45:11,851:INFO:             mlxtend: 0.21.0
2023-01-19 23:45:11,852:INFO:       statsforecast: Not installed
2023-01-19 23:45:11,852:INFO:        tune_sklearn: Not installed
2023-01-19 23:45:11,852:INFO:                 ray: Not installed
2023-01-19 23:45:11,852:INFO:            hyperopt: Not installed
2023-01-19 23:45:11,852:INFO:              optuna: Not installed
2023-01-19 23:45:11,852:INFO:               skopt: Not installed
2023-01-19 23:45:11,852:INFO:              mlflow: 2.1.1
2023-01-19 23:45:11,852:INFO:              gradio: Not installed
2023-01-19 23:45:11,852:INFO:             fastapi: Not installed
2023-01-19 23:45:11,852:INFO:             uvicorn: Not installed
2023-01-19 23:45:11,852:INFO:              m2cgen: Not installed
2023-01-19 23:45:11,852:INFO:           evidently: Not installed
2023-01-19 23:45:11,852:INFO:                nltk: 3.8.1
2023-01-19 23:45:11,852:INFO:            pyLDAvis: 3.3.1
2023-01-19 23:45:11,852:INFO:              gensim: 4.3.0
2023-01-19 23:45:11,852:INFO:               spacy: 3.4.4
2023-01-19 23:45:11,852:INFO:           wordcloud: 1.8.2.2
2023-01-19 23:45:11,852:INFO:            textblob: 0.17.1
2023-01-19 23:45:11,852:INFO:               fugue: Not installed
2023-01-19 23:45:11,852:INFO:           streamlit: Not installed
2023-01-19 23:45:11,852:INFO:             prophet: Not installed
2023-01-19 23:45:11,852:INFO:None
2023-01-19 23:45:11,853:INFO:Set up data.
2023-01-19 23:45:11,949:INFO:Set up train/test split.
2023-01-19 23:45:11,968:INFO:Set up index.
2023-01-19 23:45:11,971:INFO:Set up folding strategy.
2023-01-19 23:45:11,972:INFO:Assigning column types.
2023-01-19 23:45:11,981:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-01-19 23:45:11,985:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-19 23:45:11,989:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-19 23:45:11,995:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-19 23:45:12,062:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-19 23:45:12,112:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-19 23:45:12,118:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:45:12,126:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:45:12,129:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-19 23:45:12,134:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-19 23:45:12,139:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-19 23:45:12,202:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-19 23:45:12,250:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-19 23:45:12,252:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:45:12,255:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:45:12,255:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-01-19 23:45:12,261:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-19 23:45:12,266:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-19 23:45:12,330:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-19 23:45:12,377:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-19 23:45:12,378:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:45:12,381:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:45:12,386:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-19 23:45:12,391:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-19 23:45:12,451:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-19 23:45:12,498:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-19 23:45:12,498:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:45:12,501:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:45:12,501:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-01-19 23:45:12,511:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-19 23:45:12,574:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-19 23:45:12,627:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-19 23:45:12,627:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:45:12,630:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:45:12,640:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-19 23:45:12,701:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-19 23:45:12,747:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-19 23:45:12,748:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:45:12,751:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:45:12,751:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-01-19 23:45:12,821:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-19 23:45:12,867:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-19 23:45:12,868:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:45:12,871:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:45:12,946:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-19 23:45:12,991:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-19 23:45:12,991:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:45:12,995:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:45:12,995:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-01-19 23:45:13,068:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-19 23:45:13,115:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:45:13,118:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:45:13,190:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-19 23:45:13,237:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:45:13,239:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:45:13,240:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-01-19 23:45:13,363:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:45:13,366:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:45:13,481:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:45:13,484:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:45:13,507:INFO:Preparing preprocessing pipeline...
2023-01-19 23:45:13,510:INFO:Set up column name cleaning.
2023-01-19 23:45:13,512:INFO:Set up simple imputation.
2023-01-19 23:45:13,781:INFO:Finished creating preprocessing pipeline.
2023-01-19 23:45:13,794:INFO:Pipeline: Pipeline(memory=Memory(location=/var/folders/3w/xf1fzw1s1mnb4ckhfxf67vgw0000gn/T/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['MSSubClass', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '...
                                             'BsmtFullBath', 'BsmtHalfBath',
                                             'FullBath', 'HalfBath',
                                             'BedroomAbvGr', 'KitchenAbvGr',
                                             'TotRmsAbvGrd', 'Fireplaces',
                                             'GarageCars', 'GarageArea',
                                             'WoodDeckSF', 'OpenPorchSF',
                                             'EnclosedPorch', '3SsnPorch',
                                             'ScreenPorch', 'PoolArea', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-01-19 23:45:13,794:INFO:Creating final display dataframe.
2023-01-19 23:45:14,486:INFO:Setup _display_container:                     Description             Value
0                    Session id              1611
1                        Target         SalePrice
2                   Target type        Regression
3           Original data shape       (1458, 193)
4        Transformed data shape       (1458, 193)
5   Transformed train set shape       (1020, 193)
6    Transformed test set shape        (438, 193)
7              Numeric features               192
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              0add
2023-01-19 23:45:14,668:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:45:14,676:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:45:14,791:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-19 23:45:14,794:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-19 23:45:14,797:INFO:setup() successfully completed in 3.01s...............
2023-01-19 23:45:15,135:INFO:Initializing compare_models()
2023-01-19 23:45:15,135:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc645499190>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7fc645499190>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2023-01-19 23:45:15,135:INFO:Checking exceptions
2023-01-19 23:45:15,141:INFO:Preparing display monitor
2023-01-19 23:45:15,221:INFO:Initializing Linear Regression
2023-01-19 23:45:15,221:INFO:Total runtime is 3.635883331298828e-06 minutes
2023-01-19 23:45:15,226:INFO:SubProcess create_model() called ==================================
2023-01-19 23:45:15,232:INFO:Initializing create_model()
2023-01-19 23:45:15,233:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc645499190>, estimator=lr, fold=KFold(n_splits=10, random_state=1611, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc6469a1d90>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:45:15,233:INFO:Checking exceptions
2023-01-19 23:45:15,233:INFO:Importing libraries
2023-01-19 23:45:15,233:INFO:Copying training dataset
2023-01-19 23:45:15,237:INFO:Defining folds
2023-01-19 23:45:15,237:INFO:Declaring metric variables
2023-01-19 23:45:15,240:INFO:Importing untrained model
2023-01-19 23:45:15,244:INFO:Linear Regression Imported successfully
2023-01-19 23:45:15,252:INFO:Starting cross validation
2023-01-19 23:45:15,253:INFO:Cross validating with KFold(n_splits=10, random_state=1611, shuffle=True), n_jobs=-1
2023-01-19 23:45:20,799:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:192: UserWarning: Persisting input arguments took 1.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2023-01-19 23:45:20,799:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:192: UserWarning: Persisting input arguments took 1.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2023-01-19 23:45:20,808:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:192: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2023-01-19 23:45:20,808:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:192: UserWarning: Persisting input arguments took 1.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2023-01-19 23:45:20,809:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:192: UserWarning: Persisting input arguments took 1.15s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2023-01-19 23:45:20,811:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:192: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2023-01-19 23:45:20,815:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:192: UserWarning: Persisting input arguments took 1.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2023-01-19 23:45:20,962:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:192: UserWarning: Persisting input arguments took 1.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y, fitted_transformer = self._memory_fit(

2023-01-19 23:45:22,494:INFO:Calculating mean and std
2023-01-19 23:45:22,499:INFO:Creating metrics dataframe
2023-01-19 23:45:22,512:INFO:Uploading results into container
2023-01-19 23:45:22,515:INFO:Uploading model into container now
2023-01-19 23:45:22,518:INFO:_master_model_container: 1
2023-01-19 23:45:22,518:INFO:_display_container: 2
2023-01-19 23:45:22,518:INFO:LinearRegression(n_jobs=-1)
2023-01-19 23:45:22,519:INFO:create_model() successfully completed......................................
2023-01-19 23:45:23,643:INFO:SubProcess create_model() end ==================================
2023-01-19 23:45:23,643:INFO:Creating metrics dataframe
2023-01-19 23:45:23,660:INFO:Initializing Lasso Regression
2023-01-19 23:45:23,660:INFO:Total runtime is 0.14065223932266235 minutes
2023-01-19 23:45:23,666:INFO:SubProcess create_model() called ==================================
2023-01-19 23:45:23,666:INFO:Initializing create_model()
2023-01-19 23:45:23,666:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc645499190>, estimator=lasso, fold=KFold(n_splits=10, random_state=1611, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc6469a1d90>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:45:23,666:INFO:Checking exceptions
2023-01-19 23:45:23,666:INFO:Importing libraries
2023-01-19 23:45:23,667:INFO:Copying training dataset
2023-01-19 23:45:23,674:INFO:Defining folds
2023-01-19 23:45:23,674:INFO:Declaring metric variables
2023-01-19 23:45:23,682:INFO:Importing untrained model
2023-01-19 23:45:23,687:INFO:Lasso Regression Imported successfully
2023-01-19 23:45:23,697:INFO:Starting cross validation
2023-01-19 23:45:23,700:INFO:Cross validating with KFold(n_splits=10, random_state=1611, shuffle=True), n_jobs=-1
2023-01-19 23:45:23,904:INFO:Calculating mean and std
2023-01-19 23:45:23,905:INFO:Creating metrics dataframe
2023-01-19 23:45:23,908:INFO:Uploading results into container
2023-01-19 23:45:23,909:INFO:Uploading model into container now
2023-01-19 23:45:23,909:INFO:_master_model_container: 2
2023-01-19 23:45:23,909:INFO:_display_container: 2
2023-01-19 23:45:23,910:INFO:Lasso(random_state=1611)
2023-01-19 23:45:23,910:INFO:create_model() successfully completed......................................
2023-01-19 23:45:24,053:INFO:SubProcess create_model() end ==================================
2023-01-19 23:45:24,053:INFO:Creating metrics dataframe
2023-01-19 23:45:24,069:INFO:Initializing Ridge Regression
2023-01-19 23:45:24,069:INFO:Total runtime is 0.14747312068939208 minutes
2023-01-19 23:45:24,117:INFO:SubProcess create_model() called ==================================
2023-01-19 23:45:24,118:INFO:Initializing create_model()
2023-01-19 23:45:24,118:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc645499190>, estimator=ridge, fold=KFold(n_splits=10, random_state=1611, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc6469a1d90>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:45:24,118:INFO:Checking exceptions
2023-01-19 23:45:24,118:INFO:Importing libraries
2023-01-19 23:45:24,118:INFO:Copying training dataset
2023-01-19 23:45:24,122:INFO:Defining folds
2023-01-19 23:45:24,122:INFO:Declaring metric variables
2023-01-19 23:45:24,139:INFO:Importing untrained model
2023-01-19 23:45:24,143:INFO:Ridge Regression Imported successfully
2023-01-19 23:45:24,151:INFO:Starting cross validation
2023-01-19 23:45:24,154:INFO:Cross validating with KFold(n_splits=10, random_state=1611, shuffle=True), n_jobs=-1
2023-01-19 23:45:24,340:INFO:Calculating mean and std
2023-01-19 23:45:24,342:INFO:Creating metrics dataframe
2023-01-19 23:45:24,345:INFO:Uploading results into container
2023-01-19 23:45:24,346:INFO:Uploading model into container now
2023-01-19 23:45:24,346:INFO:_master_model_container: 3
2023-01-19 23:45:24,346:INFO:_display_container: 2
2023-01-19 23:45:24,347:INFO:Ridge(random_state=1611)
2023-01-19 23:45:24,347:INFO:create_model() successfully completed......................................
2023-01-19 23:45:24,478:INFO:SubProcess create_model() end ==================================
2023-01-19 23:45:24,478:INFO:Creating metrics dataframe
2023-01-19 23:45:24,492:INFO:Initializing Elastic Net
2023-01-19 23:45:24,492:INFO:Total runtime is 0.15452131827672322 minutes
2023-01-19 23:45:24,497:INFO:SubProcess create_model() called ==================================
2023-01-19 23:45:24,497:INFO:Initializing create_model()
2023-01-19 23:45:24,498:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc645499190>, estimator=en, fold=KFold(n_splits=10, random_state=1611, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc6469a1d90>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:45:24,498:INFO:Checking exceptions
2023-01-19 23:45:24,498:INFO:Importing libraries
2023-01-19 23:45:24,499:INFO:Copying training dataset
2023-01-19 23:45:24,504:INFO:Defining folds
2023-01-19 23:45:24,504:INFO:Declaring metric variables
2023-01-19 23:45:24,509:INFO:Importing untrained model
2023-01-19 23:45:24,513:INFO:Elastic Net Imported successfully
2023-01-19 23:45:24,522:INFO:Starting cross validation
2023-01-19 23:45:24,523:INFO:Cross validating with KFold(n_splits=10, random_state=1611, shuffle=True), n_jobs=-1
2023-01-19 23:45:24,722:INFO:Calculating mean and std
2023-01-19 23:45:24,723:INFO:Creating metrics dataframe
2023-01-19 23:45:24,728:INFO:Uploading results into container
2023-01-19 23:45:24,728:INFO:Uploading model into container now
2023-01-19 23:45:24,729:INFO:_master_model_container: 4
2023-01-19 23:45:24,729:INFO:_display_container: 2
2023-01-19 23:45:24,730:INFO:ElasticNet(random_state=1611)
2023-01-19 23:45:24,730:INFO:create_model() successfully completed......................................
2023-01-19 23:45:24,862:INFO:SubProcess create_model() end ==================================
2023-01-19 23:45:24,862:INFO:Creating metrics dataframe
2023-01-19 23:45:24,875:INFO:Initializing Least Angle Regression
2023-01-19 23:45:24,876:INFO:Total runtime is 0.16091383695602415 minutes
2023-01-19 23:45:24,880:INFO:SubProcess create_model() called ==================================
2023-01-19 23:45:24,880:INFO:Initializing create_model()
2023-01-19 23:45:24,881:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc645499190>, estimator=lar, fold=KFold(n_splits=10, random_state=1611, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc6469a1d90>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:45:24,881:INFO:Checking exceptions
2023-01-19 23:45:24,881:INFO:Importing libraries
2023-01-19 23:45:24,881:INFO:Copying training dataset
2023-01-19 23:45:24,887:INFO:Defining folds
2023-01-19 23:45:24,887:INFO:Declaring metric variables
2023-01-19 23:45:24,891:INFO:Importing untrained model
2023-01-19 23:45:24,900:INFO:Least Angle Regression Imported successfully
2023-01-19 23:45:24,907:INFO:Starting cross validation
2023-01-19 23:45:24,909:INFO:Cross validating with KFold(n_splits=10, random_state=1611, shuffle=True), n_jobs=-1
2023-01-19 23:45:24,956:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:45:24,965:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:45:24,983:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:45:24,998:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:45:25,021:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:45:25,044:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:45:25,046:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:45:25,070:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:45:25,077:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 203 iterations, i.e. alpha=3.325e-02, with an active set of 163 regressors, and the smallest cholesky pivot element being 9.306e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:45:25,085:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 211 iterations, i.e. alpha=6.271e-02, with an active set of 167 regressors, and the smallest cholesky pivot element being 9.306e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:45:25,085:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 211 iterations, i.e. alpha=5.105e-02, with an active set of 167 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:45:25,088:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 215 iterations, i.e. alpha=2.520e-02, with an active set of 171 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:45:25,090:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 221 iterations, i.e. alpha=4.793e-02, with an active set of 172 regressors, and the smallest cholesky pivot element being 9.306e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:45:25,101:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 225 iterations, i.e. alpha=2.867e-02, with an active set of 175 regressors, and the smallest cholesky pivot element being 9.306e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:45:25,103:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 226 iterations, i.e. alpha=2.388e-02, with an active set of 176 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:45:25,104:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 228 iterations, i.e. alpha=1.532e-02, with an active set of 178 regressors, and the smallest cholesky pivot element being 9.306e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:45:25,104:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 228 iterations, i.e. alpha=1.182e-02, with an active set of 178 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:45:25,105:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 229 iterations, i.e. alpha=3.367e-03, with an active set of 179 regressors, and the smallest cholesky pivot element being 9.306e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:45:25,105:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 229 iterations, i.e. alpha=2.670e-03, with an active set of 179 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:45:25,156:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:45:25,181:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), Lars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:45:25,212:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 203 iterations, i.e. alpha=2.664e-03, with an active set of 173 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:45:25,213:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 204 iterations, i.e. alpha=2.527e-03, with an active set of 174 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:45:25,214:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 206 iterations, i.e. alpha=8.528e-04, with an active set of 176 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:45:25,214:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 206 iterations, i.e. alpha=8.488e-04, with an active set of 176 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:45:25,215:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 208 iterations, i.e. alpha=3.478e-04, with an active set of 178 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:45:25,215:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 208 iterations, i.e. alpha=3.430e-04, with an active set of 178 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:45:25,230:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 217 iterations, i.e. alpha=4.662e-04, with an active set of 176 regressors, and the smallest cholesky pivot element being 9.125e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:45:25,231:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 218 iterations, i.e. alpha=1.574e-04, with an active set of 177 regressors, and the smallest cholesky pivot element being 9.125e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:45:25,231:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:649: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 219 iterations, i.e. alpha=2.045e-05, with an active set of 178 regressors, and the smallest cholesky pivot element being 9.125e-08. Reduce max_iter or increase eps parameters.
  warnings.warn(

2023-01-19 23:45:25,243:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-01-19 23:45:25,243:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py:446: RuntimeWarning: overflow encountered in square
  output_errors = np.average((y_true - y_pred) ** 2, axis=0, weights=sample_weight)

2023-01-19 23:45:25,244:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py:927: RuntimeWarning: overflow encountered in square
  numerator = (weight * (y_true - y_pred) ** 2).sum(axis=0, dtype=np.float64)

2023-01-19 23:45:25,248:INFO:Calculating mean and std
2023-01-19 23:45:25,249:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:236: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2023-01-19 23:45:25,249:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:233: RuntimeWarning: invalid value encountered in subtract
  x = asanyarray(arr - arrmean)

2023-01-19 23:45:25,250:INFO:Creating metrics dataframe
2023-01-19 23:45:25,253:INFO:Uploading results into container
2023-01-19 23:45:25,254:INFO:Uploading model into container now
2023-01-19 23:45:25,254:INFO:_master_model_container: 5
2023-01-19 23:45:25,254:INFO:_display_container: 2
2023-01-19 23:45:25,256:INFO:Lars(random_state=1611)
2023-01-19 23:45:25,257:INFO:create_model() successfully completed......................................
2023-01-19 23:45:25,386:INFO:SubProcess create_model() end ==================================
2023-01-19 23:45:25,386:INFO:Creating metrics dataframe
2023-01-19 23:45:25,401:INFO:Initializing Lasso Least Angle Regression
2023-01-19 23:45:25,401:INFO:Total runtime is 0.16967433691024777 minutes
2023-01-19 23:45:25,405:INFO:SubProcess create_model() called ==================================
2023-01-19 23:45:25,406:INFO:Initializing create_model()
2023-01-19 23:45:25,406:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc645499190>, estimator=llar, fold=KFold(n_splits=10, random_state=1611, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc6469a1d90>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:45:25,406:INFO:Checking exceptions
2023-01-19 23:45:25,406:INFO:Importing libraries
2023-01-19 23:45:25,406:INFO:Copying training dataset
2023-01-19 23:45:25,412:INFO:Defining folds
2023-01-19 23:45:25,412:INFO:Declaring metric variables
2023-01-19 23:45:25,417:INFO:Importing untrained model
2023-01-19 23:45:25,421:INFO:Lasso Least Angle Regression Imported successfully
2023-01-19 23:45:25,428:INFO:Starting cross validation
2023-01-19 23:45:25,430:INFO:Cross validating with KFold(n_splits=10, random_state=1611, shuffle=True), n_jobs=-1
2023-01-19 23:45:25,493:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-19 23:45:25,500:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-19 23:45:25,509:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-19 23:45:25,546:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-19 23:45:25,548:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-19 23:45:25,557:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-19 23:45:25,559:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-19 23:45:25,565:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-19 23:45:25,579:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-19 23:45:25,593:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), LassoLars())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)

Set parameter alpha to: original_alpha * np.sqrt(n_samples). 
  warnings.warn(

2023-01-19 23:45:25,613:INFO:Calculating mean and std
2023-01-19 23:45:25,615:INFO:Creating metrics dataframe
2023-01-19 23:45:25,618:INFO:Uploading results into container
2023-01-19 23:45:25,618:INFO:Uploading model into container now
2023-01-19 23:45:25,619:INFO:_master_model_container: 6
2023-01-19 23:45:25,619:INFO:_display_container: 2
2023-01-19 23:45:25,619:INFO:LassoLars(random_state=1611)
2023-01-19 23:45:25,619:INFO:create_model() successfully completed......................................
2023-01-19 23:45:25,751:INFO:SubProcess create_model() end ==================================
2023-01-19 23:45:25,751:INFO:Creating metrics dataframe
2023-01-19 23:45:25,766:INFO:Initializing Orthogonal Matching Pursuit
2023-01-19 23:45:25,767:INFO:Total runtime is 0.175761870543162 minutes
2023-01-19 23:45:25,771:INFO:SubProcess create_model() called ==================================
2023-01-19 23:45:25,771:INFO:Initializing create_model()
2023-01-19 23:45:25,771:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc645499190>, estimator=omp, fold=KFold(n_splits=10, random_state=1611, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc6469a1d90>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:45:25,771:INFO:Checking exceptions
2023-01-19 23:45:25,771:INFO:Importing libraries
2023-01-19 23:45:25,771:INFO:Copying training dataset
2023-01-19 23:45:25,777:INFO:Defining folds
2023-01-19 23:45:25,777:INFO:Declaring metric variables
2023-01-19 23:45:25,781:INFO:Importing untrained model
2023-01-19 23:45:25,785:INFO:Orthogonal Matching Pursuit Imported successfully
2023-01-19 23:45:25,793:INFO:Starting cross validation
2023-01-19 23:45:25,795:INFO:Cross validating with KFold(n_splits=10, random_state=1611, shuffle=True), n_jobs=-1
2023-01-19 23:45:25,849:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:45:25,855:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:45:25,870:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:45:25,883:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:45:25,897:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:45:25,914:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:45:25,920:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:45:25,928:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:45:25,938:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:45:25,950:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:45:25,975:INFO:Calculating mean and std
2023-01-19 23:45:25,976:INFO:Creating metrics dataframe
2023-01-19 23:45:25,980:INFO:Uploading results into container
2023-01-19 23:45:25,981:INFO:Uploading model into container now
2023-01-19 23:45:25,982:INFO:_master_model_container: 7
2023-01-19 23:45:25,982:INFO:_display_container: 2
2023-01-19 23:45:25,982:INFO:OrthogonalMatchingPursuit()
2023-01-19 23:45:25,983:INFO:create_model() successfully completed......................................
2023-01-19 23:45:26,112:INFO:SubProcess create_model() end ==================================
2023-01-19 23:45:26,112:INFO:Creating metrics dataframe
2023-01-19 23:45:26,126:INFO:Initializing Bayesian Ridge
2023-01-19 23:45:26,126:INFO:Total runtime is 0.18175791899363197 minutes
2023-01-19 23:45:26,131:INFO:SubProcess create_model() called ==================================
2023-01-19 23:45:26,131:INFO:Initializing create_model()
2023-01-19 23:45:26,132:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc645499190>, estimator=br, fold=KFold(n_splits=10, random_state=1611, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc6469a1d90>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:45:26,132:INFO:Checking exceptions
2023-01-19 23:45:26,132:INFO:Importing libraries
2023-01-19 23:45:26,132:INFO:Copying training dataset
2023-01-19 23:45:26,137:INFO:Defining folds
2023-01-19 23:45:26,137:INFO:Declaring metric variables
2023-01-19 23:45:26,142:INFO:Importing untrained model
2023-01-19 23:45:26,146:INFO:Bayesian Ridge Imported successfully
2023-01-19 23:45:26,154:INFO:Starting cross validation
2023-01-19 23:45:26,156:INFO:Cross validating with KFold(n_splits=10, random_state=1611, shuffle=True), n_jobs=-1
2023-01-19 23:45:26,418:INFO:Calculating mean and std
2023-01-19 23:45:26,421:INFO:Creating metrics dataframe
2023-01-19 23:45:26,424:INFO:Uploading results into container
2023-01-19 23:45:26,425:INFO:Uploading model into container now
2023-01-19 23:45:26,426:INFO:_master_model_container: 8
2023-01-19 23:45:26,426:INFO:_display_container: 2
2023-01-19 23:45:26,427:INFO:BayesianRidge()
2023-01-19 23:45:26,427:INFO:create_model() successfully completed......................................
2023-01-19 23:45:26,555:INFO:SubProcess create_model() end ==================================
2023-01-19 23:45:26,555:INFO:Creating metrics dataframe
2023-01-19 23:45:26,569:INFO:Initializing Passive Aggressive Regressor
2023-01-19 23:45:26,569:INFO:Total runtime is 0.18914003769556678 minutes
2023-01-19 23:45:26,573:INFO:SubProcess create_model() called ==================================
2023-01-19 23:45:26,574:INFO:Initializing create_model()
2023-01-19 23:45:26,574:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc645499190>, estimator=par, fold=KFold(n_splits=10, random_state=1611, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc6469a1d90>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:45:26,574:INFO:Checking exceptions
2023-01-19 23:45:26,574:INFO:Importing libraries
2023-01-19 23:45:26,574:INFO:Copying training dataset
2023-01-19 23:45:26,579:INFO:Defining folds
2023-01-19 23:45:26,580:INFO:Declaring metric variables
2023-01-19 23:45:26,584:INFO:Importing untrained model
2023-01-19 23:45:26,588:INFO:Passive Aggressive Regressor Imported successfully
2023-01-19 23:45:26,597:INFO:Starting cross validation
2023-01-19 23:45:26,634:INFO:Cross validating with KFold(n_splits=10, random_state=1611, shuffle=True), n_jobs=-1
2023-01-19 23:45:26,802:INFO:Calculating mean and std
2023-01-19 23:45:26,804:INFO:Creating metrics dataframe
2023-01-19 23:45:26,807:INFO:Uploading results into container
2023-01-19 23:45:26,808:INFO:Uploading model into container now
2023-01-19 23:45:26,808:INFO:_master_model_container: 9
2023-01-19 23:45:26,808:INFO:_display_container: 2
2023-01-19 23:45:26,809:INFO:PassiveAggressiveRegressor(random_state=1611)
2023-01-19 23:45:26,809:INFO:create_model() successfully completed......................................
2023-01-19 23:45:26,941:INFO:SubProcess create_model() end ==================================
2023-01-19 23:45:26,941:INFO:Creating metrics dataframe
2023-01-19 23:45:26,959:INFO:Initializing Huber Regressor
2023-01-19 23:45:26,959:INFO:Total runtime is 0.19563365379969275 minutes
2023-01-19 23:45:26,963:INFO:SubProcess create_model() called ==================================
2023-01-19 23:45:26,964:INFO:Initializing create_model()
2023-01-19 23:45:26,964:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc645499190>, estimator=huber, fold=KFold(n_splits=10, random_state=1611, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc6469a1d90>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:45:26,964:INFO:Checking exceptions
2023-01-19 23:45:26,964:INFO:Importing libraries
2023-01-19 23:45:26,964:INFO:Copying training dataset
2023-01-19 23:45:26,970:INFO:Defining folds
2023-01-19 23:45:26,970:INFO:Declaring metric variables
2023-01-19 23:45:26,974:INFO:Importing untrained model
2023-01-19 23:45:26,978:INFO:Huber Regressor Imported successfully
2023-01-19 23:45:26,985:INFO:Starting cross validation
2023-01-19 23:45:26,988:INFO:Cross validating with KFold(n_splits=10, random_state=1611, shuffle=True), n_jobs=-1
2023-01-19 23:45:27,280:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-19 23:45:27,294:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-19 23:45:27,297:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-19 23:45:27,314:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-19 23:45:27,322:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-19 23:45:27,333:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-19 23:45:27,334:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-19 23:45:27,358:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-19 23:45:27,435:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-19 23:45:27,447:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:335: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2023-01-19 23:45:27,462:INFO:Calculating mean and std
2023-01-19 23:45:27,463:INFO:Creating metrics dataframe
2023-01-19 23:45:27,466:INFO:Uploading results into container
2023-01-19 23:45:27,467:INFO:Uploading model into container now
2023-01-19 23:45:27,467:INFO:_master_model_container: 10
2023-01-19 23:45:27,468:INFO:_display_container: 2
2023-01-19 23:45:27,468:INFO:HuberRegressor()
2023-01-19 23:45:27,468:INFO:create_model() successfully completed......................................
2023-01-19 23:45:27,601:INFO:SubProcess create_model() end ==================================
2023-01-19 23:45:27,601:INFO:Creating metrics dataframe
2023-01-19 23:45:27,617:INFO:Initializing K Neighbors Regressor
2023-01-19 23:45:27,617:INFO:Total runtime is 0.20661148627599077 minutes
2023-01-19 23:45:27,621:INFO:SubProcess create_model() called ==================================
2023-01-19 23:45:27,622:INFO:Initializing create_model()
2023-01-19 23:45:27,622:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc645499190>, estimator=knn, fold=KFold(n_splits=10, random_state=1611, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc6469a1d90>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:45:27,622:INFO:Checking exceptions
2023-01-19 23:45:27,622:INFO:Importing libraries
2023-01-19 23:45:27,622:INFO:Copying training dataset
2023-01-19 23:45:27,628:INFO:Defining folds
2023-01-19 23:45:27,628:INFO:Declaring metric variables
2023-01-19 23:45:27,631:INFO:Importing untrained model
2023-01-19 23:45:27,635:INFO:K Neighbors Regressor Imported successfully
2023-01-19 23:45:27,642:INFO:Starting cross validation
2023-01-19 23:45:27,643:INFO:Cross validating with KFold(n_splits=10, random_state=1611, shuffle=True), n_jobs=-1
2023-01-19 23:45:28,081:INFO:Calculating mean and std
2023-01-19 23:45:28,082:INFO:Creating metrics dataframe
2023-01-19 23:45:28,086:INFO:Uploading results into container
2023-01-19 23:45:28,087:INFO:Uploading model into container now
2023-01-19 23:45:28,087:INFO:_master_model_container: 11
2023-01-19 23:45:28,087:INFO:_display_container: 2
2023-01-19 23:45:28,088:INFO:KNeighborsRegressor(n_jobs=-1)
2023-01-19 23:45:28,088:INFO:create_model() successfully completed......................................
2023-01-19 23:45:28,211:INFO:SubProcess create_model() end ==================================
2023-01-19 23:45:28,211:INFO:Creating metrics dataframe
2023-01-19 23:45:28,227:INFO:Initializing Decision Tree Regressor
2023-01-19 23:45:28,228:INFO:Total runtime is 0.2167824864387512 minutes
2023-01-19 23:45:28,233:INFO:SubProcess create_model() called ==================================
2023-01-19 23:45:28,233:INFO:Initializing create_model()
2023-01-19 23:45:28,233:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc645499190>, estimator=dt, fold=KFold(n_splits=10, random_state=1611, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc6469a1d90>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:45:28,233:INFO:Checking exceptions
2023-01-19 23:45:28,233:INFO:Importing libraries
2023-01-19 23:45:28,234:INFO:Copying training dataset
2023-01-19 23:45:28,239:INFO:Defining folds
2023-01-19 23:45:28,239:INFO:Declaring metric variables
2023-01-19 23:45:28,242:INFO:Importing untrained model
2023-01-19 23:45:28,246:INFO:Decision Tree Regressor Imported successfully
2023-01-19 23:45:28,253:INFO:Starting cross validation
2023-01-19 23:45:28,254:INFO:Cross validating with KFold(n_splits=10, random_state=1611, shuffle=True), n_jobs=-1
2023-01-19 23:45:28,473:INFO:Calculating mean and std
2023-01-19 23:45:28,475:INFO:Creating metrics dataframe
2023-01-19 23:45:28,479:INFO:Uploading results into container
2023-01-19 23:45:28,480:INFO:Uploading model into container now
2023-01-19 23:45:28,481:INFO:_master_model_container: 12
2023-01-19 23:45:28,481:INFO:_display_container: 2
2023-01-19 23:45:28,481:INFO:DecisionTreeRegressor(random_state=1611)
2023-01-19 23:45:28,481:INFO:create_model() successfully completed......................................
2023-01-19 23:45:28,612:INFO:SubProcess create_model() end ==================================
2023-01-19 23:45:28,612:INFO:Creating metrics dataframe
2023-01-19 23:45:28,628:INFO:Initializing Random Forest Regressor
2023-01-19 23:45:28,628:INFO:Total runtime is 0.2234605034192403 minutes
2023-01-19 23:45:28,632:INFO:SubProcess create_model() called ==================================
2023-01-19 23:45:28,633:INFO:Initializing create_model()
2023-01-19 23:45:28,633:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc645499190>, estimator=rf, fold=KFold(n_splits=10, random_state=1611, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc6469a1d90>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:45:28,633:INFO:Checking exceptions
2023-01-19 23:45:28,633:INFO:Importing libraries
2023-01-19 23:45:28,633:INFO:Copying training dataset
2023-01-19 23:45:28,639:INFO:Defining folds
2023-01-19 23:45:28,639:INFO:Declaring metric variables
2023-01-19 23:45:28,643:INFO:Importing untrained model
2023-01-19 23:45:28,648:INFO:Random Forest Regressor Imported successfully
2023-01-19 23:45:28,656:INFO:Starting cross validation
2023-01-19 23:45:28,657:INFO:Cross validating with KFold(n_splits=10, random_state=1611, shuffle=True), n_jobs=-1
2023-01-19 23:45:31,498:INFO:Calculating mean and std
2023-01-19 23:45:31,500:INFO:Creating metrics dataframe
2023-01-19 23:45:31,503:INFO:Uploading results into container
2023-01-19 23:45:31,504:INFO:Uploading model into container now
2023-01-19 23:45:31,504:INFO:_master_model_container: 13
2023-01-19 23:45:31,505:INFO:_display_container: 2
2023-01-19 23:45:31,505:INFO:RandomForestRegressor(n_jobs=-1, random_state=1611)
2023-01-19 23:45:31,505:INFO:create_model() successfully completed......................................
2023-01-19 23:45:31,645:INFO:SubProcess create_model() end ==================================
2023-01-19 23:45:31,645:INFO:Creating metrics dataframe
2023-01-19 23:45:31,661:INFO:Initializing Extra Trees Regressor
2023-01-19 23:45:31,662:INFO:Total runtime is 0.2740157524744669 minutes
2023-01-19 23:45:31,666:INFO:SubProcess create_model() called ==================================
2023-01-19 23:45:31,667:INFO:Initializing create_model()
2023-01-19 23:45:31,667:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc645499190>, estimator=et, fold=KFold(n_splits=10, random_state=1611, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc6469a1d90>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:45:31,667:INFO:Checking exceptions
2023-01-19 23:45:31,668:INFO:Importing libraries
2023-01-19 23:45:31,668:INFO:Copying training dataset
2023-01-19 23:45:31,673:INFO:Defining folds
2023-01-19 23:45:31,673:INFO:Declaring metric variables
2023-01-19 23:45:31,677:INFO:Importing untrained model
2023-01-19 23:45:31,682:INFO:Extra Trees Regressor Imported successfully
2023-01-19 23:45:31,689:INFO:Starting cross validation
2023-01-19 23:45:31,691:INFO:Cross validating with KFold(n_splits=10, random_state=1611, shuffle=True), n_jobs=-1
2023-01-19 23:45:35,041:INFO:Calculating mean and std
2023-01-19 23:45:35,042:INFO:Creating metrics dataframe
2023-01-19 23:45:35,047:INFO:Uploading results into container
2023-01-19 23:45:35,048:INFO:Uploading model into container now
2023-01-19 23:45:35,049:INFO:_master_model_container: 14
2023-01-19 23:45:35,049:INFO:_display_container: 2
2023-01-19 23:45:35,050:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=1611)
2023-01-19 23:45:35,050:INFO:create_model() successfully completed......................................
2023-01-19 23:45:35,192:INFO:SubProcess create_model() end ==================================
2023-01-19 23:45:35,192:INFO:Creating metrics dataframe
2023-01-19 23:45:35,208:INFO:Initializing AdaBoost Regressor
2023-01-19 23:45:35,208:INFO:Total runtime is 0.3331278045972188 minutes
2023-01-19 23:45:35,213:INFO:SubProcess create_model() called ==================================
2023-01-19 23:45:35,214:INFO:Initializing create_model()
2023-01-19 23:45:35,214:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc645499190>, estimator=ada, fold=KFold(n_splits=10, random_state=1611, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc6469a1d90>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:45:35,214:INFO:Checking exceptions
2023-01-19 23:45:35,214:INFO:Importing libraries
2023-01-19 23:45:35,214:INFO:Copying training dataset
2023-01-19 23:45:35,220:INFO:Defining folds
2023-01-19 23:45:35,220:INFO:Declaring metric variables
2023-01-19 23:45:35,224:INFO:Importing untrained model
2023-01-19 23:45:35,229:INFO:AdaBoost Regressor Imported successfully
2023-01-19 23:45:35,237:INFO:Starting cross validation
2023-01-19 23:45:35,240:INFO:Cross validating with KFold(n_splits=10, random_state=1611, shuffle=True), n_jobs=-1
2023-01-19 23:45:36,457:INFO:Calculating mean and std
2023-01-19 23:45:36,458:INFO:Creating metrics dataframe
2023-01-19 23:45:36,462:INFO:Uploading results into container
2023-01-19 23:45:36,463:INFO:Uploading model into container now
2023-01-19 23:45:36,464:INFO:_master_model_container: 15
2023-01-19 23:45:36,464:INFO:_display_container: 2
2023-01-19 23:45:36,464:INFO:AdaBoostRegressor(random_state=1611)
2023-01-19 23:45:36,464:INFO:create_model() successfully completed......................................
2023-01-19 23:45:36,656:INFO:SubProcess create_model() end ==================================
2023-01-19 23:45:36,656:INFO:Creating metrics dataframe
2023-01-19 23:45:36,673:INFO:Initializing Gradient Boosting Regressor
2023-01-19 23:45:36,674:INFO:Total runtime is 0.35754713614781697 minutes
2023-01-19 23:45:36,678:INFO:SubProcess create_model() called ==================================
2023-01-19 23:45:36,678:INFO:Initializing create_model()
2023-01-19 23:45:36,679:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc645499190>, estimator=gbr, fold=KFold(n_splits=10, random_state=1611, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc6469a1d90>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:45:36,679:INFO:Checking exceptions
2023-01-19 23:45:36,680:INFO:Importing libraries
2023-01-19 23:45:36,680:INFO:Copying training dataset
2023-01-19 23:45:36,685:INFO:Defining folds
2023-01-19 23:45:36,685:INFO:Declaring metric variables
2023-01-19 23:45:36,689:INFO:Importing untrained model
2023-01-19 23:45:36,693:INFO:Gradient Boosting Regressor Imported successfully
2023-01-19 23:45:36,700:INFO:Starting cross validation
2023-01-19 23:45:36,702:INFO:Cross validating with KFold(n_splits=10, random_state=1611, shuffle=True), n_jobs=-1
2023-01-19 23:45:38,042:INFO:Calculating mean and std
2023-01-19 23:45:38,044:INFO:Creating metrics dataframe
2023-01-19 23:45:38,048:INFO:Uploading results into container
2023-01-19 23:45:38,049:INFO:Uploading model into container now
2023-01-19 23:45:38,049:INFO:_master_model_container: 16
2023-01-19 23:45:38,049:INFO:_display_container: 2
2023-01-19 23:45:38,050:INFO:GradientBoostingRegressor(random_state=1611)
2023-01-19 23:45:38,050:INFO:create_model() successfully completed......................................
2023-01-19 23:45:38,189:INFO:SubProcess create_model() end ==================================
2023-01-19 23:45:38,189:INFO:Creating metrics dataframe
2023-01-19 23:45:38,207:INFO:Initializing Extreme Gradient Boosting
2023-01-19 23:45:38,207:INFO:Total runtime is 0.38310017188390094 minutes
2023-01-19 23:45:38,211:INFO:SubProcess create_model() called ==================================
2023-01-19 23:45:38,211:INFO:Initializing create_model()
2023-01-19 23:45:38,211:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc645499190>, estimator=xgboost, fold=KFold(n_splits=10, random_state=1611, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc6469a1d90>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:45:38,212:INFO:Checking exceptions
2023-01-19 23:45:38,212:INFO:Importing libraries
2023-01-19 23:45:38,212:INFO:Copying training dataset
2023-01-19 23:45:38,218:INFO:Defining folds
2023-01-19 23:45:38,218:INFO:Declaring metric variables
2023-01-19 23:45:38,221:INFO:Importing untrained model
2023-01-19 23:45:38,226:INFO:Extreme Gradient Boosting Imported successfully
2023-01-19 23:45:38,233:INFO:Starting cross validation
2023-01-19 23:45:38,235:INFO:Cross validating with KFold(n_splits=10, random_state=1611, shuffle=True), n_jobs=-1
2023-01-19 23:45:42,265:INFO:Calculating mean and std
2023-01-19 23:45:42,266:INFO:Creating metrics dataframe
2023-01-19 23:45:42,269:INFO:Uploading results into container
2023-01-19 23:45:42,270:INFO:Uploading model into container now
2023-01-19 23:45:42,271:INFO:_master_model_container: 17
2023-01-19 23:45:42,271:INFO:_display_container: 2
2023-01-19 23:45:42,272:INFO:XGBRegressor(base_score=None, booster='gbtree', callbacks=None,
             colsample_bylevel=None, colsample_bynode=None,
             colsample_bytree=None, early_stopping_rounds=None,
             enable_categorical=False, eval_metric=None, feature_types=None,
             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
             interaction_constraints=None, learning_rate=None, max_bin=None,
             max_cat_threshold=None, max_cat_to_onehot=None,
             max_delta_step=None, max_depth=None, max_leaves=None,
             min_child_weight=None, missing=nan, monotone_constraints=None,
             n_estimators=100, n_jobs=-1, num_parallel_tree=None,
             predictor=None, random_state=1611, ...)
2023-01-19 23:45:42,272:INFO:create_model() successfully completed......................................
2023-01-19 23:45:42,403:INFO:SubProcess create_model() end ==================================
2023-01-19 23:45:42,403:INFO:Creating metrics dataframe
2023-01-19 23:45:42,421:INFO:Initializing Light Gradient Boosting Machine
2023-01-19 23:45:42,421:INFO:Total runtime is 0.4533384561538696 minutes
2023-01-19 23:45:42,426:INFO:SubProcess create_model() called ==================================
2023-01-19 23:45:42,426:INFO:Initializing create_model()
2023-01-19 23:45:42,426:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc645499190>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=1611, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc6469a1d90>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:45:42,426:INFO:Checking exceptions
2023-01-19 23:45:42,426:INFO:Importing libraries
2023-01-19 23:45:42,426:INFO:Copying training dataset
2023-01-19 23:45:42,433:INFO:Defining folds
2023-01-19 23:45:42,433:INFO:Declaring metric variables
2023-01-19 23:45:42,437:INFO:Importing untrained model
2023-01-19 23:45:42,441:INFO:Light Gradient Boosting Machine Imported successfully
2023-01-19 23:45:42,448:INFO:Starting cross validation
2023-01-19 23:45:42,450:INFO:Cross validating with KFold(n_splits=10, random_state=1611, shuffle=True), n_jobs=-1
2023-01-19 23:45:45,903:INFO:Calculating mean and std
2023-01-19 23:45:45,955:INFO:Creating metrics dataframe
2023-01-19 23:45:45,993:INFO:Uploading results into container
2023-01-19 23:45:45,995:INFO:Uploading model into container now
2023-01-19 23:45:45,997:INFO:_master_model_container: 18
2023-01-19 23:45:45,997:INFO:_display_container: 2
2023-01-19 23:45:46,001:INFO:LGBMRegressor(random_state=1611)
2023-01-19 23:45:46,001:INFO:create_model() successfully completed......................................
2023-01-19 23:45:46,413:INFO:SubProcess create_model() end ==================================
2023-01-19 23:45:46,413:INFO:Creating metrics dataframe
2023-01-19 23:45:46,435:INFO:Initializing CatBoost Regressor
2023-01-19 23:45:46,435:INFO:Total runtime is 0.5202306350072224 minutes
2023-01-19 23:45:46,439:INFO:SubProcess create_model() called ==================================
2023-01-19 23:45:46,439:INFO:Initializing create_model()
2023-01-19 23:45:46,439:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc645499190>, estimator=catboost, fold=KFold(n_splits=10, random_state=1611, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc6469a1d90>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:45:46,439:INFO:Checking exceptions
2023-01-19 23:45:46,439:INFO:Importing libraries
2023-01-19 23:45:46,440:INFO:Copying training dataset
2023-01-19 23:45:46,446:INFO:Defining folds
2023-01-19 23:45:46,447:INFO:Declaring metric variables
2023-01-19 23:45:46,450:INFO:Importing untrained model
2023-01-19 23:45:46,458:INFO:CatBoost Regressor Imported successfully
2023-01-19 23:45:46,466:INFO:Starting cross validation
2023-01-19 23:45:46,468:INFO:Cross validating with KFold(n_splits=10, random_state=1611, shuffle=True), n_jobs=-1
2023-01-19 23:45:59,895:INFO:Calculating mean and std
2023-01-19 23:45:59,902:INFO:Creating metrics dataframe
2023-01-19 23:45:59,919:INFO:Uploading results into container
2023-01-19 23:45:59,919:INFO:Uploading model into container now
2023-01-19 23:45:59,920:INFO:_master_model_container: 19
2023-01-19 23:45:59,920:INFO:_display_container: 2
2023-01-19 23:45:59,920:INFO:<catboost.core.CatBoostRegressor object at 0x7fc6469a8f40>
2023-01-19 23:45:59,920:INFO:create_model() successfully completed......................................
2023-01-19 23:46:00,071:INFO:SubProcess create_model() end ==================================
2023-01-19 23:46:00,071:INFO:Creating metrics dataframe
2023-01-19 23:46:00,098:INFO:Initializing Dummy Regressor
2023-01-19 23:46:00,098:INFO:Total runtime is 0.7479559183120728 minutes
2023-01-19 23:46:00,102:INFO:SubProcess create_model() called ==================================
2023-01-19 23:46:00,103:INFO:Initializing create_model()
2023-01-19 23:46:00,103:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc645499190>, estimator=dummy, fold=KFold(n_splits=10, random_state=1611, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc6469a1d90>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:46:00,103:INFO:Checking exceptions
2023-01-19 23:46:00,103:INFO:Importing libraries
2023-01-19 23:46:00,103:INFO:Copying training dataset
2023-01-19 23:46:00,118:INFO:Defining folds
2023-01-19 23:46:00,119:INFO:Declaring metric variables
2023-01-19 23:46:00,128:INFO:Importing untrained model
2023-01-19 23:46:00,133:INFO:Dummy Regressor Imported successfully
2023-01-19 23:46:00,142:INFO:Starting cross validation
2023-01-19 23:46:00,144:INFO:Cross validating with KFold(n_splits=10, random_state=1611, shuffle=True), n_jobs=-1
2023-01-19 23:46:00,527:INFO:Calculating mean and std
2023-01-19 23:46:00,528:INFO:Creating metrics dataframe
2023-01-19 23:46:00,539:INFO:Uploading results into container
2023-01-19 23:46:00,540:INFO:Uploading model into container now
2023-01-19 23:46:00,541:INFO:_master_model_container: 20
2023-01-19 23:46:00,541:INFO:_display_container: 2
2023-01-19 23:46:00,541:INFO:DummyRegressor()
2023-01-19 23:46:00,541:INFO:create_model() successfully completed......................................
2023-01-19 23:46:00,692:INFO:SubProcess create_model() end ==================================
2023-01-19 23:46:00,692:INFO:Creating metrics dataframe
2023-01-19 23:46:00,729:INFO:Initializing create_model()
2023-01-19 23:46:00,730:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc645499190>, estimator=<catboost.core.CatBoostRegressor object at 0x7fc6469a8f40>, fold=KFold(n_splits=10, random_state=1611, shuffle=True), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:46:00,730:INFO:Checking exceptions
2023-01-19 23:46:00,753:INFO:Importing libraries
2023-01-19 23:46:00,753:INFO:Copying training dataset
2023-01-19 23:46:00,765:INFO:Defining folds
2023-01-19 23:46:00,765:INFO:Declaring metric variables
2023-01-19 23:46:00,765:INFO:Importing untrained model
2023-01-19 23:46:00,766:INFO:Declaring custom model
2023-01-19 23:46:00,774:INFO:CatBoost Regressor Imported successfully
2023-01-19 23:46:00,776:INFO:Cross validation set to False
2023-01-19 23:46:00,776:INFO:Fitting Model
2023-01-19 23:46:03,555:INFO:<catboost.core.CatBoostRegressor object at 0x7fc646da6220>
2023-01-19 23:46:03,555:INFO:create_model() successfully completed......................................
2023-01-19 23:46:03,734:INFO:_master_model_container: 20
2023-01-19 23:46:03,734:INFO:_display_container: 2
2023-01-19 23:46:03,734:INFO:<catboost.core.CatBoostRegressor object at 0x7fc646da6220>
2023-01-19 23:46:03,734:INFO:compare_models() successfully completed......................................
2023-01-19 23:47:51,290:INFO:Initializing create_model()
2023-01-19 23:47:51,291:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc645499190>, estimator=omp, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:47:51,291:INFO:Checking exceptions
2023-01-19 23:47:51,427:INFO:Importing libraries
2023-01-19 23:47:51,428:INFO:Copying training dataset
2023-01-19 23:47:51,441:INFO:Defining folds
2023-01-19 23:47:51,441:INFO:Declaring metric variables
2023-01-19 23:47:51,454:INFO:Importing untrained model
2023-01-19 23:47:51,464:INFO:Orthogonal Matching Pursuit Imported successfully
2023-01-19 23:47:51,484:INFO:Starting cross validation
2023-01-19 23:47:51,491:INFO:Cross validating with KFold(n_splits=10, random_state=1611, shuffle=True), n_jobs=-1
2023-01-19 23:47:51,832:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:47:51,823:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:47:51,845:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:47:51,878:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:47:51,877:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:47:51,930:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:47:51,946:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:47:51,968:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:47:52,069:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:47:52,111:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:47:52,189:INFO:Calculating mean and std
2023-01-19 23:47:52,191:INFO:Creating metrics dataframe
2023-01-19 23:47:52,202:INFO:Finalizing model
2023-01-19 23:47:52,241:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:47:52,279:INFO:Uploading results into container
2023-01-19 23:47:52,280:INFO:Uploading model into container now
2023-01-19 23:47:52,298:INFO:_master_model_container: 21
2023-01-19 23:47:52,298:INFO:_display_container: 3
2023-01-19 23:47:52,298:INFO:OrthogonalMatchingPursuit()
2023-01-19 23:47:52,298:INFO:create_model() successfully completed......................................
2023-01-19 23:47:52,771:INFO:Initializing tune_model()
2023-01-19 23:47:52,772:INFO:tune_model(estimator=OrthogonalMatchingPursuit(), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc645499190>)
2023-01-19 23:47:52,772:INFO:Checking exceptions
2023-01-19 23:47:52,834:INFO:Copying training dataset
2023-01-19 23:47:52,842:INFO:Checking base model
2023-01-19 23:47:52,843:INFO:Base model : Orthogonal Matching Pursuit
2023-01-19 23:47:52,846:INFO:Declaring metric variables
2023-01-19 23:47:52,852:INFO:Defining Hyperparameters
2023-01-19 23:47:53,063:INFO:Tuning with n_jobs=-1
2023-01-19 23:47:53,063:INFO:Initializing RandomizedSearchCV
2023-01-19 23:47:53,375:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:757: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2023-01-19 23:47:54,530:INFO:best_params: {'actual_estimator__normalize': False, 'actual_estimator__n_nonzero_coefs': 56, 'actual_estimator__fit_intercept': False}
2023-01-19 23:47:54,532:INFO:Hyperparameter search completed
2023-01-19 23:47:54,532:INFO:SubProcess create_model() called ==================================
2023-01-19 23:47:54,532:INFO:Initializing create_model()
2023-01-19 23:47:54,532:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc645499190>, estimator=OrthogonalMatchingPursuit(), fold=KFold(n_splits=10, random_state=1611, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc65ab599a0>, model_only=True, return_train_score=False, kwargs={'normalize': False, 'n_nonzero_coefs': 56, 'fit_intercept': False})
2023-01-19 23:47:54,532:INFO:Checking exceptions
2023-01-19 23:47:54,533:INFO:Importing libraries
2023-01-19 23:47:54,533:INFO:Copying training dataset
2023-01-19 23:47:54,537:INFO:Defining folds
2023-01-19 23:47:54,538:INFO:Declaring metric variables
2023-01-19 23:47:54,541:INFO:Importing untrained model
2023-01-19 23:47:54,541:INFO:Declaring custom model
2023-01-19 23:47:54,546:INFO:Orthogonal Matching Pursuit Imported successfully
2023-01-19 23:47:54,553:INFO:Starting cross validation
2023-01-19 23:47:54,555:INFO:Cross validating with KFold(n_splits=10, random_state=1611, shuffle=True), n_jobs=-1
2023-01-19 23:47:54,717:INFO:Calculating mean and std
2023-01-19 23:47:54,718:INFO:Creating metrics dataframe
2023-01-19 23:47:54,723:INFO:Finalizing model
2023-01-19 23:47:54,755:INFO:Uploading results into container
2023-01-19 23:47:54,756:INFO:Uploading model into container now
2023-01-19 23:47:54,757:INFO:_master_model_container: 22
2023-01-19 23:47:54,757:INFO:_display_container: 4
2023-01-19 23:47:54,758:INFO:OrthogonalMatchingPursuit(fit_intercept=False, n_nonzero_coefs=56,
                          normalize=False)
2023-01-19 23:47:54,758:INFO:create_model() successfully completed......................................
2023-01-19 23:47:54,879:INFO:SubProcess create_model() end ==================================
2023-01-19 23:47:54,879:INFO:choose_better activated
2023-01-19 23:47:54,882:INFO:SubProcess create_model() called ==================================
2023-01-19 23:47:54,883:INFO:Initializing create_model()
2023-01-19 23:47:54,883:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc645499190>, estimator=OrthogonalMatchingPursuit(), fold=KFold(n_splits=10, random_state=1611, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:47:54,883:INFO:Checking exceptions
2023-01-19 23:47:54,885:INFO:Importing libraries
2023-01-19 23:47:54,885:INFO:Copying training dataset
2023-01-19 23:47:54,889:INFO:Defining folds
2023-01-19 23:47:54,889:INFO:Declaring metric variables
2023-01-19 23:47:54,889:INFO:Importing untrained model
2023-01-19 23:47:54,889:INFO:Declaring custom model
2023-01-19 23:47:54,889:INFO:Orthogonal Matching Pursuit Imported successfully
2023-01-19 23:47:54,889:INFO:Starting cross validation
2023-01-19 23:47:54,891:INFO:Cross validating with KFold(n_splits=10, random_state=1611, shuffle=True), n_jobs=-1
2023-01-19 23:47:54,935:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:47:54,941:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:47:54,951:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:47:54,961:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:47:54,967:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:47:54,985:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:47:54,995:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:47:55,008:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:47:55,017:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:47:55,024:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:47:55,048:INFO:Calculating mean and std
2023-01-19 23:47:55,048:INFO:Creating metrics dataframe
2023-01-19 23:47:55,050:INFO:Finalizing model
2023-01-19 23:47:55,070:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:47:55,077:INFO:Uploading results into container
2023-01-19 23:47:55,077:INFO:Uploading model into container now
2023-01-19 23:47:55,078:INFO:_master_model_container: 23
2023-01-19 23:47:55,078:INFO:_display_container: 5
2023-01-19 23:47:55,078:INFO:OrthogonalMatchingPursuit()
2023-01-19 23:47:55,078:INFO:create_model() successfully completed......................................
2023-01-19 23:47:55,194:INFO:SubProcess create_model() end ==================================
2023-01-19 23:47:55,194:INFO:OrthogonalMatchingPursuit() result for R2 is 0.874
2023-01-19 23:47:55,195:INFO:OrthogonalMatchingPursuit(fit_intercept=False, n_nonzero_coefs=56,
                          normalize=False) result for R2 is 0.8816
2023-01-19 23:47:55,195:INFO:OrthogonalMatchingPursuit(fit_intercept=False, n_nonzero_coefs=56,
                          normalize=False) is best model
2023-01-19 23:47:55,195:INFO:choose_better completed
2023-01-19 23:47:55,204:INFO:_master_model_container: 23
2023-01-19 23:47:55,205:INFO:_display_container: 4
2023-01-19 23:47:55,205:INFO:OrthogonalMatchingPursuit(fit_intercept=False, n_nonzero_coefs=56,
                          normalize=False)
2023-01-19 23:47:55,205:INFO:tune_model() successfully completed......................................
2023-01-19 23:48:04,593:INFO:Initializing create_model()
2023-01-19 23:48:04,594:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc645499190>, estimator=omp, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:48:04,594:INFO:Checking exceptions
2023-01-19 23:48:04,641:INFO:Importing libraries
2023-01-19 23:48:04,642:INFO:Copying training dataset
2023-01-19 23:48:04,647:INFO:Defining folds
2023-01-19 23:48:04,647:INFO:Declaring metric variables
2023-01-19 23:48:04,652:INFO:Importing untrained model
2023-01-19 23:48:04,656:INFO:Orthogonal Matching Pursuit Imported successfully
2023-01-19 23:48:04,663:INFO:Starting cross validation
2023-01-19 23:48:04,665:INFO:Cross validating with KFold(n_splits=10, random_state=1611, shuffle=True), n_jobs=-1
2023-01-19 23:48:04,714:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:48:04,723:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:48:04,732:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:48:04,744:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:48:04,774:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:48:04,797:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:48:04,804:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:48:04,809:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:48:04,821:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:48:04,826:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:48:04,877:INFO:Calculating mean and std
2023-01-19 23:48:04,877:INFO:Creating metrics dataframe
2023-01-19 23:48:04,885:INFO:Finalizing model
2023-01-19 23:48:04,912:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:48:04,927:INFO:Uploading results into container
2023-01-19 23:48:04,928:INFO:Uploading model into container now
2023-01-19 23:48:04,942:INFO:_master_model_container: 24
2023-01-19 23:48:04,942:INFO:_display_container: 5
2023-01-19 23:48:04,943:INFO:OrthogonalMatchingPursuit()
2023-01-19 23:48:04,943:INFO:create_model() successfully completed......................................
2023-01-19 23:48:05,154:INFO:Initializing tune_model()
2023-01-19 23:48:05,154:INFO:tune_model(estimator=OrthogonalMatchingPursuit(), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc645499190>)
2023-01-19 23:48:05,154:INFO:Checking exceptions
2023-01-19 23:48:05,183:INFO:Copying training dataset
2023-01-19 23:48:05,188:INFO:Checking base model
2023-01-19 23:48:05,189:INFO:Base model : Orthogonal Matching Pursuit
2023-01-19 23:48:05,192:INFO:Declaring metric variables
2023-01-19 23:48:05,197:INFO:Defining Hyperparameters
2023-01-19 23:48:05,341:INFO:Tuning with n_jobs=-1
2023-01-19 23:48:05,341:INFO:Initializing RandomizedSearchCV
2023-01-19 23:48:05,541:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:757: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2023-01-19 23:48:06,577:INFO:best_params: {'actual_estimator__normalize': False, 'actual_estimator__n_nonzero_coefs': 56, 'actual_estimator__fit_intercept': False}
2023-01-19 23:48:06,578:INFO:Hyperparameter search completed
2023-01-19 23:48:06,578:INFO:SubProcess create_model() called ==================================
2023-01-19 23:48:06,578:INFO:Initializing create_model()
2023-01-19 23:48:06,578:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc645499190>, estimator=OrthogonalMatchingPursuit(), fold=KFold(n_splits=10, random_state=1611, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc64443efd0>, model_only=True, return_train_score=False, kwargs={'normalize': False, 'n_nonzero_coefs': 56, 'fit_intercept': False})
2023-01-19 23:48:06,578:INFO:Checking exceptions
2023-01-19 23:48:06,579:INFO:Importing libraries
2023-01-19 23:48:06,579:INFO:Copying training dataset
2023-01-19 23:48:06,583:INFO:Defining folds
2023-01-19 23:48:06,583:INFO:Declaring metric variables
2023-01-19 23:48:06,586:INFO:Importing untrained model
2023-01-19 23:48:06,586:INFO:Declaring custom model
2023-01-19 23:48:06,589:INFO:Orthogonal Matching Pursuit Imported successfully
2023-01-19 23:48:06,596:INFO:Starting cross validation
2023-01-19 23:48:06,597:INFO:Cross validating with KFold(n_splits=10, random_state=1611, shuffle=True), n_jobs=-1
2023-01-19 23:48:06,770:INFO:Calculating mean and std
2023-01-19 23:48:06,771:INFO:Creating metrics dataframe
2023-01-19 23:48:06,776:INFO:Finalizing model
2023-01-19 23:48:06,807:INFO:Uploading results into container
2023-01-19 23:48:06,808:INFO:Uploading model into container now
2023-01-19 23:48:06,809:INFO:_master_model_container: 25
2023-01-19 23:48:06,809:INFO:_display_container: 6
2023-01-19 23:48:06,810:INFO:OrthogonalMatchingPursuit(fit_intercept=False, n_nonzero_coefs=56,
                          normalize=False)
2023-01-19 23:48:06,810:INFO:create_model() successfully completed......................................
2023-01-19 23:48:06,932:INFO:SubProcess create_model() end ==================================
2023-01-19 23:48:06,932:INFO:choose_better activated
2023-01-19 23:48:06,936:INFO:SubProcess create_model() called ==================================
2023-01-19 23:48:06,937:INFO:Initializing create_model()
2023-01-19 23:48:06,937:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc645499190>, estimator=OrthogonalMatchingPursuit(), fold=KFold(n_splits=10, random_state=1611, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:48:06,937:INFO:Checking exceptions
2023-01-19 23:48:06,938:INFO:Importing libraries
2023-01-19 23:48:06,939:INFO:Copying training dataset
2023-01-19 23:48:06,942:INFO:Defining folds
2023-01-19 23:48:06,942:INFO:Declaring metric variables
2023-01-19 23:48:06,942:INFO:Importing untrained model
2023-01-19 23:48:06,942:INFO:Declaring custom model
2023-01-19 23:48:06,943:INFO:Orthogonal Matching Pursuit Imported successfully
2023-01-19 23:48:06,943:INFO:Starting cross validation
2023-01-19 23:48:06,944:INFO:Cross validating with KFold(n_splits=10, random_state=1611, shuffle=True), n_jobs=-1
2023-01-19 23:48:06,990:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:48:07,000:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:48:07,009:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:48:07,023:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:48:07,028:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:48:07,041:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:48:07,052:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:48:07,064:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:48:07,075:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:48:07,084:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:48:07,108:INFO:Calculating mean and std
2023-01-19 23:48:07,133:INFO:Creating metrics dataframe
2023-01-19 23:48:07,139:INFO:Finalizing model
2023-01-19 23:48:07,165:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-19 23:48:07,173:INFO:Uploading results into container
2023-01-19 23:48:07,173:INFO:Uploading model into container now
2023-01-19 23:48:07,174:INFO:_master_model_container: 26
2023-01-19 23:48:07,174:INFO:_display_container: 7
2023-01-19 23:48:07,174:INFO:OrthogonalMatchingPursuit()
2023-01-19 23:48:07,174:INFO:create_model() successfully completed......................................
2023-01-19 23:48:07,301:INFO:SubProcess create_model() end ==================================
2023-01-19 23:48:07,301:INFO:OrthogonalMatchingPursuit() result for R2 is 0.874
2023-01-19 23:48:07,302:INFO:OrthogonalMatchingPursuit(fit_intercept=False, n_nonzero_coefs=56,
                          normalize=False) result for R2 is 0.8816
2023-01-19 23:48:07,302:INFO:OrthogonalMatchingPursuit(fit_intercept=False, n_nonzero_coefs=56,
                          normalize=False) is best model
2023-01-19 23:48:07,302:INFO:choose_better completed
2023-01-19 23:48:07,311:INFO:_master_model_container: 26
2023-01-19 23:48:07,311:INFO:_display_container: 6
2023-01-19 23:48:07,312:INFO:OrthogonalMatchingPursuit(fit_intercept=False, n_nonzero_coefs=56,
                          normalize=False)
2023-01-19 23:48:07,312:INFO:tune_model() successfully completed......................................
2023-01-19 23:49:01,329:INFO:Initializing blend_models()
2023-01-19 23:49:01,331:INFO:blend_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc645499190>, estimator_list=[<catboost.core.CatBoostRegressor object at 0x7fc6469a1880>, BayesianRidge(), OrthogonalMatchingPursuit(fit_intercept=False, n_nonzero_coefs=56,
                          normalize=False)], fold=None, round=4, choose_better=False, optimize=R2, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-01-19 23:49:01,332:INFO:Checking exceptions
2023-01-19 23:49:01,405:INFO:Importing libraries
2023-01-19 23:49:01,406:INFO:Copying training dataset
2023-01-19 23:49:01,425:INFO:Getting model names
2023-01-19 23:49:01,430:INFO:SubProcess create_model() called ==================================
2023-01-19 23:49:01,432:INFO:Initializing create_model()
2023-01-19 23:49:01,432:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc645499190>, estimator=VotingRegressor(estimators=[('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x7fc6469a1880>),
                            ('Bayesian Ridge', BayesianRidge()),
                            ('Orthogonal Matching Pursuit',
                             OrthogonalMatchingPursuit(fit_intercept=False,
                                                       n_nonzero_coefs=56,
                                                       normalize=False))],
                n_jobs=-1), fold=KFold(n_splits=10, random_state=1611, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc6469b0670>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:49:01,432:INFO:Checking exceptions
2023-01-19 23:49:01,432:INFO:Importing libraries
2023-01-19 23:49:01,432:INFO:Copying training dataset
2023-01-19 23:49:01,441:INFO:Defining folds
2023-01-19 23:49:01,441:INFO:Declaring metric variables
2023-01-19 23:49:01,446:INFO:Importing untrained model
2023-01-19 23:49:01,446:INFO:Declaring custom model
2023-01-19 23:49:01,454:INFO:Voting Regressor Imported successfully
2023-01-19 23:49:01,467:INFO:Starting cross validation
2023-01-19 23:49:01,470:INFO:Cross validating with KFold(n_splits=10, random_state=1611, shuffle=True), n_jobs=-1
2023-01-19 23:49:13,871:INFO:Calculating mean and std
2023-01-19 23:49:13,873:INFO:Creating metrics dataframe
2023-01-19 23:49:13,879:INFO:Finalizing model
2023-01-19 23:49:16,324:INFO:Uploading results into container
2023-01-19 23:49:16,325:INFO:Uploading model into container now
2023-01-19 23:49:16,327:INFO:_master_model_container: 27
2023-01-19 23:49:16,327:INFO:_display_container: 7
2023-01-19 23:49:16,330:INFO:VotingRegressor(estimators=[('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x7fc646d8b670>),
                            ('Bayesian Ridge', BayesianRidge()),
                            ('Orthogonal Matching Pursuit',
                             OrthogonalMatchingPursuit(fit_intercept=False,
                                                       n_nonzero_coefs=56,
                                                       normalize=False))],
                n_jobs=-1)
2023-01-19 23:49:16,330:INFO:create_model() successfully completed......................................
2023-01-19 23:49:16,476:INFO:SubProcess create_model() end ==================================
2023-01-19 23:49:16,488:INFO:_master_model_container: 27
2023-01-19 23:49:16,489:INFO:_display_container: 7
2023-01-19 23:49:16,491:INFO:VotingRegressor(estimators=[('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x7fc646d8b670>),
                            ('Bayesian Ridge', BayesianRidge()),
                            ('Orthogonal Matching Pursuit',
                             OrthogonalMatchingPursuit(fit_intercept=False,
                                                       n_nonzero_coefs=56,
                                                       normalize=False))],
                n_jobs=-1)
2023-01-19 23:49:16,491:INFO:blend_models() successfully completed......................................
2023-01-19 23:49:25,747:INFO:Initializing blend_models()
2023-01-19 23:49:25,747:INFO:blend_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc645499190>, estimator_list=[<catboost.core.CatBoostRegressor object at 0x7fc6469a1880>, BayesianRidge()], fold=None, round=4, choose_better=False, optimize=R2, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-01-19 23:49:25,747:INFO:Checking exceptions
2023-01-19 23:49:25,773:INFO:Importing libraries
2023-01-19 23:49:25,774:INFO:Copying training dataset
2023-01-19 23:49:25,780:INFO:Getting model names
2023-01-19 23:49:25,785:INFO:SubProcess create_model() called ==================================
2023-01-19 23:49:25,786:INFO:Initializing create_model()
2023-01-19 23:49:25,787:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc645499190>, estimator=VotingRegressor(estimators=[('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x7fc6469a1880>),
                            ('Bayesian Ridge', BayesianRidge())],
                n_jobs=-1), fold=KFold(n_splits=10, random_state=1611, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc644539ac0>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:49:25,787:INFO:Checking exceptions
2023-01-19 23:49:25,787:INFO:Importing libraries
2023-01-19 23:49:25,787:INFO:Copying training dataset
2023-01-19 23:49:25,795:INFO:Defining folds
2023-01-19 23:49:25,796:INFO:Declaring metric variables
2023-01-19 23:49:25,800:INFO:Importing untrained model
2023-01-19 23:49:25,800:INFO:Declaring custom model
2023-01-19 23:49:25,804:INFO:Voting Regressor Imported successfully
2023-01-19 23:49:25,815:INFO:Starting cross validation
2023-01-19 23:49:25,817:INFO:Cross validating with KFold(n_splits=10, random_state=1611, shuffle=True), n_jobs=-1
2023-01-19 23:49:41,349:INFO:Calculating mean and std
2023-01-19 23:49:41,366:INFO:Creating metrics dataframe
2023-01-19 23:49:41,399:INFO:Finalizing model
2023-01-19 23:49:43,545:INFO:Uploading results into container
2023-01-19 23:49:43,548:INFO:Uploading model into container now
2023-01-19 23:49:43,551:INFO:_master_model_container: 28
2023-01-19 23:49:43,551:INFO:_display_container: 8
2023-01-19 23:49:43,553:INFO:VotingRegressor(estimators=[('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x7fc646d88910>),
                            ('Bayesian Ridge', BayesianRidge())],
                n_jobs=-1)
2023-01-19 23:49:43,554:INFO:create_model() successfully completed......................................
2023-01-19 23:49:43,755:INFO:SubProcess create_model() end ==================================
2023-01-19 23:49:43,767:INFO:_master_model_container: 28
2023-01-19 23:49:43,768:INFO:_display_container: 8
2023-01-19 23:49:43,769:INFO:VotingRegressor(estimators=[('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x7fc646d88910>),
                            ('Bayesian Ridge', BayesianRidge())],
                n_jobs=-1)
2023-01-19 23:49:43,769:INFO:blend_models() successfully completed......................................
2023-01-19 23:49:48,744:INFO:Initializing blend_models()
2023-01-19 23:49:48,744:INFO:blend_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc645499190>, estimator_list=[<catboost.core.CatBoostRegressor object at 0x7fc6469a1880>], fold=None, round=4, choose_better=False, optimize=R2, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-01-19 23:49:48,745:INFO:Checking exceptions
2023-01-19 23:49:48,803:INFO:Importing libraries
2023-01-19 23:49:48,803:INFO:Copying training dataset
2023-01-19 23:49:48,809:INFO:Getting model names
2023-01-19 23:49:48,815:INFO:SubProcess create_model() called ==================================
2023-01-19 23:49:48,815:INFO:Initializing create_model()
2023-01-19 23:49:48,816:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc645499190>, estimator=VotingRegressor(estimators=[('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x7fc6469a1880>)],
                n_jobs=-1), fold=KFold(n_splits=10, random_state=1611, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc644b5b7c0>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:49:48,816:INFO:Checking exceptions
2023-01-19 23:49:48,816:INFO:Importing libraries
2023-01-19 23:49:48,816:INFO:Copying training dataset
2023-01-19 23:49:48,825:INFO:Defining folds
2023-01-19 23:49:48,825:INFO:Declaring metric variables
2023-01-19 23:49:48,832:INFO:Importing untrained model
2023-01-19 23:49:48,832:INFO:Declaring custom model
2023-01-19 23:49:48,838:INFO:Voting Regressor Imported successfully
2023-01-19 23:49:48,848:INFO:Starting cross validation
2023-01-19 23:49:48,852:INFO:Cross validating with KFold(n_splits=10, random_state=1611, shuffle=True), n_jobs=-1
2023-01-19 23:50:01,842:INFO:Calculating mean and std
2023-01-19 23:50:01,844:INFO:Creating metrics dataframe
2023-01-19 23:50:01,849:INFO:Finalizing model
2023-01-19 23:50:04,146:INFO:Uploading results into container
2023-01-19 23:50:04,147:INFO:Uploading model into container now
2023-01-19 23:50:04,148:INFO:_master_model_container: 29
2023-01-19 23:50:04,148:INFO:_display_container: 9
2023-01-19 23:50:04,149:INFO:VotingRegressor(estimators=[('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x7fc646a23160>)],
                n_jobs=-1)
2023-01-19 23:50:04,149:INFO:create_model() successfully completed......................................
2023-01-19 23:50:04,298:INFO:SubProcess create_model() end ==================================
2023-01-19 23:50:04,312:INFO:_master_model_container: 29
2023-01-19 23:50:04,312:INFO:_display_container: 9
2023-01-19 23:50:04,313:INFO:VotingRegressor(estimators=[('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x7fc646a23160>)],
                n_jobs=-1)
2023-01-19 23:50:04,313:INFO:blend_models() successfully completed......................................
2023-01-19 23:50:12,624:INFO:Initializing blend_models()
2023-01-19 23:50:12,624:INFO:blend_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc645499190>, estimator_list=[<catboost.core.CatBoostRegressor object at 0x7fc6469a1880>, BayesianRidge()], fold=None, round=4, choose_better=False, optimize=R2, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-01-19 23:50:12,625:INFO:Checking exceptions
2023-01-19 23:50:12,680:INFO:Importing libraries
2023-01-19 23:50:12,680:INFO:Copying training dataset
2023-01-19 23:50:12,700:INFO:Getting model names
2023-01-19 23:50:12,706:INFO:SubProcess create_model() called ==================================
2023-01-19 23:50:12,708:INFO:Initializing create_model()
2023-01-19 23:50:12,708:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc645499190>, estimator=VotingRegressor(estimators=[('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x7fc6469a1880>),
                            ('Bayesian Ridge', BayesianRidge())],
                n_jobs=-1), fold=KFold(n_splits=10, random_state=1611, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc644b5b5e0>, model_only=True, return_train_score=False, kwargs={})
2023-01-19 23:50:12,709:INFO:Checking exceptions
2023-01-19 23:50:12,709:INFO:Importing libraries
2023-01-19 23:50:12,709:INFO:Copying training dataset
2023-01-19 23:50:12,740:INFO:Defining folds
2023-01-19 23:50:12,740:INFO:Declaring metric variables
2023-01-19 23:50:12,757:INFO:Importing untrained model
2023-01-19 23:50:12,757:INFO:Declaring custom model
2023-01-19 23:50:12,769:INFO:Voting Regressor Imported successfully
2023-01-19 23:50:12,780:INFO:Starting cross validation
2023-01-19 23:50:12,782:INFO:Cross validating with KFold(n_splits=10, random_state=1611, shuffle=True), n_jobs=-1
2023-01-19 23:50:26,205:INFO:Calculating mean and std
2023-01-19 23:50:26,207:INFO:Creating metrics dataframe
2023-01-19 23:50:26,214:INFO:Finalizing model
2023-01-19 23:50:28,846:INFO:Uploading results into container
2023-01-19 23:50:28,847:INFO:Uploading model into container now
2023-01-19 23:50:28,849:INFO:_master_model_container: 30
2023-01-19 23:50:28,850:INFO:_display_container: 10
2023-01-19 23:50:28,852:INFO:VotingRegressor(estimators=[('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x7fc646cda160>),
                            ('Bayesian Ridge', BayesianRidge())],
                n_jobs=-1)
2023-01-19 23:50:28,853:INFO:create_model() successfully completed......................................
2023-01-19 23:50:29,011:INFO:SubProcess create_model() end ==================================
2023-01-19 23:50:29,026:INFO:_master_model_container: 30
2023-01-19 23:50:29,026:INFO:_display_container: 10
2023-01-19 23:50:29,027:INFO:VotingRegressor(estimators=[('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x7fc646cda160>),
                            ('Bayesian Ridge', BayesianRidge())],
                n_jobs=-1)
2023-01-19 23:50:29,028:INFO:blend_models() successfully completed......................................
2023-01-19 23:50:54,389:INFO:Initializing tune_model()
2023-01-19 23:50:54,390:INFO:tune_model(estimator=VotingRegressor(estimators=[('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x7fc646cda160>),
                            ('Bayesian Ridge', BayesianRidge())],
                n_jobs=-1), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc645499190>)
2023-01-19 23:50:54,390:INFO:Checking exceptions
2023-01-19 23:50:54,465:INFO:Copying training dataset
2023-01-19 23:50:54,472:INFO:Checking base model
2023-01-19 23:50:54,476:INFO:Base model : Voting Regressor
2023-01-19 23:50:54,476:INFO:Model has a special tunable class, using that
2023-01-19 23:50:54,487:INFO:Declaring metric variables
2023-01-19 23:50:54,491:INFO:Defining Hyperparameters
2023-01-19 23:50:54,968:INFO:Tuning with n_jobs=-1
2023-01-19 23:50:54,968:INFO:Initializing RandomizedSearchCV
2023-01-19 23:51:55,611:INFO:Initializing finalize_model()
2023-01-19 23:51:55,613:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc645499190>, estimator=VotingRegressor(estimators=[('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x7fc646cda160>),
                            ('Bayesian Ridge', BayesianRidge())],
                n_jobs=-1), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-01-19 23:51:55,618:INFO:Finalizing VotingRegressor(estimators=[('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x7fc646cda160>),
                            ('Bayesian Ridge', BayesianRidge())],
                n_jobs=-1)
2023-01-19 23:51:55,644:INFO:Initializing create_model()
2023-01-19 23:51:55,644:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc645499190>, estimator=VotingRegressor(estimators=[('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x7fc646cda160>),
                            ('Bayesian Ridge', BayesianRidge())],
                n_jobs=-1), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-01-19 23:51:55,644:INFO:Checking exceptions
2023-01-19 23:51:55,654:INFO:Importing libraries
2023-01-19 23:51:55,654:INFO:Copying training dataset
2023-01-19 23:51:55,658:INFO:Defining folds
2023-01-19 23:51:55,659:INFO:Declaring metric variables
2023-01-19 23:51:55,660:INFO:Importing untrained model
2023-01-19 23:51:55,661:INFO:Declaring custom model
2023-01-19 23:51:55,671:INFO:Voting Regressor Imported successfully
2023-01-19 23:51:55,680:INFO:Cross validation set to False
2023-01-19 23:51:55,680:INFO:Fitting Model
2023-01-19 23:52:05,178:INFO:Pipeline(memory=Memory(location=/var/folders/3w/xf1fzw1s1mnb4ckhfxf67vgw0000gn/T/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['MSSubClass', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '...
                                             'EnclosedPorch', '3SsnPorch',
                                             'ScreenPorch', 'PoolArea', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 VotingRegressor(estimators=[('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x7fc64636f0a0>),
                                             ('Bayesian Ridge',
                                              BayesianRidge())],
                                 n_jobs=-1))])
2023-01-19 23:52:05,178:INFO:create_model() successfully completed......................................
2023-01-19 23:52:05,881:INFO:_master_model_container: 30
2023-01-19 23:52:05,881:INFO:_display_container: 10
2023-01-19 23:52:05,894:INFO:Pipeline(memory=Memory(location=/var/folders/3w/xf1fzw1s1mnb4ckhfxf67vgw0000gn/T/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['MSSubClass', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '...
                                             'EnclosedPorch', '3SsnPorch',
                                             'ScreenPorch', 'PoolArea', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 VotingRegressor(estimators=[('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x7fc64636f0a0>),
                                             ('Bayesian Ridge',
                                              BayesianRidge())],
                                 n_jobs=-1))])
2023-01-19 23:52:05,895:INFO:finalize_model() successfully completed......................................
2023-01-19 23:57:30,679:INFO:Initializing predict_model()
2023-01-19 23:57:30,685:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fc645499190>, estimator=Pipeline(memory=Memory(location=/var/folders/3w/xf1fzw1s1mnb4ckhfxf67vgw0000gn/T/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['MSSubClass', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '...
                                             'EnclosedPorch', '3SsnPorch',
                                             'ScreenPorch', 'PoolArea', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 VotingRegressor(estimators=[('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x7fc64636f0a0>),
                                             ('Bayesian Ridge',
                                              BayesianRidge())],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fc644426280>)
2023-01-19 23:57:30,686:INFO:Checking exceptions
2023-01-19 23:57:30,687:INFO:Preloading libraries
2023-01-19 23:57:30,747:INFO:Set up data.
2023-01-19 23:57:31,020:INFO:Set up index.
2023-01-20 14:01:13,792:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-20 14:01:13,793:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-20 14:01:13,793:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-20 14:01:13,793:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-20 14:01:14,847:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-01-20 14:01:15,176:INFO:PyCaret RegressionExperiment
2023-01-20 14:01:15,176:INFO:Logging name: reg-default-name
2023-01-20 14:01:15,176:INFO:ML Usecase: MLUsecase.REGRESSION
2023-01-20 14:01:15,176:INFO:version 3.0.0.rc8
2023-01-20 14:01:15,176:INFO:Initializing setup()
2023-01-20 14:01:15,176:INFO:self.USI: a40d
2023-01-20 14:01:15,176:INFO:self._variable_keys: {'logging_param', 'y_test', 'fold_generator', 'data', 'n_jobs_param', 'y_train', 'pipeline', 'idx', '_available_plots', 'exp_id', '_ml_usecase', 'X_train', 'target_param', 'X_test', 'USI', 'X', 'y', 'gpu_n_jobs_param', 'exp_name_log', 'fold_groups_param', 'transform_target_param', 'html_param', 'seed', 'memory', 'fold_shuffle_param', 'gpu_param', 'log_plots_param'}
2023-01-20 14:01:15,176:INFO:Checking environment
2023-01-20 14:01:15,176:INFO:python_version: 3.9.12
2023-01-20 14:01:15,176:INFO:python_build: ('main', 'Apr  5 2022 01:53:17')
2023-01-20 14:01:15,176:INFO:machine: x86_64
2023-01-20 14:01:15,176:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-01-20 14:01:15,176:INFO:Memory: svmem(total=8589934592, available=2484482048, percent=71.1, used=5764182016, free=131493888, active=2359492608, inactive=2299461632, wired=3404689408)
2023-01-20 14:01:15,177:INFO:Physical Core: 4
2023-01-20 14:01:15,177:INFO:Logical Core: 8
2023-01-20 14:01:15,177:INFO:Checking libraries
2023-01-20 14:01:15,177:INFO:System:
2023-01-20 14:01:15,177:INFO:    python: 3.9.12 (main, Apr  5 2022, 01:53:17)  [Clang 12.0.0 ]
2023-01-20 14:01:15,177:INFO:executable: /Users/hiroto/opt/anaconda3/bin/python
2023-01-20 14:01:15,177:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-01-20 14:01:15,177:INFO:PyCaret required dependencies:
2023-01-20 14:01:15,177:INFO:                 pip: 21.2.4
2023-01-20 14:01:15,177:INFO:          setuptools: 66.0.0
2023-01-20 14:01:15,177:INFO:             pycaret: 3.0.0rc8
2023-01-20 14:01:15,177:INFO:             IPython: 8.8.0
2023-01-20 14:01:15,177:INFO:          ipywidgets: 8.0.4
2023-01-20 14:01:15,177:INFO:                tqdm: 4.64.1
2023-01-20 14:01:15,177:INFO:               numpy: 1.23.5
2023-01-20 14:01:15,177:INFO:              pandas: 1.5.3
2023-01-20 14:01:15,177:INFO:              jinja2: 3.1.2
2023-01-20 14:01:15,177:INFO:               scipy: 1.10.0
2023-01-20 14:01:15,177:INFO:              joblib: 1.2.0
2023-01-20 14:01:15,177:INFO:             sklearn: 1.1.3
2023-01-20 14:01:15,177:INFO:                pyod: 1.0.7
2023-01-20 14:01:15,177:INFO:            imblearn: 0.10.1
2023-01-20 14:01:15,177:INFO:   category_encoders: 2.6.0
2023-01-20 14:01:15,177:INFO:            lightgbm: 3.3.4
2023-01-20 14:01:15,177:INFO:               numba: 0.56.4
2023-01-20 14:01:15,177:INFO:            requests: 2.28.2
2023-01-20 14:01:15,178:INFO:          matplotlib: 3.6.3
2023-01-20 14:01:15,178:INFO:          scikitplot: 0.3.7
2023-01-20 14:01:15,178:INFO:         yellowbrick: 1.5
2023-01-20 14:01:15,178:INFO:              plotly: 5.12.0
2023-01-20 14:01:15,178:INFO:             kaleido: 0.2.1
2023-01-20 14:01:15,178:INFO:         statsmodels: 0.13.5
2023-01-20 14:01:15,178:INFO:              sktime: 0.15.1
2023-01-20 14:01:15,178:INFO:               tbats: 1.1.2
2023-01-20 14:01:15,178:INFO:            pmdarima: 2.0.2
2023-01-20 14:01:15,178:INFO:              psutil: 5.9.4
2023-01-20 14:01:15,178:INFO:PyCaret optional dependencies:
2023-01-20 14:01:15,180:INFO:                shap: 0.41.0
2023-01-20 14:01:15,180:INFO:           interpret: Not installed
2023-01-20 14:01:15,180:INFO:                umap: 0.5.3
2023-01-20 14:01:15,180:INFO:    pandas_profiling: 3.6.2
2023-01-20 14:01:15,180:INFO:  explainerdashboard: Not installed
2023-01-20 14:01:15,180:INFO:             autoviz: Not installed
2023-01-20 14:01:15,180:INFO:           fairlearn: Not installed
2023-01-20 14:01:15,181:INFO:             xgboost: 1.7.3
2023-01-20 14:01:15,181:INFO:            catboost: 1.1.1
2023-01-20 14:01:15,181:INFO:              kmodes: 0.12.2
2023-01-20 14:01:15,181:INFO:             mlxtend: 0.21.0
2023-01-20 14:01:15,181:INFO:       statsforecast: Not installed
2023-01-20 14:01:15,181:INFO:        tune_sklearn: Not installed
2023-01-20 14:01:15,181:INFO:                 ray: Not installed
2023-01-20 14:01:15,181:INFO:            hyperopt: Not installed
2023-01-20 14:01:15,181:INFO:              optuna: Not installed
2023-01-20 14:01:15,181:INFO:               skopt: Not installed
2023-01-20 14:01:15,181:INFO:              mlflow: 2.1.1
2023-01-20 14:01:15,181:INFO:              gradio: Not installed
2023-01-20 14:01:15,181:INFO:             fastapi: Not installed
2023-01-20 14:01:15,181:INFO:             uvicorn: Not installed
2023-01-20 14:01:15,181:INFO:              m2cgen: Not installed
2023-01-20 14:01:15,181:INFO:           evidently: Not installed
2023-01-20 14:01:15,181:INFO:                nltk: 3.8.1
2023-01-20 14:01:15,181:INFO:            pyLDAvis: 3.3.1
2023-01-20 14:01:15,181:INFO:              gensim: 4.3.0
2023-01-20 14:01:15,181:INFO:               spacy: 3.4.4
2023-01-20 14:01:15,181:INFO:           wordcloud: 1.8.2.2
2023-01-20 14:01:15,181:INFO:            textblob: 0.17.1
2023-01-20 14:01:15,181:INFO:               fugue: Not installed
2023-01-20 14:01:15,181:INFO:           streamlit: Not installed
2023-01-20 14:01:15,181:INFO:             prophet: Not installed
2023-01-20 14:01:15,181:INFO:None
2023-01-20 14:01:15,181:INFO:Set up data.
2023-01-20 14:01:15,238:INFO:Set up train/test split.
2023-01-20 14:01:15,258:INFO:Set up index.
2023-01-20 14:01:15,260:INFO:Set up folding strategy.
2023-01-20 14:01:15,260:INFO:Assigning column types.
2023-01-20 14:01:15,265:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-01-20 14:01:15,266:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-20 14:01:15,272:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-20 14:01:15,277:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-20 14:01:15,347:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-20 14:01:15,399:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-20 14:01:15,400:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-20 14:01:15,545:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-20 14:01:15,641:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-20 14:01:15,647:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-20 14:01:15,653:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-20 14:01:15,721:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-20 14:01:15,770:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-20 14:01:15,771:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-20 14:01:15,774:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-20 14:01:15,774:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-01-20 14:01:15,779:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-20 14:01:15,784:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-20 14:01:15,852:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-20 14:01:15,902:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-20 14:01:15,903:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-20 14:01:15,906:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-20 14:01:15,912:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-20 14:01:15,916:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-20 14:01:15,980:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-20 14:01:16,044:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-20 14:01:16,047:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-20 14:01:16,050:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-20 14:01:16,050:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-01-20 14:01:16,063:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-20 14:01:16,123:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-20 14:01:16,171:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-20 14:01:16,172:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-20 14:01:16,174:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-20 14:01:16,183:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-20 14:01:16,247:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-20 14:01:16,301:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-20 14:01:16,302:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-20 14:01:16,306:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-20 14:01:16,307:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-01-20 14:01:16,398:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-20 14:01:16,445:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-20 14:01:16,446:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-20 14:01:16,448:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-20 14:01:16,524:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-20 14:01:16,571:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-20 14:01:16,572:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-20 14:01:16,574:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-20 14:01:16,575:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-01-20 14:01:16,655:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-20 14:01:16,732:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-20 14:01:16,739:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-20 14:01:16,883:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-20 14:01:16,938:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-20 14:01:16,940:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-20 14:01:16,941:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-01-20 14:01:17,056:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-20 14:01:17,059:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-20 14:01:17,181:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-20 14:01:17,184:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-20 14:01:17,185:INFO:Preparing preprocessing pipeline...
2023-01-20 14:01:17,186:INFO:Set up column name cleaning.
2023-01-20 14:01:17,187:INFO:Set up simple imputation.
2023-01-20 14:01:17,330:INFO:Finished creating preprocessing pipeline.
2023-01-20 14:01:17,337:INFO:Pipeline: Pipeline(memory=Memory(location=/var/folders/3w/xf1fzw1s1mnb4ckhfxf67vgw0000gn/T/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['MSSubClass', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '...
                                             'BsmtFullBath', 'BsmtHalfBath',
                                             'FullBath', 'HalfBath',
                                             'BedroomAbvGr', 'KitchenAbvGr',
                                             'TotRmsAbvGrd', 'Fireplaces',
                                             'GarageCars', 'GarageArea',
                                             'WoodDeckSF', 'OpenPorchSF',
                                             'EnclosedPorch', '3SsnPorch',
                                             'ScreenPorch', 'PoolArea', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-01-20 14:01:17,337:INFO:Creating final display dataframe.
2023-01-20 14:01:21,448:INFO:PyCaret RegressionExperiment
2023-01-20 14:01:21,448:INFO:Logging name: reg-default-name
2023-01-20 14:01:21,448:INFO:ML Usecase: MLUsecase.REGRESSION
2023-01-20 14:01:21,448:INFO:version 3.0.0.rc8
2023-01-20 14:01:21,448:INFO:Initializing setup()
2023-01-20 14:01:21,448:INFO:self.USI: 959d
2023-01-20 14:01:21,448:INFO:self._variable_keys: {'logging_param', 'y_test', 'fold_generator', 'data', 'n_jobs_param', 'y_train', 'pipeline', 'idx', '_available_plots', 'exp_id', '_ml_usecase', 'X_train', 'target_param', 'X_test', 'USI', 'X', 'y', 'gpu_n_jobs_param', 'exp_name_log', 'fold_groups_param', 'transform_target_param', 'html_param', 'seed', 'memory', 'fold_shuffle_param', 'gpu_param', 'log_plots_param'}
2023-01-20 14:01:21,448:INFO:Checking environment
2023-01-20 14:01:21,448:INFO:python_version: 3.9.12
2023-01-20 14:01:21,448:INFO:python_build: ('main', 'Apr  5 2022 01:53:17')
2023-01-20 14:01:21,448:INFO:machine: x86_64
2023-01-20 14:01:21,448:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-01-20 14:01:21,448:INFO:Memory: svmem(total=8589934592, available=2560339968, percent=70.2, used=5735927808, free=139649024, active=2424954880, inactive=2349187072, wired=3310972928)
2023-01-20 14:01:21,448:INFO:Physical Core: 4
2023-01-20 14:01:21,448:INFO:Logical Core: 8
2023-01-20 14:01:21,448:INFO:Checking libraries
2023-01-20 14:01:21,448:INFO:System:
2023-01-20 14:01:21,449:INFO:    python: 3.9.12 (main, Apr  5 2022, 01:53:17)  [Clang 12.0.0 ]
2023-01-20 14:01:21,449:INFO:executable: /Users/hiroto/opt/anaconda3/bin/python
2023-01-20 14:01:21,449:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-01-20 14:01:21,449:INFO:PyCaret required dependencies:
2023-01-20 14:01:21,449:INFO:                 pip: 21.2.4
2023-01-20 14:01:21,449:INFO:          setuptools: 66.0.0
2023-01-20 14:01:21,449:INFO:             pycaret: 3.0.0rc8
2023-01-20 14:01:21,449:INFO:             IPython: 8.8.0
2023-01-20 14:01:21,449:INFO:          ipywidgets: 8.0.4
2023-01-20 14:01:21,449:INFO:                tqdm: 4.64.1
2023-01-20 14:01:21,449:INFO:               numpy: 1.23.5
2023-01-20 14:01:21,449:INFO:              pandas: 1.5.3
2023-01-20 14:01:21,449:INFO:              jinja2: 3.1.2
2023-01-20 14:01:21,449:INFO:               scipy: 1.10.0
2023-01-20 14:01:21,449:INFO:              joblib: 1.2.0
2023-01-20 14:01:21,449:INFO:             sklearn: 1.1.3
2023-01-20 14:01:21,449:INFO:                pyod: 1.0.7
2023-01-20 14:01:21,449:INFO:            imblearn: 0.10.1
2023-01-20 14:01:21,449:INFO:   category_encoders: 2.6.0
2023-01-20 14:01:21,449:INFO:            lightgbm: 3.3.4
2023-01-20 14:01:21,449:INFO:               numba: 0.56.4
2023-01-20 14:01:21,449:INFO:            requests: 2.28.2
2023-01-20 14:01:21,449:INFO:          matplotlib: 3.6.3
2023-01-20 14:01:21,449:INFO:          scikitplot: 0.3.7
2023-01-20 14:01:21,449:INFO:         yellowbrick: 1.5
2023-01-20 14:01:21,449:INFO:              plotly: 5.12.0
2023-01-20 14:01:21,449:INFO:             kaleido: 0.2.1
2023-01-20 14:01:21,449:INFO:         statsmodels: 0.13.5
2023-01-20 14:01:21,450:INFO:              sktime: 0.15.1
2023-01-20 14:01:21,450:INFO:               tbats: 1.1.2
2023-01-20 14:01:21,450:INFO:            pmdarima: 2.0.2
2023-01-20 14:01:21,450:INFO:              psutil: 5.9.4
2023-01-20 14:01:21,450:INFO:PyCaret optional dependencies:
2023-01-20 14:01:21,450:INFO:                shap: 0.41.0
2023-01-20 14:01:21,450:INFO:           interpret: Not installed
2023-01-20 14:01:21,450:INFO:                umap: 0.5.3
2023-01-20 14:01:21,450:INFO:    pandas_profiling: 3.6.2
2023-01-20 14:01:21,450:INFO:  explainerdashboard: Not installed
2023-01-20 14:01:21,450:INFO:             autoviz: Not installed
2023-01-20 14:01:21,450:INFO:           fairlearn: Not installed
2023-01-20 14:01:21,450:INFO:             xgboost: 1.7.3
2023-01-20 14:01:21,450:INFO:            catboost: 1.1.1
2023-01-20 14:01:21,450:INFO:              kmodes: 0.12.2
2023-01-20 14:01:21,450:INFO:             mlxtend: 0.21.0
2023-01-20 14:01:21,450:INFO:       statsforecast: Not installed
2023-01-20 14:01:21,450:INFO:        tune_sklearn: Not installed
2023-01-20 14:01:21,450:INFO:                 ray: Not installed
2023-01-20 14:01:21,450:INFO:            hyperopt: Not installed
2023-01-20 14:01:21,450:INFO:              optuna: Not installed
2023-01-20 14:01:21,450:INFO:               skopt: Not installed
2023-01-20 14:01:21,450:INFO:              mlflow: 2.1.1
2023-01-20 14:01:21,450:INFO:              gradio: Not installed
2023-01-20 14:01:21,450:INFO:             fastapi: Not installed
2023-01-20 14:01:21,450:INFO:             uvicorn: Not installed
2023-01-20 14:01:21,450:INFO:              m2cgen: Not installed
2023-01-20 14:01:21,450:INFO:           evidently: Not installed
2023-01-20 14:01:21,450:INFO:                nltk: 3.8.1
2023-01-20 14:01:21,451:INFO:            pyLDAvis: 3.3.1
2023-01-20 14:01:21,451:INFO:              gensim: 4.3.0
2023-01-20 14:01:21,451:INFO:               spacy: 3.4.4
2023-01-20 14:01:21,451:INFO:           wordcloud: 1.8.2.2
2023-01-20 14:01:21,451:INFO:            textblob: 0.17.1
2023-01-20 14:01:21,451:INFO:               fugue: Not installed
2023-01-20 14:01:21,451:INFO:           streamlit: Not installed
2023-01-20 14:01:21,451:INFO:             prophet: Not installed
2023-01-20 14:01:21,451:INFO:None
2023-01-20 14:01:21,451:INFO:Set up data.
2023-01-20 14:01:21,509:INFO:Set up train/test split.
2023-01-20 14:01:21,520:INFO:Set up index.
2023-01-20 14:01:21,523:INFO:Set up folding strategy.
2023-01-20 14:01:21,523:INFO:Assigning column types.
2023-01-20 14:01:21,529:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-01-20 14:01:21,529:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-20 14:01:21,534:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-20 14:01:21,539:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-20 14:01:21,632:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-20 14:01:21,678:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-20 14:01:21,679:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-20 14:01:21,681:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-20 14:01:21,682:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-20 14:01:21,686:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-20 14:01:21,691:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-20 14:01:21,749:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-20 14:01:21,793:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-20 14:01:21,793:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-20 14:01:21,796:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-20 14:01:21,796:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-01-20 14:01:21,801:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-20 14:01:21,805:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-20 14:01:21,862:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-20 14:01:21,906:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-20 14:01:21,906:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-20 14:01:21,909:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-20 14:01:21,914:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-20 14:01:21,918:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-20 14:01:21,975:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-20 14:01:22,020:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-20 14:01:22,020:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-20 14:01:22,024:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-20 14:01:22,024:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-01-20 14:01:22,038:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-20 14:01:22,099:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-20 14:01:22,145:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-20 14:01:22,145:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-20 14:01:22,148:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-20 14:01:22,157:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-20 14:01:22,215:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-20 14:01:22,258:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-20 14:01:22,259:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-20 14:01:22,261:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-20 14:01:22,262:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-01-20 14:01:22,327:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-20 14:01:22,404:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-20 14:01:22,405:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-20 14:01:22,408:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-20 14:01:22,528:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-20 14:01:22,575:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-20 14:01:22,576:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-20 14:01:22,579:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-20 14:01:22,579:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-01-20 14:01:22,644:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-20 14:01:22,688:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-20 14:01:22,691:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-20 14:01:22,756:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-20 14:01:22,799:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-20 14:01:22,802:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-20 14:01:22,802:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-01-20 14:01:22,910:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-20 14:01:22,913:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-20 14:01:23,021:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-20 14:01:23,024:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-20 14:01:23,024:INFO:Preparing preprocessing pipeline...
2023-01-20 14:01:23,025:INFO:Set up column name cleaning.
2023-01-20 14:01:23,025:INFO:Set up simple imputation.
2023-01-20 14:01:23,146:INFO:Finished creating preprocessing pipeline.
2023-01-20 14:01:23,152:INFO:Pipeline: Pipeline(memory=Memory(location=/var/folders/3w/xf1fzw1s1mnb4ckhfxf67vgw0000gn/T/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['MSSubClass', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '...
                                             'BsmtFullBath', 'BsmtHalfBath',
                                             'FullBath', 'HalfBath',
                                             'BedroomAbvGr', 'KitchenAbvGr',
                                             'TotRmsAbvGrd', 'Fireplaces',
                                             'GarageCars', 'GarageArea',
                                             'WoodDeckSF', 'OpenPorchSF',
                                             'EnclosedPorch', '3SsnPorch',
                                             'ScreenPorch', 'PoolArea', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-01-20 14:01:23,152:INFO:Creating final display dataframe.
2023-01-20 14:01:23,702:INFO:Setup _display_container:                     Description             Value
0                    Session id              1766
1                        Target         SalePrice
2                   Target type        Regression
3           Original data shape       (1458, 193)
4        Transformed data shape       (1458, 193)
5   Transformed train set shape       (1020, 193)
6    Transformed test set shape        (438, 193)
7              Numeric features               192
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              959d
2023-01-20 14:01:23,838:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-20 14:01:23,840:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-20 14:01:23,958:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-20 14:01:23,960:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-20 14:01:23,961:INFO:setup() successfully completed in 2.51s...............
2023-01-20 14:01:43,158:INFO:Initializing create_model()
2023-01-20 14:01:43,158:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9132bf4490>, estimator=catboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-20 14:01:43,158:INFO:Checking exceptions
2023-01-20 14:01:43,218:INFO:Importing libraries
2023-01-20 14:01:43,219:INFO:Copying training dataset
2023-01-20 14:01:43,239:INFO:Defining folds
2023-01-20 14:01:43,239:INFO:Declaring metric variables
2023-01-20 14:01:43,250:INFO:Importing untrained model
2023-01-20 14:01:43,259:INFO:CatBoost Regressor Imported successfully
2023-01-20 14:01:43,274:INFO:Starting cross validation
2023-01-20 14:01:43,289:INFO:Cross validating with KFold(n_splits=10, random_state=1766, shuffle=True), n_jobs=-1
2023-01-20 14:02:09,251:INFO:Calculating mean and std
2023-01-20 14:02:09,370:INFO:Creating metrics dataframe
2023-01-20 14:02:09,545:INFO:Finalizing model
2023-01-20 14:02:12,345:INFO:Uploading results into container
2023-01-20 14:02:12,346:INFO:Uploading model into container now
2023-01-20 14:02:12,386:INFO:_master_model_container: 1
2023-01-20 14:02:12,386:INFO:_display_container: 2
2023-01-20 14:02:12,386:INFO:<catboost.core.CatBoostRegressor object at 0x7f9120e29d00>
2023-01-20 14:02:12,386:INFO:create_model() successfully completed......................................
2023-01-20 14:02:13,390:INFO:Initializing create_model()
2023-01-20 14:02:13,391:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9132bf4490>, estimator=br, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-20 14:02:13,391:INFO:Checking exceptions
2023-01-20 14:02:13,429:INFO:Importing libraries
2023-01-20 14:02:13,463:INFO:Copying training dataset
2023-01-20 14:02:13,467:INFO:Defining folds
2023-01-20 14:02:13,504:INFO:Declaring metric variables
2023-01-20 14:02:13,513:INFO:Importing untrained model
2023-01-20 14:02:13,559:INFO:Bayesian Ridge Imported successfully
2023-01-20 14:02:13,617:INFO:Starting cross validation
2023-01-20 14:02:13,658:INFO:Cross validating with KFold(n_splits=10, random_state=1766, shuffle=True), n_jobs=-1
2023-01-20 14:02:14,190:INFO:Calculating mean and std
2023-01-20 14:02:14,191:INFO:Creating metrics dataframe
2023-01-20 14:02:14,196:INFO:Finalizing model
2023-01-20 14:02:14,299:INFO:Uploading results into container
2023-01-20 14:02:14,301:INFO:Uploading model into container now
2023-01-20 14:02:14,315:INFO:_master_model_container: 2
2023-01-20 14:02:14,316:INFO:_display_container: 3
2023-01-20 14:02:14,316:INFO:BayesianRidge()
2023-01-20 14:02:14,316:INFO:create_model() successfully completed......................................
2023-01-20 14:02:25,250:INFO:Initializing create_model()
2023-01-20 14:02:25,255:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9132bf4490>, estimator=omp, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-20 14:02:25,255:INFO:Checking exceptions
2023-01-20 14:02:25,316:INFO:Importing libraries
2023-01-20 14:02:25,316:INFO:Copying training dataset
2023-01-20 14:02:25,340:INFO:Defining folds
2023-01-20 14:02:25,340:INFO:Declaring metric variables
2023-01-20 14:02:25,347:INFO:Importing untrained model
2023-01-20 14:02:25,352:INFO:Orthogonal Matching Pursuit Imported successfully
2023-01-20 14:02:25,359:INFO:Starting cross validation
2023-01-20 14:02:25,362:INFO:Cross validating with KFold(n_splits=10, random_state=1766, shuffle=True), n_jobs=-1
2023-01-20 14:02:25,997:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-20 14:02:25,997:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-20 14:02:25,997:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-20 14:02:26,017:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-20 14:02:26,017:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-20 14:02:26,026:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-20 14:02:26,058:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-20 14:02:26,095:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-20 14:02:26,238:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-20 14:02:26,250:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-20 14:02:26,315:INFO:Calculating mean and std
2023-01-20 14:02:26,317:INFO:Creating metrics dataframe
2023-01-20 14:02:26,324:INFO:Finalizing model
2023-01-20 14:02:26,468:INFO:Uploading results into container
2023-01-20 14:02:26,470:INFO:Uploading model into container now
2023-01-20 14:02:26,486:INFO:_master_model_container: 3
2023-01-20 14:02:26,487:INFO:_display_container: 4
2023-01-20 14:02:26,487:INFO:OrthogonalMatchingPursuit()
2023-01-20 14:02:26,487:INFO:create_model() successfully completed......................................
2023-01-20 14:02:26,698:INFO:Initializing tune_model()
2023-01-20 14:02:26,698:INFO:tune_model(estimator=OrthogonalMatchingPursuit(), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9132bf4490>)
2023-01-20 14:02:26,698:INFO:Checking exceptions
2023-01-20 14:02:26,733:INFO:Copying training dataset
2023-01-20 14:02:26,740:INFO:Checking base model
2023-01-20 14:02:26,740:INFO:Base model : Orthogonal Matching Pursuit
2023-01-20 14:02:26,746:INFO:Declaring metric variables
2023-01-20 14:02:26,751:INFO:Defining Hyperparameters
2023-01-20 14:02:26,953:INFO:Tuning with n_jobs=-1
2023-01-20 14:02:26,953:INFO:Initializing RandomizedSearchCV
2023-01-20 14:02:28,182:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:757: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2023-01-20 14:02:28,182:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:757: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2023-01-20 14:02:28,194:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:757: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2023-01-20 14:02:28,227:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:757: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2023-01-20 14:02:28,238:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:757: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2023-01-20 14:02:28,326:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:757: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2023-01-20 14:02:28,327:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:757: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2023-01-20 14:02:28,334:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:757: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2023-01-20 14:02:28,350:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:757: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2023-01-20 14:02:28,383:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_omp.py:757: RuntimeWarning: Orthogonal matching pursuit ended prematurely due to linear dependence in the dictionary. The requested precision might not have been met.
  coef_, self.n_iter_ = orthogonal_mp_gram(

2023-01-20 14:02:28,503:INFO:best_params: {'actual_estimator__normalize': True, 'actual_estimator__n_nonzero_coefs': 30, 'actual_estimator__fit_intercept': True}
2023-01-20 14:02:28,505:INFO:Hyperparameter search completed
2023-01-20 14:02:28,505:INFO:SubProcess create_model() called ==================================
2023-01-20 14:02:28,506:INFO:Initializing create_model()
2023-01-20 14:02:28,506:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9132bf4490>, estimator=OrthogonalMatchingPursuit(), fold=KFold(n_splits=10, random_state=1766, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f911e6aef70>, model_only=True, return_train_score=False, kwargs={'normalize': True, 'n_nonzero_coefs': 30, 'fit_intercept': True})
2023-01-20 14:02:28,506:INFO:Checking exceptions
2023-01-20 14:02:28,506:INFO:Importing libraries
2023-01-20 14:02:28,506:INFO:Copying training dataset
2023-01-20 14:02:28,512:INFO:Defining folds
2023-01-20 14:02:28,512:INFO:Declaring metric variables
2023-01-20 14:02:28,516:INFO:Importing untrained model
2023-01-20 14:02:28,516:INFO:Declaring custom model
2023-01-20 14:02:28,520:INFO:Orthogonal Matching Pursuit Imported successfully
2023-01-20 14:02:28,527:INFO:Starting cross validation
2023-01-20 14:02:28,533:INFO:Cross validating with KFold(n_splits=10, random_state=1766, shuffle=True), n_jobs=-1
2023-01-20 14:02:28,712:INFO:Calculating mean and std
2023-01-20 14:02:28,713:INFO:Creating metrics dataframe
2023-01-20 14:02:28,719:INFO:Finalizing model
2023-01-20 14:02:28,754:INFO:Uploading results into container
2023-01-20 14:02:28,755:INFO:Uploading model into container now
2023-01-20 14:02:28,756:INFO:_master_model_container: 4
2023-01-20 14:02:28,756:INFO:_display_container: 5
2023-01-20 14:02:28,757:INFO:OrthogonalMatchingPursuit(n_nonzero_coefs=30, normalize=True)
2023-01-20 14:02:28,757:INFO:create_model() successfully completed......................................
2023-01-20 14:02:28,907:INFO:SubProcess create_model() end ==================================
2023-01-20 14:02:28,907:INFO:choose_better activated
2023-01-20 14:02:28,911:INFO:SubProcess create_model() called ==================================
2023-01-20 14:02:28,911:INFO:Initializing create_model()
2023-01-20 14:02:28,911:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9132bf4490>, estimator=OrthogonalMatchingPursuit(), fold=KFold(n_splits=10, random_state=1766, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-20 14:02:28,911:INFO:Checking exceptions
2023-01-20 14:02:28,913:INFO:Importing libraries
2023-01-20 14:02:28,913:INFO:Copying training dataset
2023-01-20 14:02:28,917:INFO:Defining folds
2023-01-20 14:02:28,917:INFO:Declaring metric variables
2023-01-20 14:02:28,917:INFO:Importing untrained model
2023-01-20 14:02:28,917:INFO:Declaring custom model
2023-01-20 14:02:28,917:INFO:Orthogonal Matching Pursuit Imported successfully
2023-01-20 14:02:28,917:INFO:Starting cross validation
2023-01-20 14:02:28,919:INFO:Cross validating with KFold(n_splits=10, random_state=1766, shuffle=True), n_jobs=-1
2023-01-20 14:02:28,962:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-20 14:02:28,968:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-20 14:02:28,981:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-20 14:02:28,991:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-20 14:02:29,006:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-20 14:02:29,024:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-20 14:02:29,027:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-20 14:02:29,046:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-20 14:02:29,061:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-20 14:02:29,074:WARNING:/Users/hiroto/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.
If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:

from sklearn.pipeline import make_pipeline

model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())

If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:

kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}
model.fit(X, y, **kwargs)


  warnings.warn(

2023-01-20 14:02:29,096:INFO:Calculating mean and std
2023-01-20 14:02:29,097:INFO:Creating metrics dataframe
2023-01-20 14:02:29,099:INFO:Finalizing model
2023-01-20 14:02:29,124:INFO:Uploading results into container
2023-01-20 14:02:29,124:INFO:Uploading model into container now
2023-01-20 14:02:29,124:INFO:_master_model_container: 5
2023-01-20 14:02:29,124:INFO:_display_container: 6
2023-01-20 14:02:29,125:INFO:OrthogonalMatchingPursuit()
2023-01-20 14:02:29,125:INFO:create_model() successfully completed......................................
2023-01-20 14:02:29,260:INFO:SubProcess create_model() end ==================================
2023-01-20 14:02:29,260:INFO:OrthogonalMatchingPursuit() result for R2 is 0.8574
2023-01-20 14:02:29,261:INFO:OrthogonalMatchingPursuit(n_nonzero_coefs=30, normalize=True) result for R2 is 0.8648
2023-01-20 14:02:29,261:INFO:OrthogonalMatchingPursuit(n_nonzero_coefs=30, normalize=True) is best model
2023-01-20 14:02:29,261:INFO:choose_better completed
2023-01-20 14:02:29,271:INFO:_master_model_container: 5
2023-01-20 14:02:29,271:INFO:_display_container: 5
2023-01-20 14:02:29,271:INFO:OrthogonalMatchingPursuit(n_nonzero_coefs=30, normalize=True)
2023-01-20 14:02:29,271:INFO:tune_model() successfully completed......................................
2023-01-20 14:03:45,319:INFO:Initializing finalize_model()
2023-01-20 14:03:45,319:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9132bf4490>, estimator=<catboost.core.CatBoostRegressor object at 0x7f9120e29d00>, fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-01-20 14:03:45,319:INFO:Finalizing <catboost.core.CatBoostRegressor object at 0x7f9120e29d00>
2023-01-20 14:03:45,326:INFO:Initializing create_model()
2023-01-20 14:03:45,326:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9132bf4490>, estimator=<catboost.core.CatBoostRegressor object at 0x7f9120e29d00>, fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-01-20 14:03:45,326:INFO:Checking exceptions
2023-01-20 14:03:45,329:INFO:Importing libraries
2023-01-20 14:03:45,329:INFO:Copying training dataset
2023-01-20 14:03:45,330:INFO:Defining folds
2023-01-20 14:03:45,330:INFO:Declaring metric variables
2023-01-20 14:03:45,331:INFO:Importing untrained model
2023-01-20 14:03:45,331:INFO:Declaring custom model
2023-01-20 14:03:45,335:INFO:CatBoost Regressor Imported successfully
2023-01-20 14:03:45,338:INFO:Cross validation set to False
2023-01-20 14:03:45,338:INFO:Fitting Model
2023-01-20 14:03:47,572:INFO:Pipeline(memory=Memory(location=/var/folders/3w/xf1fzw1s1mnb4ckhfxf67vgw0000gn/T/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['MSSubClass', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '...
                                             'TotRmsAbvGrd', 'Fireplaces',
                                             'GarageCars', 'GarageArea',
                                             'WoodDeckSF', 'OpenPorchSF',
                                             'EnclosedPorch', '3SsnPorch',
                                             'ScreenPorch', 'PoolArea', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 <catboost.core.CatBoostRegressor object at 0x7f911e762a60>)])
2023-01-20 14:03:47,572:INFO:create_model() successfully completed......................................
2023-01-20 14:03:47,732:INFO:_master_model_container: 5
2023-01-20 14:03:47,732:INFO:_display_container: 5
2023-01-20 14:03:47,742:INFO:Pipeline(memory=Memory(location=/var/folders/3w/xf1fzw1s1mnb4ckhfxf67vgw0000gn/T/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['MSSubClass', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '...
                                             'TotRmsAbvGrd', 'Fireplaces',
                                             'GarageCars', 'GarageArea',
                                             'WoodDeckSF', 'OpenPorchSF',
                                             'EnclosedPorch', '3SsnPorch',
                                             'ScreenPorch', 'PoolArea', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 <catboost.core.CatBoostRegressor object at 0x7f911e762a60>)])
2023-01-20 14:03:47,742:INFO:finalize_model() successfully completed......................................
2023-01-20 14:03:47,903:INFO:Initializing finalize_model()
2023-01-20 14:03:47,903:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9132bf4490>, estimator=BayesianRidge(), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-01-20 14:03:47,904:INFO:Finalizing BayesianRidge()
2023-01-20 14:03:47,911:INFO:Initializing create_model()
2023-01-20 14:03:47,912:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9132bf4490>, estimator=BayesianRidge(), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-01-20 14:03:47,912:INFO:Checking exceptions
2023-01-20 14:03:47,914:INFO:Importing libraries
2023-01-20 14:03:47,914:INFO:Copying training dataset
2023-01-20 14:03:47,914:INFO:Defining folds
2023-01-20 14:03:47,914:INFO:Declaring metric variables
2023-01-20 14:03:47,914:INFO:Importing untrained model
2023-01-20 14:03:47,914:INFO:Declaring custom model
2023-01-20 14:03:47,915:INFO:Bayesian Ridge Imported successfully
2023-01-20 14:03:47,917:INFO:Cross validation set to False
2023-01-20 14:03:47,917:INFO:Fitting Model
2023-01-20 14:03:47,994:INFO:Pipeline(memory=Memory(location=/var/folders/3w/xf1fzw1s1mnb4ckhfxf67vgw0000gn/T/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['MSSubClass', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '...
                                             'FullBath', 'HalfBath',
                                             'BedroomAbvGr', 'KitchenAbvGr',
                                             'TotRmsAbvGrd', 'Fireplaces',
                                             'GarageCars', 'GarageArea',
                                             'WoodDeckSF', 'OpenPorchSF',
                                             'EnclosedPorch', '3SsnPorch',
                                             'ScreenPorch', 'PoolArea', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator', BayesianRidge())])
2023-01-20 14:03:47,994:INFO:create_model() successfully completed......................................
2023-01-20 14:03:48,159:INFO:_master_model_container: 5
2023-01-20 14:03:48,159:INFO:_display_container: 5
2023-01-20 14:03:48,168:INFO:Pipeline(memory=Memory(location=/var/folders/3w/xf1fzw1s1mnb4ckhfxf67vgw0000gn/T/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['MSSubClass', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '...
                                             'FullBath', 'HalfBath',
                                             'BedroomAbvGr', 'KitchenAbvGr',
                                             'TotRmsAbvGrd', 'Fireplaces',
                                             'GarageCars', 'GarageArea',
                                             'WoodDeckSF', 'OpenPorchSF',
                                             'EnclosedPorch', '3SsnPorch',
                                             'ScreenPorch', 'PoolArea', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator', BayesianRidge())])
2023-01-20 14:03:48,168:INFO:finalize_model() successfully completed......................................
2023-01-20 14:03:53,810:INFO:Initializing blend_models()
2023-01-20 14:03:53,810:INFO:blend_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9132bf4490>, estimator_list=[<catboost.core.CatBoostRegressor object at 0x7f9120e29d00>, BayesianRidge()], fold=None, round=4, choose_better=False, optimize=R2, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-01-20 14:03:53,811:INFO:Checking exceptions
2023-01-20 14:03:53,866:INFO:Importing libraries
2023-01-20 14:03:53,867:INFO:Copying training dataset
2023-01-20 14:03:53,882:INFO:Getting model names
2023-01-20 14:03:53,892:INFO:SubProcess create_model() called ==================================
2023-01-20 14:03:53,896:INFO:Initializing create_model()
2023-01-20 14:03:53,896:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9132bf4490>, estimator=VotingRegressor(estimators=[('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x7f9120e29d00>),
                            ('Bayesian Ridge', BayesianRidge())],
                n_jobs=-1), fold=KFold(n_splits=10, random_state=1766, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f911e0b2eb0>, model_only=True, return_train_score=False, kwargs={})
2023-01-20 14:03:53,896:INFO:Checking exceptions
2023-01-20 14:03:53,897:INFO:Importing libraries
2023-01-20 14:03:53,897:INFO:Copying training dataset
2023-01-20 14:03:53,905:INFO:Defining folds
2023-01-20 14:03:53,906:INFO:Declaring metric variables
2023-01-20 14:03:53,912:INFO:Importing untrained model
2023-01-20 14:03:53,912:INFO:Declaring custom model
2023-01-20 14:03:53,917:INFO:Voting Regressor Imported successfully
2023-01-20 14:03:53,925:INFO:Starting cross validation
2023-01-20 14:03:53,927:INFO:Cross validating with KFold(n_splits=10, random_state=1766, shuffle=True), n_jobs=-1
2023-01-20 14:04:06,712:INFO:Calculating mean and std
2023-01-20 14:04:06,714:INFO:Creating metrics dataframe
2023-01-20 14:04:06,724:INFO:Finalizing model
2023-01-20 14:04:08,969:INFO:Uploading results into container
2023-01-20 14:04:08,970:INFO:Uploading model into container now
2023-01-20 14:04:08,971:INFO:_master_model_container: 6
2023-01-20 14:04:08,971:INFO:_display_container: 6
2023-01-20 14:04:08,974:INFO:VotingRegressor(estimators=[('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x7f911fb02160>),
                            ('Bayesian Ridge', BayesianRidge())],
                n_jobs=-1)
2023-01-20 14:04:08,974:INFO:create_model() successfully completed......................................
2023-01-20 14:04:09,258:INFO:SubProcess create_model() end ==================================
2023-01-20 14:04:09,271:INFO:_master_model_container: 6
2023-01-20 14:04:09,272:INFO:_display_container: 6
2023-01-20 14:04:09,273:INFO:VotingRegressor(estimators=[('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x7f911fb02160>),
                            ('Bayesian Ridge', BayesianRidge())],
                n_jobs=-1)
2023-01-20 14:04:09,274:INFO:blend_models() successfully completed......................................
2023-01-20 14:04:13,236:INFO:Initializing finalize_model()
2023-01-20 14:04:13,236:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9132bf4490>, estimator=VotingRegressor(estimators=[('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x7f911fb02160>),
                            ('Bayesian Ridge', BayesianRidge())],
                n_jobs=-1), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-01-20 14:04:13,238:INFO:Finalizing VotingRegressor(estimators=[('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x7f911fb02160>),
                            ('Bayesian Ridge', BayesianRidge())],
                n_jobs=-1)
2023-01-20 14:04:13,245:INFO:Initializing create_model()
2023-01-20 14:04:13,245:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7f9132bf4490>, estimator=VotingRegressor(estimators=[('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x7f911fb02160>),
                            ('Bayesian Ridge', BayesianRidge())],
                n_jobs=-1), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-01-20 14:04:13,245:INFO:Checking exceptions
2023-01-20 14:04:13,247:INFO:Importing libraries
2023-01-20 14:04:13,247:INFO:Copying training dataset
2023-01-20 14:04:13,248:INFO:Defining folds
2023-01-20 14:04:13,248:INFO:Declaring metric variables
2023-01-20 14:04:13,249:INFO:Importing untrained model
2023-01-20 14:04:13,249:INFO:Declaring custom model
2023-01-20 14:04:13,251:INFO:Voting Regressor Imported successfully
2023-01-20 14:04:13,253:INFO:Cross validation set to False
2023-01-20 14:04:13,253:INFO:Fitting Model
2023-01-20 14:04:15,483:INFO:Pipeline(memory=Memory(location=/var/folders/3w/xf1fzw1s1mnb4ckhfxf67vgw0000gn/T/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['MSSubClass', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '...
                                             'EnclosedPorch', '3SsnPorch',
                                             'ScreenPorch', 'PoolArea', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 VotingRegressor(estimators=[('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x7f9132c0b130>),
                                             ('Bayesian Ridge',
                                              BayesianRidge())],
                                 n_jobs=-1))])
2023-01-20 14:04:15,483:INFO:create_model() successfully completed......................................
2023-01-20 14:04:15,645:INFO:_master_model_container: 6
2023-01-20 14:04:15,645:INFO:_display_container: 6
2023-01-20 14:04:15,659:INFO:Pipeline(memory=Memory(location=/var/folders/3w/xf1fzw1s1mnb4ckhfxf67vgw0000gn/T/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['MSSubClass', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '...
                                             'EnclosedPorch', '3SsnPorch',
                                             'ScreenPorch', 'PoolArea', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 VotingRegressor(estimators=[('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x7f9132c0b130>),
                                             ('Bayesian Ridge',
                                              BayesianRidge())],
                                 n_jobs=-1))])
2023-01-20 14:04:15,659:INFO:finalize_model() successfully completed......................................
2023-01-22 21:41:50,239:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-22 21:41:50,240:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-22 21:41:50,241:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-22 21:41:50,241:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-01-22 21:41:51,276:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-01-22 21:41:51,630:INFO:PyCaret RegressionExperiment
2023-01-22 21:41:51,630:INFO:Logging name: reg-default-name
2023-01-22 21:41:51,630:INFO:ML Usecase: MLUsecase.REGRESSION
2023-01-22 21:41:51,630:INFO:version 3.0.0.rc8
2023-01-22 21:41:51,630:INFO:Initializing setup()
2023-01-22 21:41:51,630:INFO:self.USI: 5b0a
2023-01-22 21:41:51,630:INFO:self._variable_keys: {'n_jobs_param', 'logging_param', 'y', 'exp_name_log', 'exp_id', 'fold_groups_param', 'X_train', 'target_param', 'log_plots_param', 'fold_generator', 'data', 'y_test', 'gpu_n_jobs_param', 'y_train', 'gpu_param', 'transform_target_param', 'html_param', 'fold_shuffle_param', 'memory', 'idx', 'pipeline', 'USI', '_available_plots', 'seed', 'X', 'X_test', '_ml_usecase'}
2023-01-22 21:41:51,631:INFO:Checking environment
2023-01-22 21:41:51,631:INFO:python_version: 3.9.12
2023-01-22 21:41:51,631:INFO:python_build: ('main', 'Apr  5 2022 01:53:17')
2023-01-22 21:41:51,631:INFO:machine: x86_64
2023-01-22 21:41:51,631:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-01-22 21:41:51,631:INFO:Memory: svmem(total=8589934592, available=2346991616, percent=72.7, used=5476446208, free=46448640, active=2344669184, inactive=2252148736, wired=3131777024)
2023-01-22 21:41:51,631:INFO:Physical Core: 4
2023-01-22 21:41:51,631:INFO:Logical Core: 8
2023-01-22 21:41:51,631:INFO:Checking libraries
2023-01-22 21:41:51,631:INFO:System:
2023-01-22 21:41:51,632:INFO:    python: 3.9.12 (main, Apr  5 2022, 01:53:17)  [Clang 12.0.0 ]
2023-01-22 21:41:51,632:INFO:executable: /Users/hiroto/opt/anaconda3/bin/python
2023-01-22 21:41:51,632:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-01-22 21:41:51,632:INFO:PyCaret required dependencies:
2023-01-22 21:41:51,632:INFO:                 pip: 21.2.4
2023-01-22 21:41:51,632:INFO:          setuptools: 66.0.0
2023-01-22 21:41:51,632:INFO:             pycaret: 3.0.0rc8
2023-01-22 21:41:51,632:INFO:             IPython: 8.8.0
2023-01-22 21:41:51,632:INFO:          ipywidgets: 8.0.4
2023-01-22 21:41:51,632:INFO:                tqdm: 4.64.1
2023-01-22 21:41:51,632:INFO:               numpy: 1.23.5
2023-01-22 21:41:51,632:INFO:              pandas: 1.5.3
2023-01-22 21:41:51,632:INFO:              jinja2: 3.1.2
2023-01-22 21:41:51,632:INFO:               scipy: 1.10.0
2023-01-22 21:41:51,632:INFO:              joblib: 1.2.0
2023-01-22 21:41:51,632:INFO:             sklearn: 1.1.3
2023-01-22 21:41:51,632:INFO:                pyod: 1.0.7
2023-01-22 21:41:51,633:INFO:            imblearn: 0.10.1
2023-01-22 21:41:51,633:INFO:   category_encoders: 2.6.0
2023-01-22 21:41:51,633:INFO:            lightgbm: 3.3.4
2023-01-22 21:41:51,633:INFO:               numba: 0.56.4
2023-01-22 21:41:51,633:INFO:            requests: 2.28.2
2023-01-22 21:41:51,633:INFO:          matplotlib: 3.6.3
2023-01-22 21:41:51,633:INFO:          scikitplot: 0.3.7
2023-01-22 21:41:51,633:INFO:         yellowbrick: 1.5
2023-01-22 21:41:51,633:INFO:              plotly: 5.12.0
2023-01-22 21:41:51,633:INFO:             kaleido: 0.2.1
2023-01-22 21:41:51,633:INFO:         statsmodels: 0.13.5
2023-01-22 21:41:51,633:INFO:              sktime: 0.15.1
2023-01-22 21:41:51,633:INFO:               tbats: 1.1.2
2023-01-22 21:41:51,633:INFO:            pmdarima: 2.0.2
2023-01-22 21:41:51,633:INFO:              psutil: 5.9.4
2023-01-22 21:41:51,633:INFO:PyCaret optional dependencies:
2023-01-22 21:41:51,637:INFO:                shap: 0.41.0
2023-01-22 21:41:51,637:INFO:           interpret: Not installed
2023-01-22 21:41:51,637:INFO:                umap: 0.5.3
2023-01-22 21:41:51,637:INFO:    pandas_profiling: 3.6.2
2023-01-22 21:41:51,637:INFO:  explainerdashboard: Not installed
2023-01-22 21:41:51,637:INFO:             autoviz: Not installed
2023-01-22 21:41:51,637:INFO:           fairlearn: Not installed
2023-01-22 21:41:51,637:INFO:             xgboost: 1.7.3
2023-01-22 21:41:51,637:INFO:            catboost: 1.1.1
2023-01-22 21:41:51,637:INFO:              kmodes: 0.12.2
2023-01-22 21:41:51,637:INFO:             mlxtend: 0.21.0
2023-01-22 21:41:51,637:INFO:       statsforecast: Not installed
2023-01-22 21:41:51,637:INFO:        tune_sklearn: Not installed
2023-01-22 21:41:51,637:INFO:                 ray: Not installed
2023-01-22 21:41:51,637:INFO:            hyperopt: Not installed
2023-01-22 21:41:51,637:INFO:              optuna: Not installed
2023-01-22 21:41:51,637:INFO:               skopt: Not installed
2023-01-22 21:41:51,637:INFO:              mlflow: 2.1.1
2023-01-22 21:41:51,637:INFO:              gradio: Not installed
2023-01-22 21:41:51,637:INFO:             fastapi: Not installed
2023-01-22 21:41:51,637:INFO:             uvicorn: Not installed
2023-01-22 21:41:51,637:INFO:              m2cgen: Not installed
2023-01-22 21:41:51,637:INFO:           evidently: Not installed
2023-01-22 21:41:51,637:INFO:                nltk: 3.8.1
2023-01-22 21:41:51,638:INFO:            pyLDAvis: 3.3.1
2023-01-22 21:41:51,638:INFO:              gensim: 4.3.0
2023-01-22 21:41:51,638:INFO:               spacy: 3.4.4
2023-01-22 21:41:51,638:INFO:           wordcloud: 1.8.2.2
2023-01-22 21:41:51,638:INFO:            textblob: 0.17.1
2023-01-22 21:41:51,638:INFO:               fugue: Not installed
2023-01-22 21:41:51,638:INFO:           streamlit: Not installed
2023-01-22 21:41:51,638:INFO:             prophet: Not installed
2023-01-22 21:41:51,638:INFO:None
2023-01-22 21:41:51,638:INFO:Set up data.
2023-01-22 21:41:51,693:INFO:Set up train/test split.
2023-01-22 21:41:51,707:INFO:Set up index.
2023-01-22 21:41:51,708:INFO:Set up folding strategy.
2023-01-22 21:41:51,708:INFO:Assigning column types.
2023-01-22 21:41:51,713:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-01-22 21:41:51,713:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-22 21:41:51,719:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-22 21:41:51,723:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-22 21:41:51,784:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-22 21:41:51,830:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-22 21:41:51,831:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-22 21:41:52,039:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-22 21:41:52,129:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-22 21:41:52,135:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-22 21:41:52,141:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-22 21:41:52,206:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-22 21:41:52,254:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-22 21:41:52,255:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-22 21:41:52,257:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-22 21:41:52,258:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-01-22 21:41:52,262:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-22 21:41:52,268:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-22 21:41:52,335:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-22 21:41:52,380:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-22 21:41:52,380:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-22 21:41:52,383:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-22 21:41:52,388:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-22 21:41:52,392:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-22 21:41:52,453:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-22 21:41:52,498:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-22 21:41:52,498:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-22 21:41:52,501:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-22 21:41:52,502:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-01-22 21:41:52,511:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-22 21:41:52,571:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-22 21:41:52,615:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-22 21:41:52,615:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-22 21:41:52,618:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-22 21:41:52,627:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-22 21:41:52,687:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-22 21:41:52,732:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-22 21:41:52,733:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-22 21:41:52,735:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-22 21:41:52,736:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-01-22 21:41:52,804:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-22 21:41:52,850:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-22 21:41:52,850:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-22 21:41:52,853:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-22 21:41:52,921:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-22 21:41:52,967:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-22 21:41:52,968:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-22 21:41:52,970:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-22 21:41:52,971:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-01-22 21:41:53,044:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-22 21:41:53,107:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-22 21:41:53,112:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-22 21:41:53,202:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-22 21:41:53,248:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-22 21:41:53,251:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-22 21:41:53,251:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-01-22 21:41:53,365:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-22 21:41:53,368:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-22 21:41:53,487:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-22 21:41:53,489:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-22 21:41:53,490:INFO:Preparing preprocessing pipeline...
2023-01-22 21:41:53,491:INFO:Set up column name cleaning.
2023-01-22 21:41:53,491:INFO:Set up simple imputation.
2023-01-22 21:41:53,645:INFO:Finished creating preprocessing pipeline.
2023-01-22 21:41:53,652:INFO:Pipeline: Pipeline(memory=Memory(location=/var/folders/3w/xf1fzw1s1mnb4ckhfxf67vgw0000gn/T/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['MSSubClass', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '...
                                             'LowQualFinSF', 'GrLivArea',
                                             'FullBath', 'HalfBath',
                                             'BedroomAbvGr', 'KitchenAbvGr',
                                             'TotRmsAbvGrd', 'Fireplaces',
                                             'GarageCars', 'GarageArea',
                                             'WoodDeckSF', 'OpenPorchSF',
                                             'EnclosedPorch', '3SsnPorch',
                                             'ScreenPorch', 'PoolArea',
                                             'MiscVal', 'MoSold', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-01-22 21:41:53,652:INFO:Creating final display dataframe.
2023-01-22 21:41:54,237:INFO:Setup _display_container:                     Description             Value
0                    Session id              8822
1                        Target         SalePrice
2                   Target type        Regression
3           Original data shape       (1460, 180)
4        Transformed data shape       (1460, 180)
5   Transformed train set shape       (1021, 180)
6    Transformed test set shape        (439, 180)
7              Numeric features               179
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              5b0a
2023-01-22 21:41:54,380:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-22 21:41:54,383:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-22 21:41:54,518:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-22 21:41:54,522:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-22 21:41:54,523:INFO:setup() successfully completed in 2.89s...............
2023-01-22 21:43:01,036:INFO:Initializing create_model()
2023-01-22 21:43:01,037:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb0df8a95e0>, estimator=catboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-22 21:43:01,038:INFO:Checking exceptions
2023-01-22 21:43:01,125:INFO:Importing libraries
2023-01-22 21:43:01,125:INFO:Copying training dataset
2023-01-22 21:43:01,137:INFO:Defining folds
2023-01-22 21:43:01,137:INFO:Declaring metric variables
2023-01-22 21:43:01,142:INFO:Importing untrained model
2023-01-22 21:43:01,151:INFO:CatBoost Regressor Imported successfully
2023-01-22 21:43:01,159:INFO:Starting cross validation
2023-01-22 21:43:01,169:INFO:Cross validating with KFold(n_splits=10, random_state=8822, shuffle=True), n_jobs=-1
2023-01-22 21:43:27,836:INFO:Calculating mean and std
2023-01-22 21:43:27,853:INFO:Creating metrics dataframe
2023-01-22 21:43:27,893:INFO:Finalizing model
2023-01-22 21:43:30,154:INFO:Uploading results into container
2023-01-22 21:43:30,155:INFO:Uploading model into container now
2023-01-22 21:43:30,208:INFO:_master_model_container: 1
2023-01-22 21:43:30,208:INFO:_display_container: 2
2023-01-22 21:43:30,209:INFO:<catboost.core.CatBoostRegressor object at 0x7fb0c6dfcaf0>
2023-01-22 21:43:30,209:INFO:create_model() successfully completed......................................
2023-01-22 21:43:30,534:INFO:Initializing create_model()
2023-01-22 21:43:30,534:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb0df8a95e0>, estimator=br, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-22 21:43:30,534:INFO:Checking exceptions
2023-01-22 21:43:30,554:INFO:Importing libraries
2023-01-22 21:43:30,554:INFO:Copying training dataset
2023-01-22 21:43:30,563:INFO:Defining folds
2023-01-22 21:43:30,563:INFO:Declaring metric variables
2023-01-22 21:43:30,569:INFO:Importing untrained model
2023-01-22 21:43:30,574:INFO:Bayesian Ridge Imported successfully
2023-01-22 21:43:30,581:INFO:Starting cross validation
2023-01-22 21:43:30,583:INFO:Cross validating with KFold(n_splits=10, random_state=8822, shuffle=True), n_jobs=-1
2023-01-22 21:43:30,916:INFO:Calculating mean and std
2023-01-22 21:43:30,916:INFO:Creating metrics dataframe
2023-01-22 21:43:30,921:INFO:Finalizing model
2023-01-22 21:43:30,994:INFO:Uploading results into container
2023-01-22 21:43:30,995:INFO:Uploading model into container now
2023-01-22 21:43:31,010:INFO:_master_model_container: 2
2023-01-22 21:43:31,010:INFO:_display_container: 3
2023-01-22 21:43:31,011:INFO:BayesianRidge()
2023-01-22 21:43:31,011:INFO:create_model() successfully completed......................................
2023-01-22 21:43:31,248:INFO:Initializing blend_models()
2023-01-22 21:43:31,249:INFO:blend_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb0df8a95e0>, estimator_list=[<catboost.core.CatBoostRegressor object at 0x7fb0c6dfcaf0>, BayesianRidge()], fold=None, round=4, choose_better=False, optimize=R2, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-01-22 21:43:31,249:INFO:Checking exceptions
2023-01-22 21:43:31,272:INFO:Importing libraries
2023-01-22 21:43:31,272:INFO:Copying training dataset
2023-01-22 21:43:31,276:INFO:Getting model names
2023-01-22 21:43:31,280:INFO:SubProcess create_model() called ==================================
2023-01-22 21:43:31,282:INFO:Initializing create_model()
2023-01-22 21:43:31,282:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb0df8a95e0>, estimator=VotingRegressor(estimators=[('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x7fb0c6dfcaf0>),
                            ('Bayesian Ridge', BayesianRidge())],
                n_jobs=-1), fold=KFold(n_splits=10, random_state=8822, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb0c6ffd070>, model_only=True, return_train_score=False, kwargs={})
2023-01-22 21:43:31,282:INFO:Checking exceptions
2023-01-22 21:43:31,282:INFO:Importing libraries
2023-01-22 21:43:31,282:INFO:Copying training dataset
2023-01-22 21:43:31,289:INFO:Defining folds
2023-01-22 21:43:31,289:INFO:Declaring metric variables
2023-01-22 21:43:31,295:INFO:Importing untrained model
2023-01-22 21:43:31,295:INFO:Declaring custom model
2023-01-22 21:43:31,303:INFO:Voting Regressor Imported successfully
2023-01-22 21:43:31,310:INFO:Starting cross validation
2023-01-22 21:43:31,311:INFO:Cross validating with KFold(n_splits=10, random_state=8822, shuffle=True), n_jobs=-1
2023-01-22 21:43:45,404:INFO:Calculating mean and std
2023-01-22 21:43:45,406:INFO:Creating metrics dataframe
2023-01-22 21:43:45,412:INFO:Finalizing model
2023-01-22 21:43:48,308:INFO:Uploading results into container
2023-01-22 21:43:48,311:INFO:Uploading model into container now
2023-01-22 21:43:48,314:INFO:_master_model_container: 3
2023-01-22 21:43:48,314:INFO:_display_container: 4
2023-01-22 21:43:48,319:INFO:VotingRegressor(estimators=[('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x7fb0c57126d0>),
                            ('Bayesian Ridge', BayesianRidge())],
                n_jobs=-1)
2023-01-22 21:43:48,319:INFO:create_model() successfully completed......................................
2023-01-22 21:43:48,873:INFO:SubProcess create_model() end ==================================
2023-01-22 21:43:48,900:INFO:_master_model_container: 3
2023-01-22 21:43:48,900:INFO:_display_container: 4
2023-01-22 21:43:48,902:INFO:VotingRegressor(estimators=[('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x7fb0c57126d0>),
                            ('Bayesian Ridge', BayesianRidge())],
                n_jobs=-1)
2023-01-22 21:43:48,902:INFO:blend_models() successfully completed......................................
2023-01-22 21:43:53,270:INFO:Initializing finalize_model()
2023-01-22 21:43:53,271:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb0df8a95e0>, estimator=VotingRegressor(estimators=[('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x7fb0c57126d0>),
                            ('Bayesian Ridge', BayesianRidge())],
                n_jobs=-1), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-01-22 21:43:53,273:INFO:Finalizing VotingRegressor(estimators=[('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x7fb0c57126d0>),
                            ('Bayesian Ridge', BayesianRidge())],
                n_jobs=-1)
2023-01-22 21:43:53,281:INFO:Initializing create_model()
2023-01-22 21:43:53,281:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb0df8a95e0>, estimator=VotingRegressor(estimators=[('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x7fb0c57126d0>),
                            ('Bayesian Ridge', BayesianRidge())],
                n_jobs=-1), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-01-22 21:43:53,281:INFO:Checking exceptions
2023-01-22 21:43:53,283:INFO:Importing libraries
2023-01-22 21:43:53,283:INFO:Copying training dataset
2023-01-22 21:43:53,284:INFO:Defining folds
2023-01-22 21:43:53,284:INFO:Declaring metric variables
2023-01-22 21:43:53,284:INFO:Importing untrained model
2023-01-22 21:43:53,284:INFO:Declaring custom model
2023-01-22 21:43:53,286:INFO:Voting Regressor Imported successfully
2023-01-22 21:43:53,287:INFO:Cross validation set to False
2023-01-22 21:43:53,287:INFO:Fitting Model
2023-01-22 21:43:56,915:INFO:Pipeline(memory=Memory(location=/var/folders/3w/xf1fzw1s1mnb4ckhfxf67vgw0000gn/T/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['MSSubClass', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '...
                                             'ScreenPorch', 'PoolArea',
                                             'MiscVal', 'MoSold', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 VotingRegressor(estimators=[('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x7fb0c71742b0>),
                                             ('Bayesian Ridge',
                                              BayesianRidge())],
                                 n_jobs=-1))])
2023-01-22 21:43:56,915:INFO:create_model() successfully completed......................................
2023-01-22 21:43:57,095:INFO:_master_model_container: 3
2023-01-22 21:43:57,095:INFO:_display_container: 4
2023-01-22 21:43:57,113:INFO:Pipeline(memory=Memory(location=/var/folders/3w/xf1fzw1s1mnb4ckhfxf67vgw0000gn/T/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['MSSubClass', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '...
                                             'ScreenPorch', 'PoolArea',
                                             'MiscVal', 'MoSold', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 VotingRegressor(estimators=[('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x7fb0c71742b0>),
                                             ('Bayesian Ridge',
                                              BayesianRidge())],
                                 n_jobs=-1))])
2023-01-22 21:43:57,113:INFO:finalize_model() successfully completed......................................
2023-01-22 21:44:00,123:INFO:Initializing predict_model()
2023-01-22 21:44:00,124:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb0df8a95e0>, estimator=Pipeline(memory=Memory(location=/var/folders/3w/xf1fzw1s1mnb4ckhfxf67vgw0000gn/T/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['MSSubClass', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '...
                                             'ScreenPorch', 'PoolArea',
                                             'MiscVal', 'MoSold', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 VotingRegressor(estimators=[('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x7fb0c71742b0>),
                                             ('Bayesian Ridge',
                                              BayesianRidge())],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fb0c71715e0>)
2023-01-22 21:44:00,124:INFO:Checking exceptions
2023-01-22 21:44:00,124:INFO:Preloading libraries
2023-01-22 21:44:00,127:INFO:Set up data.
2023-01-22 21:44:00,261:INFO:Set up index.
2023-01-22 21:44:06,898:INFO:Initializing predict_model()
2023-01-22 21:44:06,901:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb0df8a95e0>, estimator=Pipeline(memory=Memory(location=/var/folders/3w/xf1fzw1s1mnb4ckhfxf67vgw0000gn/T/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['MSSubClass', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '...
                                             'ScreenPorch', 'PoolArea',
                                             'MiscVal', 'MoSold', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 VotingRegressor(estimators=[('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x7fb0c71742b0>),
                                             ('Bayesian Ridge',
                                              BayesianRidge())],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fb0c7171670>)
2023-01-22 21:44:06,901:INFO:Checking exceptions
2023-01-22 21:44:06,901:INFO:Preloading libraries
2023-01-22 21:44:06,903:INFO:Set up data.
2023-01-22 21:44:07,008:INFO:Set up index.
2023-01-22 21:49:10,058:INFO:Initializing predict_model()
2023-01-22 21:49:10,063:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb0df8a95e0>, estimator=Pipeline(memory=Memory(location=/var/folders/3w/xf1fzw1s1mnb4ckhfxf67vgw0000gn/T/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['MSSubClass', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '...
                                             'ScreenPorch', 'PoolArea',
                                             'MiscVal', 'MoSold', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 VotingRegressor(estimators=[('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x7fb0c71742b0>),
                                             ('Bayesian Ridge',
                                              BayesianRidge())],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fb0c6d1c3a0>)
2023-01-22 21:49:10,063:INFO:Checking exceptions
2023-01-22 21:49:10,063:INFO:Preloading libraries
2023-01-22 21:49:10,124:INFO:Set up data.
2023-01-22 21:49:10,299:INFO:Set up index.
2023-01-22 21:49:16,328:INFO:PyCaret RegressionExperiment
2023-01-22 21:49:16,328:INFO:Logging name: reg-default-name
2023-01-22 21:49:16,328:INFO:ML Usecase: MLUsecase.REGRESSION
2023-01-22 21:49:16,328:INFO:version 3.0.0.rc8
2023-01-22 21:49:16,328:INFO:Initializing setup()
2023-01-22 21:49:16,328:INFO:self.USI: 7cff
2023-01-22 21:49:16,328:INFO:self._variable_keys: {'n_jobs_param', 'logging_param', 'y', 'exp_name_log', 'exp_id', 'fold_groups_param', 'X_train', 'target_param', 'log_plots_param', 'fold_generator', 'data', 'y_test', 'gpu_n_jobs_param', 'y_train', 'gpu_param', 'transform_target_param', 'html_param', 'fold_shuffle_param', 'memory', 'idx', 'pipeline', 'USI', '_available_plots', 'seed', 'X', 'X_test', '_ml_usecase'}
2023-01-22 21:49:16,328:INFO:Checking environment
2023-01-22 21:49:16,328:INFO:python_version: 3.9.12
2023-01-22 21:49:16,328:INFO:python_build: ('main', 'Apr  5 2022 01:53:17')
2023-01-22 21:49:16,328:INFO:machine: x86_64
2023-01-22 21:49:16,328:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-01-22 21:49:16,329:INFO:Memory: svmem(total=8589934592, available=2435010560, percent=71.7, used=5530320896, free=270442496, active=2168315904, inactive=2162511872, wired=3362004992)
2023-01-22 21:49:16,329:INFO:Physical Core: 4
2023-01-22 21:49:16,329:INFO:Logical Core: 8
2023-01-22 21:49:16,329:INFO:Checking libraries
2023-01-22 21:49:16,329:INFO:System:
2023-01-22 21:49:16,329:INFO:    python: 3.9.12 (main, Apr  5 2022, 01:53:17)  [Clang 12.0.0 ]
2023-01-22 21:49:16,329:INFO:executable: /Users/hiroto/opt/anaconda3/bin/python
2023-01-22 21:49:16,329:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-01-22 21:49:16,329:INFO:PyCaret required dependencies:
2023-01-22 21:49:16,329:INFO:                 pip: 21.2.4
2023-01-22 21:49:16,329:INFO:          setuptools: 66.0.0
2023-01-22 21:49:16,329:INFO:             pycaret: 3.0.0rc8
2023-01-22 21:49:16,329:INFO:             IPython: 8.8.0
2023-01-22 21:49:16,329:INFO:          ipywidgets: 8.0.4
2023-01-22 21:49:16,329:INFO:                tqdm: 4.64.1
2023-01-22 21:49:16,329:INFO:               numpy: 1.23.5
2023-01-22 21:49:16,329:INFO:              pandas: 1.5.3
2023-01-22 21:49:16,329:INFO:              jinja2: 3.1.2
2023-01-22 21:49:16,329:INFO:               scipy: 1.10.0
2023-01-22 21:49:16,329:INFO:              joblib: 1.2.0
2023-01-22 21:49:16,329:INFO:             sklearn: 1.1.3
2023-01-22 21:49:16,329:INFO:                pyod: 1.0.7
2023-01-22 21:49:16,329:INFO:            imblearn: 0.10.1
2023-01-22 21:49:16,329:INFO:   category_encoders: 2.6.0
2023-01-22 21:49:16,329:INFO:            lightgbm: 3.3.4
2023-01-22 21:49:16,330:INFO:               numba: 0.56.4
2023-01-22 21:49:16,330:INFO:            requests: 2.28.2
2023-01-22 21:49:16,330:INFO:          matplotlib: 3.6.3
2023-01-22 21:49:16,330:INFO:          scikitplot: 0.3.7
2023-01-22 21:49:16,330:INFO:         yellowbrick: 1.5
2023-01-22 21:49:16,330:INFO:              plotly: 5.12.0
2023-01-22 21:49:16,330:INFO:             kaleido: 0.2.1
2023-01-22 21:49:16,330:INFO:         statsmodels: 0.13.5
2023-01-22 21:49:16,330:INFO:              sktime: 0.15.1
2023-01-22 21:49:16,330:INFO:               tbats: 1.1.2
2023-01-22 21:49:16,330:INFO:            pmdarima: 2.0.2
2023-01-22 21:49:16,330:INFO:              psutil: 5.9.4
2023-01-22 21:49:16,330:INFO:PyCaret optional dependencies:
2023-01-22 21:49:16,330:INFO:                shap: 0.41.0
2023-01-22 21:49:16,330:INFO:           interpret: Not installed
2023-01-22 21:49:16,330:INFO:                umap: 0.5.3
2023-01-22 21:49:16,330:INFO:    pandas_profiling: 3.6.2
2023-01-22 21:49:16,330:INFO:  explainerdashboard: Not installed
2023-01-22 21:49:16,330:INFO:             autoviz: Not installed
2023-01-22 21:49:16,330:INFO:           fairlearn: Not installed
2023-01-22 21:49:16,331:INFO:             xgboost: 1.7.3
2023-01-22 21:49:16,332:INFO:            catboost: 1.1.1
2023-01-22 21:49:16,332:INFO:              kmodes: 0.12.2
2023-01-22 21:49:16,332:INFO:             mlxtend: 0.21.0
2023-01-22 21:49:16,332:INFO:       statsforecast: Not installed
2023-01-22 21:49:16,332:INFO:        tune_sklearn: Not installed
2023-01-22 21:49:16,332:INFO:                 ray: Not installed
2023-01-22 21:49:16,332:INFO:            hyperopt: Not installed
2023-01-22 21:49:16,332:INFO:              optuna: Not installed
2023-01-22 21:49:16,334:INFO:               skopt: Not installed
2023-01-22 21:49:16,334:INFO:              mlflow: 2.1.1
2023-01-22 21:49:16,334:INFO:              gradio: Not installed
2023-01-22 21:49:16,334:INFO:             fastapi: Not installed
2023-01-22 21:49:16,334:INFO:             uvicorn: Not installed
2023-01-22 21:49:16,334:INFO:              m2cgen: Not installed
2023-01-22 21:49:16,335:INFO:           evidently: Not installed
2023-01-22 21:49:16,335:INFO:                nltk: 3.8.1
2023-01-22 21:49:16,335:INFO:            pyLDAvis: 3.3.1
2023-01-22 21:49:16,335:INFO:              gensim: 4.3.0
2023-01-22 21:49:16,335:INFO:               spacy: 3.4.4
2023-01-22 21:49:16,335:INFO:           wordcloud: 1.8.2.2
2023-01-22 21:49:16,335:INFO:            textblob: 0.17.1
2023-01-22 21:49:16,335:INFO:               fugue: Not installed
2023-01-22 21:49:16,335:INFO:           streamlit: Not installed
2023-01-22 21:49:16,335:INFO:             prophet: Not installed
2023-01-22 21:49:16,335:INFO:None
2023-01-22 21:49:16,336:INFO:Set up data.
2023-01-22 21:49:16,400:INFO:Set up train/test split.
2023-01-22 21:49:16,413:INFO:Set up index.
2023-01-22 21:49:16,414:INFO:Set up folding strategy.
2023-01-22 21:49:16,414:INFO:Assigning column types.
2023-01-22 21:49:16,421:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-01-22 21:49:16,422:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-22 21:49:16,428:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-22 21:49:16,433:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-22 21:49:16,500:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-22 21:49:16,553:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-22 21:49:16,553:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-22 21:49:16,556:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-22 21:49:16,557:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-22 21:49:16,562:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-22 21:49:16,567:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-22 21:49:16,634:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-22 21:49:16,683:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-22 21:49:16,683:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-22 21:49:16,686:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-22 21:49:16,686:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-01-22 21:49:16,691:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-22 21:49:16,696:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-22 21:49:16,762:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-22 21:49:16,809:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-22 21:49:16,810:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-22 21:49:16,813:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-22 21:49:16,819:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-22 21:49:16,824:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-22 21:49:16,893:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-22 21:49:16,939:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-22 21:49:16,940:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-22 21:49:16,942:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-22 21:49:16,943:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-01-22 21:49:16,952:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-22 21:49:17,020:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-22 21:49:17,067:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-22 21:49:17,068:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-22 21:49:17,070:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-22 21:49:17,079:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-22 21:49:17,143:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-22 21:49:17,208:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-22 21:49:17,213:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-22 21:49:17,218:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-22 21:49:17,218:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-01-22 21:49:17,300:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-22 21:49:17,346:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-22 21:49:17,347:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-22 21:49:17,350:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-22 21:49:17,419:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-22 21:49:17,465:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-22 21:49:17,466:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-22 21:49:17,468:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-22 21:49:17,469:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-01-22 21:49:17,539:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-22 21:49:17,585:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-22 21:49:17,587:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-22 21:49:17,656:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-22 21:49:17,702:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-22 21:49:17,705:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-22 21:49:17,705:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-01-22 21:49:17,821:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-22 21:49:17,823:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-22 21:49:17,941:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-22 21:49:17,944:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-22 21:49:17,945:INFO:Preparing preprocessing pipeline...
2023-01-22 21:49:17,946:INFO:Set up column name cleaning.
2023-01-22 21:49:17,946:INFO:Set up simple imputation.
2023-01-22 21:49:18,071:INFO:Finished creating preprocessing pipeline.
2023-01-22 21:49:18,077:INFO:Pipeline: Pipeline(memory=Memory(location=/var/folders/3w/xf1fzw1s1mnb4ckhfxf67vgw0000gn/T/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['MSSubClass', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '...
                                             'LowQualFinSF', 'GrLivArea',
                                             'FullBath', 'HalfBath',
                                             'BedroomAbvGr', 'KitchenAbvGr',
                                             'TotRmsAbvGrd', 'Fireplaces',
                                             'GarageCars', 'GarageArea',
                                             'WoodDeckSF', 'OpenPorchSF',
                                             'EnclosedPorch', '3SsnPorch',
                                             'ScreenPorch', 'PoolArea',
                                             'MiscVal', 'MoSold', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-01-22 21:49:18,077:INFO:Creating final display dataframe.
2023-01-22 21:49:18,613:INFO:Setup _display_container:                     Description             Value
0                    Session id              8675
1                        Target         SalePrice
2                   Target type        Regression
3           Original data shape       (1460, 180)
4        Transformed data shape       (1460, 180)
5   Transformed train set shape       (1021, 180)
6    Transformed test set shape        (439, 180)
7              Numeric features               179
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              7cff
2023-01-22 21:49:18,755:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-22 21:49:18,758:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-22 21:49:18,876:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-22 21:49:18,879:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-22 21:49:18,881:INFO:setup() successfully completed in 2.56s...............
2023-01-22 21:49:18,882:INFO:Initializing create_model()
2023-01-22 21:49:18,882:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb0c6bdb220>, estimator=catboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-22 21:49:18,882:INFO:Checking exceptions
2023-01-22 21:49:18,900:INFO:Importing libraries
2023-01-22 21:49:18,900:INFO:Copying training dataset
2023-01-22 21:49:18,910:INFO:Defining folds
2023-01-22 21:49:18,910:INFO:Declaring metric variables
2023-01-22 21:49:18,914:INFO:Importing untrained model
2023-01-22 21:49:18,919:INFO:CatBoost Regressor Imported successfully
2023-01-22 21:49:18,929:INFO:Starting cross validation
2023-01-22 21:49:18,931:INFO:Cross validating with KFold(n_splits=10, random_state=8675, shuffle=True), n_jobs=-1
2023-01-22 21:49:42,537:INFO:Calculating mean and std
2023-01-22 21:49:42,546:INFO:Creating metrics dataframe
2023-01-22 21:49:42,563:INFO:Finalizing model
2023-01-22 21:49:44,725:INFO:Uploading results into container
2023-01-22 21:49:44,727:INFO:Uploading model into container now
2023-01-22 21:49:44,741:INFO:_master_model_container: 1
2023-01-22 21:49:44,741:INFO:_display_container: 2
2023-01-22 21:49:44,741:INFO:<catboost.core.CatBoostRegressor object at 0x7fb0c773b550>
2023-01-22 21:49:44,741:INFO:create_model() successfully completed......................................
2023-01-22 21:49:44,963:INFO:Initializing create_model()
2023-01-22 21:49:44,963:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb0c6bdb220>, estimator=br, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-22 21:49:44,963:INFO:Checking exceptions
2023-01-22 21:49:44,984:INFO:Importing libraries
2023-01-22 21:49:44,985:INFO:Copying training dataset
2023-01-22 21:49:44,998:INFO:Defining folds
2023-01-22 21:49:44,998:INFO:Declaring metric variables
2023-01-22 21:49:45,007:INFO:Importing untrained model
2023-01-22 21:49:45,012:INFO:Bayesian Ridge Imported successfully
2023-01-22 21:49:45,019:INFO:Starting cross validation
2023-01-22 21:49:45,021:INFO:Cross validating with KFold(n_splits=10, random_state=8675, shuffle=True), n_jobs=-1
2023-01-22 21:49:45,330:INFO:Calculating mean and std
2023-01-22 21:49:45,330:INFO:Creating metrics dataframe
2023-01-22 21:49:45,335:INFO:Finalizing model
2023-01-22 21:49:45,404:INFO:Uploading results into container
2023-01-22 21:49:45,405:INFO:Uploading model into container now
2023-01-22 21:49:45,418:INFO:_master_model_container: 2
2023-01-22 21:49:45,419:INFO:_display_container: 3
2023-01-22 21:49:45,419:INFO:BayesianRidge()
2023-01-22 21:49:45,419:INFO:create_model() successfully completed......................................
2023-01-22 21:49:45,586:INFO:Initializing blend_models()
2023-01-22 21:49:45,586:INFO:blend_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb0c6bdb220>, estimator_list=[<catboost.core.CatBoostRegressor object at 0x7fb0c773b550>, BayesianRidge()], fold=None, round=4, choose_better=False, optimize=R2, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-01-22 21:49:45,586:INFO:Checking exceptions
2023-01-22 21:49:45,609:INFO:Importing libraries
2023-01-22 21:49:45,609:INFO:Copying training dataset
2023-01-22 21:49:45,614:INFO:Getting model names
2023-01-22 21:49:45,620:INFO:SubProcess create_model() called ==================================
2023-01-22 21:49:45,622:INFO:Initializing create_model()
2023-01-22 21:49:45,622:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb0c6bdb220>, estimator=VotingRegressor(estimators=[('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x7fb0c773b550>),
                            ('Bayesian Ridge', BayesianRidge())],
                n_jobs=-1), fold=KFold(n_splits=10, random_state=8675, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb0df8101f0>, model_only=True, return_train_score=False, kwargs={})
2023-01-22 21:49:45,622:INFO:Checking exceptions
2023-01-22 21:49:45,622:INFO:Importing libraries
2023-01-22 21:49:45,622:INFO:Copying training dataset
2023-01-22 21:49:45,630:INFO:Defining folds
2023-01-22 21:49:45,630:INFO:Declaring metric variables
2023-01-22 21:49:45,636:INFO:Importing untrained model
2023-01-22 21:49:45,636:INFO:Declaring custom model
2023-01-22 21:49:45,641:INFO:Voting Regressor Imported successfully
2023-01-22 21:49:45,649:INFO:Starting cross validation
2023-01-22 21:49:45,651:INFO:Cross validating with KFold(n_splits=10, random_state=8675, shuffle=True), n_jobs=-1
2023-01-22 21:50:00,296:INFO:Calculating mean and std
2023-01-22 21:50:00,297:INFO:Creating metrics dataframe
2023-01-22 21:50:00,305:INFO:Finalizing model
2023-01-22 21:50:02,624:INFO:Uploading results into container
2023-01-22 21:50:02,625:INFO:Uploading model into container now
2023-01-22 21:50:02,626:INFO:_master_model_container: 3
2023-01-22 21:50:02,627:INFO:_display_container: 4
2023-01-22 21:50:02,629:INFO:VotingRegressor(estimators=[('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x7fb0c6ba7d60>),
                            ('Bayesian Ridge', BayesianRidge())],
                n_jobs=-1)
2023-01-22 21:50:02,629:INFO:create_model() successfully completed......................................
2023-01-22 21:50:02,825:INFO:SubProcess create_model() end ==================================
2023-01-22 21:50:02,840:INFO:_master_model_container: 3
2023-01-22 21:50:02,840:INFO:_display_container: 4
2023-01-22 21:50:02,842:INFO:VotingRegressor(estimators=[('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x7fb0c6ba7d60>),
                            ('Bayesian Ridge', BayesianRidge())],
                n_jobs=-1)
2023-01-22 21:50:02,842:INFO:blend_models() successfully completed......................................
2023-01-22 21:50:03,011:INFO:Initializing finalize_model()
2023-01-22 21:50:03,011:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb0c6bdb220>, estimator=VotingRegressor(estimators=[('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x7fb0c6ba7d60>),
                            ('Bayesian Ridge', BayesianRidge())],
                n_jobs=-1), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-01-22 21:50:03,013:INFO:Finalizing VotingRegressor(estimators=[('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x7fb0c6ba7d60>),
                            ('Bayesian Ridge', BayesianRidge())],
                n_jobs=-1)
2023-01-22 21:50:03,026:INFO:Initializing create_model()
2023-01-22 21:50:03,027:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb0c6bdb220>, estimator=VotingRegressor(estimators=[('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x7fb0c6ba7d60>),
                            ('Bayesian Ridge', BayesianRidge())],
                n_jobs=-1), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-01-22 21:50:03,027:INFO:Checking exceptions
2023-01-22 21:50:03,029:INFO:Importing libraries
2023-01-22 21:50:03,029:INFO:Copying training dataset
2023-01-22 21:50:03,029:INFO:Defining folds
2023-01-22 21:50:03,029:INFO:Declaring metric variables
2023-01-22 21:50:03,029:INFO:Importing untrained model
2023-01-22 21:50:03,029:INFO:Declaring custom model
2023-01-22 21:50:03,030:INFO:Voting Regressor Imported successfully
2023-01-22 21:50:03,032:INFO:Cross validation set to False
2023-01-22 21:50:03,032:INFO:Fitting Model
2023-01-22 21:50:05,685:INFO:Pipeline(memory=Memory(location=/var/folders/3w/xf1fzw1s1mnb4ckhfxf67vgw0000gn/T/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['MSSubClass', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '...
                                             'ScreenPorch', 'PoolArea',
                                             'MiscVal', 'MoSold', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 VotingRegressor(estimators=[('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x7fb0c773bc70>),
                                             ('Bayesian Ridge',
                                              BayesianRidge())],
                                 n_jobs=-1))])
2023-01-22 21:50:05,685:INFO:create_model() successfully completed......................................
2023-01-22 21:50:05,849:INFO:_master_model_container: 3
2023-01-22 21:50:05,849:INFO:_display_container: 4
2023-01-22 21:50:05,863:INFO:Pipeline(memory=Memory(location=/var/folders/3w/xf1fzw1s1mnb4ckhfxf67vgw0000gn/T/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['MSSubClass', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '...
                                             'ScreenPorch', 'PoolArea',
                                             'MiscVal', 'MoSold', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 VotingRegressor(estimators=[('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x7fb0c773bc70>),
                                             ('Bayesian Ridge',
                                              BayesianRidge())],
                                 n_jobs=-1))])
2023-01-22 21:50:05,864:INFO:finalize_model() successfully completed......................................
2023-01-23 01:57:26,013:INFO:PyCaret RegressionExperiment
2023-01-23 01:57:26,015:INFO:Logging name: reg-default-name
2023-01-23 01:57:26,017:INFO:ML Usecase: MLUsecase.REGRESSION
2023-01-23 01:57:26,017:INFO:version 3.0.0.rc8
2023-01-23 01:57:26,017:INFO:Initializing setup()
2023-01-23 01:57:26,017:INFO:self.USI: 62cb
2023-01-23 01:57:26,019:INFO:self._variable_keys: {'n_jobs_param', 'logging_param', 'y', 'exp_name_log', 'exp_id', 'fold_groups_param', 'X_train', 'target_param', 'log_plots_param', 'fold_generator', 'data', 'y_test', 'gpu_n_jobs_param', 'y_train', 'gpu_param', 'transform_target_param', 'html_param', 'fold_shuffle_param', 'memory', 'idx', 'pipeline', 'USI', '_available_plots', 'seed', 'X', 'X_test', '_ml_usecase'}
2023-01-23 01:57:26,019:INFO:Checking environment
2023-01-23 01:57:26,021:INFO:python_version: 3.9.12
2023-01-23 01:57:26,021:INFO:python_build: ('main', 'Apr  5 2022 01:53:17')
2023-01-23 01:57:26,023:INFO:machine: x86_64
2023-01-23 01:57:26,025:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-01-23 01:57:26,036:INFO:Memory: svmem(total=8589934592, available=2320343040, percent=73.0, used=5296177152, free=598425600, active=1724596224, inactive=1717719040, wired=3571580928)
2023-01-23 01:57:26,039:INFO:Physical Core: 4
2023-01-23 01:57:26,040:INFO:Logical Core: 8
2023-01-23 01:57:26,040:INFO:Checking libraries
2023-01-23 01:57:26,041:INFO:System:
2023-01-23 01:57:26,042:INFO:    python: 3.9.12 (main, Apr  5 2022, 01:53:17)  [Clang 12.0.0 ]
2023-01-23 01:57:26,042:INFO:executable: /Users/hiroto/opt/anaconda3/bin/python
2023-01-23 01:57:26,042:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-01-23 01:57:26,042:INFO:PyCaret required dependencies:
2023-01-23 01:57:26,046:INFO:                 pip: 21.2.4
2023-01-23 01:57:26,047:INFO:          setuptools: 66.0.0
2023-01-23 01:57:26,047:INFO:             pycaret: 3.0.0rc8
2023-01-23 01:57:26,047:INFO:             IPython: 8.8.0
2023-01-23 01:57:26,047:INFO:          ipywidgets: 8.0.4
2023-01-23 01:57:26,047:INFO:                tqdm: 4.64.1
2023-01-23 01:57:26,047:INFO:               numpy: 1.23.5
2023-01-23 01:57:26,047:INFO:              pandas: 1.5.3
2023-01-23 01:57:26,047:INFO:              jinja2: 3.1.2
2023-01-23 01:57:26,047:INFO:               scipy: 1.10.0
2023-01-23 01:57:26,047:INFO:              joblib: 1.2.0
2023-01-23 01:57:26,047:INFO:             sklearn: 1.1.3
2023-01-23 01:57:26,047:INFO:                pyod: 1.0.7
2023-01-23 01:57:26,047:INFO:            imblearn: 0.10.1
2023-01-23 01:57:26,047:INFO:   category_encoders: 2.6.0
2023-01-23 01:57:26,047:INFO:            lightgbm: 3.3.4
2023-01-23 01:57:26,047:INFO:               numba: 0.56.4
2023-01-23 01:57:26,047:INFO:            requests: 2.28.2
2023-01-23 01:57:26,047:INFO:          matplotlib: 3.6.3
2023-01-23 01:57:26,048:INFO:          scikitplot: 0.3.7
2023-01-23 01:57:26,048:INFO:         yellowbrick: 1.5
2023-01-23 01:57:26,048:INFO:              plotly: 5.12.0
2023-01-23 01:57:26,048:INFO:             kaleido: 0.2.1
2023-01-23 01:57:26,048:INFO:         statsmodels: 0.13.5
2023-01-23 01:57:26,048:INFO:              sktime: 0.15.1
2023-01-23 01:57:26,048:INFO:               tbats: 1.1.2
2023-01-23 01:57:26,048:INFO:            pmdarima: 2.0.2
2023-01-23 01:57:26,048:INFO:              psutil: 5.9.4
2023-01-23 01:57:26,048:INFO:PyCaret optional dependencies:
2023-01-23 01:57:26,048:INFO:                shap: 0.41.0
2023-01-23 01:57:26,048:INFO:           interpret: Not installed
2023-01-23 01:57:26,048:INFO:                umap: 0.5.3
2023-01-23 01:57:26,048:INFO:    pandas_profiling: 3.6.2
2023-01-23 01:57:26,048:INFO:  explainerdashboard: Not installed
2023-01-23 01:57:26,048:INFO:             autoviz: Not installed
2023-01-23 01:57:26,048:INFO:           fairlearn: Not installed
2023-01-23 01:57:26,048:INFO:             xgboost: 1.7.3
2023-01-23 01:57:26,049:INFO:            catboost: 1.1.1
2023-01-23 01:57:26,049:INFO:              kmodes: 0.12.2
2023-01-23 01:57:26,049:INFO:             mlxtend: 0.21.0
2023-01-23 01:57:26,049:INFO:       statsforecast: Not installed
2023-01-23 01:57:26,049:INFO:        tune_sklearn: Not installed
2023-01-23 01:57:26,049:INFO:                 ray: Not installed
2023-01-23 01:57:26,049:INFO:            hyperopt: Not installed
2023-01-23 01:57:26,049:INFO:              optuna: Not installed
2023-01-23 01:57:26,049:INFO:               skopt: Not installed
2023-01-23 01:57:26,049:INFO:              mlflow: 2.1.1
2023-01-23 01:57:26,049:INFO:              gradio: Not installed
2023-01-23 01:57:26,049:INFO:             fastapi: Not installed
2023-01-23 01:57:26,049:INFO:             uvicorn: Not installed
2023-01-23 01:57:26,049:INFO:              m2cgen: Not installed
2023-01-23 01:57:26,049:INFO:           evidently: Not installed
2023-01-23 01:57:26,049:INFO:                nltk: 3.8.1
2023-01-23 01:57:26,049:INFO:            pyLDAvis: 3.3.1
2023-01-23 01:57:26,049:INFO:              gensim: 4.3.0
2023-01-23 01:57:26,049:INFO:               spacy: 3.4.4
2023-01-23 01:57:26,049:INFO:           wordcloud: 1.8.2.2
2023-01-23 01:57:26,049:INFO:            textblob: 0.17.1
2023-01-23 01:57:26,050:INFO:               fugue: Not installed
2023-01-23 01:57:26,050:INFO:           streamlit: Not installed
2023-01-23 01:57:26,050:INFO:             prophet: Not installed
2023-01-23 01:57:26,050:INFO:None
2023-01-23 01:57:26,051:INFO:Set up data.
2023-01-23 01:57:26,188:INFO:Set up train/test split.
2023-01-23 01:57:26,253:INFO:Set up index.
2023-01-23 01:57:26,257:INFO:Set up folding strategy.
2023-01-23 01:57:26,261:INFO:Assigning column types.
2023-01-23 01:57:26,271:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-01-23 01:57:26,292:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-23 01:57:26,306:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-23 01:57:26,313:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-23 01:57:26,385:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-23 01:57:26,436:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-23 01:57:26,450:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-23 01:57:26,467:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-23 01:57:26,472:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2023-01-23 01:57:26,478:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-23 01:57:26,484:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-23 01:57:26,547:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-23 01:57:26,593:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-23 01:57:26,594:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-23 01:57:26,596:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-23 01:57:26,597:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2023-01-23 01:57:26,602:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-23 01:57:26,606:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-23 01:57:26,694:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-23 01:57:26,752:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-23 01:57:26,752:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-23 01:57:26,755:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-23 01:57:26,760:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2023-01-23 01:57:26,765:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-23 01:57:26,826:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-23 01:57:26,872:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-23 01:57:26,873:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-23 01:57:26,875:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-23 01:57:26,876:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2023-01-23 01:57:26,885:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-23 01:57:26,944:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-23 01:57:26,990:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-23 01:57:26,991:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-23 01:57:26,994:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-23 01:57:27,004:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2023-01-23 01:57:27,065:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-23 01:57:27,109:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-23 01:57:27,110:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-23 01:57:27,112:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-23 01:57:27,113:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2023-01-23 01:57:27,194:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-23 01:57:27,239:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-23 01:57:27,239:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-23 01:57:27,242:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-23 01:57:27,310:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-23 01:57:27,355:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-01-23 01:57:27,355:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-23 01:57:27,358:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-23 01:57:27,359:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-01-23 01:57:27,433:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-23 01:57:27,485:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-23 01:57:27,488:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-23 01:57:27,556:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2023-01-23 01:57:27,601:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-23 01:57:27,604:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-23 01:57:27,604:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2023-01-23 01:57:27,721:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-23 01:57:27,724:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-23 01:57:27,845:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-23 01:57:27,847:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-23 01:57:27,919:INFO:Preparing preprocessing pipeline...
2023-01-23 01:57:27,925:INFO:Set up column name cleaning.
2023-01-23 01:57:27,949:INFO:Set up simple imputation.
2023-01-23 01:57:28,594:INFO:Finished creating preprocessing pipeline.
2023-01-23 01:57:28,607:INFO:Pipeline: Pipeline(memory=Memory(location=/var/folders/3w/xf1fzw1s1mnb4ckhfxf67vgw0000gn/T/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['MSSubClass', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '...
                                             'LowQualFinSF', 'GrLivArea',
                                             'FullBath', 'HalfBath',
                                             'BedroomAbvGr', 'KitchenAbvGr',
                                             'TotRmsAbvGrd', 'Fireplaces',
                                             'GarageCars', 'GarageArea',
                                             'WoodDeckSF', 'OpenPorchSF',
                                             'EnclosedPorch', '3SsnPorch',
                                             'ScreenPorch', 'PoolArea',
                                             'MiscVal', 'MoSold', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2023-01-23 01:57:28,607:INFO:Creating final display dataframe.
2023-01-23 01:57:29,275:INFO:Setup _display_container:                     Description             Value
0                    Session id              4253
1                        Target         SalePrice
2                   Target type        Regression
3           Original data shape       (1460, 180)
4        Transformed data shape       (1460, 180)
5   Transformed train set shape       (1021, 180)
6    Transformed test set shape        (439, 180)
7              Numeric features               179
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              62cb
2023-01-23 01:57:29,548:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-23 01:57:29,551:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-23 01:57:29,670:INFO:Soft dependency imported: xgboost: 1.7.3
2023-01-23 01:57:29,672:INFO:Soft dependency imported: catboost: 1.1.1
2023-01-23 01:57:29,693:INFO:setup() successfully completed in 3.87s...............
2023-01-23 01:57:29,877:INFO:Initializing create_model()
2023-01-23 01:57:29,877:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb0c8ad8730>, estimator=catboost, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-23 01:57:29,877:INFO:Checking exceptions
2023-01-23 01:57:30,127:INFO:Importing libraries
2023-01-23 01:57:30,128:INFO:Copying training dataset
2023-01-23 01:57:30,225:INFO:Defining folds
2023-01-23 01:57:30,225:INFO:Declaring metric variables
2023-01-23 01:57:30,232:INFO:Importing untrained model
2023-01-23 01:57:30,317:INFO:CatBoost Regressor Imported successfully
2023-01-23 01:57:30,343:INFO:Starting cross validation
2023-01-23 01:57:30,359:INFO:Cross validating with KFold(n_splits=10, random_state=4253, shuffle=True), n_jobs=-1
2023-01-23 01:58:04,697:INFO:Calculating mean and std
2023-01-23 01:58:04,709:INFO:Creating metrics dataframe
2023-01-23 01:58:04,728:INFO:Finalizing model
2023-01-23 01:58:06,836:INFO:Uploading results into container
2023-01-23 01:58:06,840:INFO:Uploading model into container now
2023-01-23 01:58:06,864:INFO:_master_model_container: 1
2023-01-23 01:58:06,864:INFO:_display_container: 2
2023-01-23 01:58:06,864:INFO:<catboost.core.CatBoostRegressor object at 0x7fb0c56f8b20>
2023-01-23 01:58:06,865:INFO:create_model() successfully completed......................................
2023-01-23 01:58:09,388:INFO:Initializing create_model()
2023-01-23 01:58:09,388:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb0c8ad8730>, estimator=br, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-01-23 01:58:09,388:INFO:Checking exceptions
2023-01-23 01:58:09,406:INFO:Importing libraries
2023-01-23 01:58:09,407:INFO:Copying training dataset
2023-01-23 01:58:09,417:INFO:Defining folds
2023-01-23 01:58:09,417:INFO:Declaring metric variables
2023-01-23 01:58:09,420:INFO:Importing untrained model
2023-01-23 01:58:09,425:INFO:Bayesian Ridge Imported successfully
2023-01-23 01:58:09,433:INFO:Starting cross validation
2023-01-23 01:58:09,435:INFO:Cross validating with KFold(n_splits=10, random_state=4253, shuffle=True), n_jobs=-1
2023-01-23 01:58:09,743:INFO:Calculating mean and std
2023-01-23 01:58:09,743:INFO:Creating metrics dataframe
2023-01-23 01:58:09,748:INFO:Finalizing model
2023-01-23 01:58:09,831:INFO:Uploading results into container
2023-01-23 01:58:09,832:INFO:Uploading model into container now
2023-01-23 01:58:09,847:INFO:_master_model_container: 2
2023-01-23 01:58:09,847:INFO:_display_container: 3
2023-01-23 01:58:09,848:INFO:BayesianRidge()
2023-01-23 01:58:09,848:INFO:create_model() successfully completed......................................
2023-01-23 01:58:10,034:INFO:Initializing blend_models()
2023-01-23 01:58:10,034:INFO:blend_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb0c8ad8730>, estimator_list=[<catboost.core.CatBoostRegressor object at 0x7fb0c56f8b20>, BayesianRidge()], fold=None, round=4, choose_better=False, optimize=R2, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-01-23 01:58:10,034:INFO:Checking exceptions
2023-01-23 01:58:10,059:INFO:Importing libraries
2023-01-23 01:58:10,059:INFO:Copying training dataset
2023-01-23 01:58:10,063:INFO:Getting model names
2023-01-23 01:58:10,067:INFO:SubProcess create_model() called ==================================
2023-01-23 01:58:10,068:INFO:Initializing create_model()
2023-01-23 01:58:10,068:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb0c8ad8730>, estimator=VotingRegressor(estimators=[('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x7fb0c56f8b20>),
                            ('Bayesian Ridge', BayesianRidge())],
                n_jobs=-1), fold=KFold(n_splits=10, random_state=4253, shuffle=True), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb0df26daf0>, model_only=True, return_train_score=False, kwargs={})
2023-01-23 01:58:10,068:INFO:Checking exceptions
2023-01-23 01:58:10,069:INFO:Importing libraries
2023-01-23 01:58:10,069:INFO:Copying training dataset
2023-01-23 01:58:10,076:INFO:Defining folds
2023-01-23 01:58:10,076:INFO:Declaring metric variables
2023-01-23 01:58:10,080:INFO:Importing untrained model
2023-01-23 01:58:10,080:INFO:Declaring custom model
2023-01-23 01:58:10,085:INFO:Voting Regressor Imported successfully
2023-01-23 01:58:10,093:INFO:Starting cross validation
2023-01-23 01:58:10,095:INFO:Cross validating with KFold(n_splits=10, random_state=4253, shuffle=True), n_jobs=-1
2023-01-23 01:58:22,080:INFO:Calculating mean and std
2023-01-23 01:58:22,082:INFO:Creating metrics dataframe
2023-01-23 01:58:22,088:INFO:Finalizing model
2023-01-23 01:58:24,134:INFO:Uploading results into container
2023-01-23 01:58:24,136:INFO:Uploading model into container now
2023-01-23 01:58:24,137:INFO:_master_model_container: 3
2023-01-23 01:58:24,137:INFO:_display_container: 4
2023-01-23 01:58:24,139:INFO:VotingRegressor(estimators=[('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x7fb0c835f7c0>),
                            ('Bayesian Ridge', BayesianRidge())],
                n_jobs=-1)
2023-01-23 01:58:24,139:INFO:create_model() successfully completed......................................
2023-01-23 01:58:24,314:INFO:SubProcess create_model() end ==================================
2023-01-23 01:58:24,328:INFO:_master_model_container: 3
2023-01-23 01:58:24,329:INFO:_display_container: 4
2023-01-23 01:58:24,331:INFO:VotingRegressor(estimators=[('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x7fb0c835f7c0>),
                            ('Bayesian Ridge', BayesianRidge())],
                n_jobs=-1)
2023-01-23 01:58:24,331:INFO:blend_models() successfully completed......................................
2023-01-23 01:58:24,511:INFO:Initializing finalize_model()
2023-01-23 01:58:24,512:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb0c8ad8730>, estimator=VotingRegressor(estimators=[('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x7fb0c835f7c0>),
                            ('Bayesian Ridge', BayesianRidge())],
                n_jobs=-1), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-01-23 01:58:24,513:INFO:Finalizing VotingRegressor(estimators=[('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x7fb0c835f7c0>),
                            ('Bayesian Ridge', BayesianRidge())],
                n_jobs=-1)
2023-01-23 01:58:24,528:INFO:Initializing create_model()
2023-01-23 01:58:24,528:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb0c8ad8730>, estimator=VotingRegressor(estimators=[('CatBoost Regressor',
                             <catboost.core.CatBoostRegressor object at 0x7fb0c835f7c0>),
                            ('Bayesian Ridge', BayesianRidge())],
                n_jobs=-1), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-01-23 01:58:24,528:INFO:Checking exceptions
2023-01-23 01:58:24,530:INFO:Importing libraries
2023-01-23 01:58:24,530:INFO:Copying training dataset
2023-01-23 01:58:24,530:INFO:Defining folds
2023-01-23 01:58:24,531:INFO:Declaring metric variables
2023-01-23 01:58:24,531:INFO:Importing untrained model
2023-01-23 01:58:24,531:INFO:Declaring custom model
2023-01-23 01:58:24,532:INFO:Voting Regressor Imported successfully
2023-01-23 01:58:24,534:INFO:Cross validation set to False
2023-01-23 01:58:24,534:INFO:Fitting Model
2023-01-23 01:58:26,738:INFO:Pipeline(memory=Memory(location=/var/folders/3w/xf1fzw1s1mnb4ckhfxf67vgw0000gn/T/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['MSSubClass', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '...
                                             'ScreenPorch', 'PoolArea',
                                             'MiscVal', 'MoSold', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 VotingRegressor(estimators=[('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x7fb0c6cc33a0>),
                                             ('Bayesian Ridge',
                                              BayesianRidge())],
                                 n_jobs=-1))])
2023-01-23 01:58:26,738:INFO:create_model() successfully completed......................................
2023-01-23 01:58:26,910:INFO:_master_model_container: 3
2023-01-23 01:58:26,911:INFO:_display_container: 4
2023-01-23 01:58:26,923:INFO:Pipeline(memory=Memory(location=/var/folders/3w/xf1fzw1s1mnb4ckhfxf67vgw0000gn/T/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['MSSubClass', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '...
                                             'ScreenPorch', 'PoolArea',
                                             'MiscVal', 'MoSold', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 VotingRegressor(estimators=[('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x7fb0c6cc33a0>),
                                             ('Bayesian Ridge',
                                              BayesianRidge())],
                                 n_jobs=-1))])
2023-01-23 01:58:26,923:INFO:finalize_model() successfully completed......................................
2023-01-23 02:01:10,597:INFO:Initializing predict_model()
2023-01-23 02:01:10,599:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb0c8ad8730>, estimator=Pipeline(memory=Memory(location=/var/folders/3w/xf1fzw1s1mnb4ckhfxf67vgw0000gn/T/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['MSSubClass', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '...
                                             'ScreenPorch', 'PoolArea',
                                             'MiscVal', 'MoSold', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 VotingRegressor(estimators=[('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x7fb0c6cc33a0>),
                                             ('Bayesian Ridge',
                                              BayesianRidge())],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fb0c82bec10>)
2023-01-23 02:01:10,599:INFO:Checking exceptions
2023-01-23 02:01:10,599:INFO:Preloading libraries
2023-01-23 02:01:10,609:INFO:Set up data.
2023-01-23 02:01:10,698:INFO:Set up index.
2023-01-23 02:13:48,881:INFO:Initializing predict_model()
2023-01-23 02:13:48,886:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb0c8ad8730>, estimator=Pipeline(memory=Memory(location=/var/folders/3w/xf1fzw1s1mnb4ckhfxf67vgw0000gn/T/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['MSSubClass', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '...
                                             'ScreenPorch', 'PoolArea',
                                             'MiscVal', 'MoSold', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 VotingRegressor(estimators=[('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x7fb0c6cc33a0>),
                                             ('Bayesian Ridge',
                                              BayesianRidge())],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fb0c82bec10>)
2023-01-23 02:13:48,886:INFO:Checking exceptions
2023-01-23 02:13:48,886:INFO:Preloading libraries
2023-01-23 02:13:48,973:INFO:Set up data.
2023-01-23 02:13:49,328:INFO:Set up index.
2023-01-23 02:14:00,527:INFO:Initializing predict_model()
2023-01-23 02:14:00,528:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb0c8ad8730>, estimator=Pipeline(memory=Memory(location=/var/folders/3w/xf1fzw1s1mnb4ckhfxf67vgw0000gn/T/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['MSSubClass', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '...
                                             'ScreenPorch', 'PoolArea',
                                             'MiscVal', 'MoSold', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 VotingRegressor(estimators=[('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x7fb0c6cc33a0>),
                                             ('Bayesian Ridge',
                                              BayesianRidge())],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fb0c6c77310>)
2023-01-23 02:14:00,528:INFO:Checking exceptions
2023-01-23 02:14:00,528:INFO:Preloading libraries
2023-01-23 02:14:00,530:INFO:Set up data.
2023-01-23 02:14:00,585:INFO:Set up index.
2023-01-23 02:16:18,304:INFO:Initializing predict_model()
2023-01-23 02:16:18,305:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb0c8ad8730>, estimator=Pipeline(memory=Memory(location=/var/folders/3w/xf1fzw1s1mnb4ckhfxf67vgw0000gn/T/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['MSSubClass', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '...
                                             'ScreenPorch', 'PoolArea',
                                             'MiscVal', 'MoSold', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 VotingRegressor(estimators=[('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x7fb0c6cc33a0>),
                                             ('Bayesian Ridge',
                                              BayesianRidge())],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fb0c70f9ca0>)
2023-01-23 02:16:18,305:INFO:Checking exceptions
2023-01-23 02:16:18,305:INFO:Preloading libraries
2023-01-23 02:16:18,400:INFO:Set up data.
2023-01-23 02:16:18,556:INFO:Set up index.
2023-01-23 02:19:11,622:INFO:Initializing predict_model()
2023-01-23 02:19:11,623:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb0c8ad8730>, estimator=Pipeline(memory=Memory(location=/var/folders/3w/xf1fzw1s1mnb4ckhfxf67vgw0000gn/T/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['MSSubClass', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '...
                                             'ScreenPorch', 'PoolArea',
                                             'MiscVal', 'MoSold', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 VotingRegressor(estimators=[('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x7fb0c6cc33a0>),
                                             ('Bayesian Ridge',
                                              BayesianRidge())],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fb0c6bfaca0>)
2023-01-23 02:19:11,623:INFO:Checking exceptions
2023-01-23 02:19:11,623:INFO:Preloading libraries
2023-01-23 02:19:11,626:INFO:Set up data.
2023-01-23 02:19:11,684:INFO:Set up index.
2023-01-23 02:20:35,781:INFO:Initializing predict_model()
2023-01-23 02:20:35,781:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb0c8ad8730>, estimator=Pipeline(memory=Memory(location=/var/folders/3w/xf1fzw1s1mnb4ckhfxf67vgw0000gn/T/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['MSSubClass', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '...
                                             'ScreenPorch', 'PoolArea',
                                             'MiscVal', 'MoSold', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 VotingRegressor(estimators=[('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x7fb0c6cc33a0>),
                                             ('Bayesian Ridge',
                                              BayesianRidge())],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fb0c82bec10>)
2023-01-23 02:20:35,782:INFO:Checking exceptions
2023-01-23 02:20:35,782:INFO:Preloading libraries
2023-01-23 02:20:35,799:INFO:Set up data.
2023-01-23 02:20:35,888:INFO:Set up index.
2023-01-23 02:21:16,124:INFO:Initializing predict_model()
2023-01-23 02:21:16,125:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb0c8ad8730>, estimator=Pipeline(memory=Memory(location=/var/folders/3w/xf1fzw1s1mnb4ckhfxf67vgw0000gn/T/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['MSSubClass', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '...
                                             'ScreenPorch', 'PoolArea',
                                             'MiscVal', 'MoSold', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 VotingRegressor(estimators=[('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x7fb0c6cc33a0>),
                                             ('Bayesian Ridge',
                                              BayesianRidge())],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fb0c9e4f670>)
2023-01-23 02:21:16,125:INFO:Checking exceptions
2023-01-23 02:21:16,125:INFO:Preloading libraries
2023-01-23 02:21:16,127:INFO:Set up data.
2023-01-23 02:21:16,178:INFO:Set up index.
2023-01-23 02:22:47,880:INFO:Initializing predict_model()
2023-01-23 02:22:47,881:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb0c8ad8730>, estimator=Pipeline(memory=Memory(location=/var/folders/3w/xf1fzw1s1mnb4ckhfxf67vgw0000gn/T/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['MSSubClass', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '...
                                             'ScreenPorch', 'PoolArea',
                                             'MiscVal', 'MoSold', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 VotingRegressor(estimators=[('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x7fb0c6cc33a0>),
                                             ('Bayesian Ridge',
                                              BayesianRidge())],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fb0c8edeca0>)
2023-01-23 02:22:47,882:INFO:Checking exceptions
2023-01-23 02:22:47,882:INFO:Preloading libraries
2023-01-23 02:22:47,896:INFO:Set up data.
2023-01-23 02:22:48,072:INFO:Set up index.
2023-01-23 02:22:56,417:INFO:Initializing predict_model()
2023-01-23 02:22:56,417:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb0c8ad8730>, estimator=Pipeline(memory=Memory(location=/var/folders/3w/xf1fzw1s1mnb4ckhfxf67vgw0000gn/T/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['MSSubClass', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '...
                                             'ScreenPorch', 'PoolArea',
                                             'MiscVal', 'MoSold', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 VotingRegressor(estimators=[('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x7fb0c6cc33a0>),
                                             ('Bayesian Ridge',
                                              BayesianRidge())],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fb0c8ede310>)
2023-01-23 02:22:56,418:INFO:Checking exceptions
2023-01-23 02:22:56,418:INFO:Preloading libraries
2023-01-23 02:22:56,419:INFO:Set up data.
2023-01-23 02:22:56,479:INFO:Set up index.
2023-01-23 02:23:24,484:INFO:Initializing predict_model()
2023-01-23 02:23:24,484:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb0c8ad8730>, estimator=Pipeline(memory=Memory(location=/var/folders/3w/xf1fzw1s1mnb4ckhfxf67vgw0000gn/T/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['MSSubClass', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '...
                                             'ScreenPorch', 'PoolArea',
                                             'MiscVal', 'MoSold', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 VotingRegressor(estimators=[('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x7fb0c6cc33a0>),
                                             ('Bayesian Ridge',
                                              BayesianRidge())],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fb0c8ede820>)
2023-01-23 02:23:24,485:INFO:Checking exceptions
2023-01-23 02:23:24,485:INFO:Preloading libraries
2023-01-23 02:23:24,489:INFO:Set up data.
2023-01-23 02:23:24,559:INFO:Set up index.
2023-01-23 02:25:11,764:INFO:Initializing predict_model()
2023-01-23 02:25:11,766:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb0c8ad8730>, estimator=Pipeline(memory=Memory(location=/var/folders/3w/xf1fzw1s1mnb4ckhfxf67vgw0000gn/T/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['MSSubClass', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '...
                                             'ScreenPorch', 'PoolArea',
                                             'MiscVal', 'MoSold', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 VotingRegressor(estimators=[('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x7fb0c6cc33a0>),
                                             ('Bayesian Ridge',
                                              BayesianRidge())],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fb0c9f2fb80>)
2023-01-23 02:25:11,766:INFO:Checking exceptions
2023-01-23 02:25:11,766:INFO:Preloading libraries
2023-01-23 02:25:11,770:INFO:Set up data.
2023-01-23 02:25:11,924:INFO:Set up index.
2023-01-23 02:27:18,065:INFO:Initializing predict_model()
2023-01-23 02:27:18,067:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7fb0c8ad8730>, estimator=Pipeline(memory=Memory(location=/var/folders/3w/xf1fzw1s1mnb4ckhfxf67vgw0000gn/T/joblib),
         steps=[('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('numerical_imputer',
                 TransformerWrapper(include=['MSSubClass', 'LotArea',
                                             'OverallQual', 'OverallCond',
                                             'YearBuilt', 'YearRemodAdd',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '...
                                             'ScreenPorch', 'PoolArea',
                                             'MiscVal', 'MoSold', ...],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('actual_estimator',
                 VotingRegressor(estimators=[('CatBoost Regressor',
                                              <catboost.core.CatBoostRegressor object at 0x7fb0c6cc33a0>),
                                             ('Bayesian Ridge',
                                              BayesianRidge())],
                                 n_jobs=-1))]), probability_threshold=None, encoded_labels=False, raw_score=False, drift_report=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fb0c82bee50>)
2023-01-23 02:27:18,067:INFO:Checking exceptions
2023-01-23 02:27:18,067:INFO:Preloading libraries
2023-01-23 02:27:18,093:INFO:Set up data.
2023-01-23 02:27:18,237:INFO:Set up index.
